{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1b87ba52",
            "metadata": {},
            "source": [
                "# AWS Neuron compilation on Yolov8\n",
                "\n",
                "This notebook shows how to compile Yolov8/Pytorch to AWS Inferentia (inf1 instances) using NeuronSDK.\n",
                "\n",
                "Reference: \n",
                "- Model Prediction with Ultralytics YOLO\n",
                "    - https://docs.ultralytics.com/modes/predict/"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "49acc5c3",
            "metadata": {},
            "source": [
                "## 1. Neuron Compilation using  Native Neuron SDK"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "45fd47d8",
            "metadata": {},
            "source": [
                "### Load yolo8 model using ultralytics Lib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "ad6f3253",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'model/yolov8n.pt'...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 6.23M/6.23M [00:00<00:00, 356MB/s]\n"
                    ]
                }
            ],
            "source": [
                "from ultralytics import YOLO\n",
                "\n",
                "model = YOLO(\"model/yolov8n.pt\", task=\"detect\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "81366877",
            "metadata": {},
            "source": [
                "### Compile pytorch model to neuron model\n",
                "- When having an error, skip this cell"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "422acc95",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "input example shape:  torch.Size([1, 3, 640, 640])\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/ubuntu/miniconda3/envs/yolo8-conda-py310/lib/python3.10/site-packages/ultralytics/nn/modules/head.py:54: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if self.dynamic or self.shape != shape:\n",
                        "/home/ubuntu/miniconda3/envs/yolo8-conda-py310/lib/python3.10/site-packages/torch/jit/_trace.py:976: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
                        "  module._c._create_method_from_trace(\n",
                        "INFO:Neuron:All operators are compiled by neuron-cc (this does not guarantee that neuron-cc will successfully compile)\n",
                        "INFO:Neuron:Number of arithmetic operators (pre-compilation) before = 186, fused = 186, percent fused = 100.0%\n",
                        "/home/ubuntu/miniconda3/envs/yolo8-conda-py310/lib/python3.10/site-packages/torch/jit/_trace.py:804: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
                        "  traced = torch._C._create_function_from_trace(\n",
                        "INFO:Neuron:Compiling function _NeuronGraph$650 with neuron-cc\n",
                        "INFO:Neuron:Compiling with command line: '/home/ubuntu/miniconda3/envs/yolo8-conda-py310/bin/neuron-cc compile /tmp/tmp62li8sr0/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /tmp/tmp62li8sr0/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[1, 3, 640, 640], \"float32\"]}, \"outputs\": [\"Detect_74/aten_cat_5/concat:0\", \"Detect_74/aten_cat/concat:0\", \"Detect_74/aten_cat_1/concat:0\", \"Detect_74/aten_cat_2/concat:0\"]} --verbose 35'\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "....\n",
                        "Compiler status PASS\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:Neuron:Number of arithmetic operators (post-compilation) before = 186, compiled = 186, percent compiled = 100.0%\n",
                        "INFO:Neuron:The neuron partitioner created 1 sub-graphs\n",
                        "INFO:Neuron:Neuron successfully compiled 1 sub-graphs, Total fused subgraphs = 1, Percent of model sub-graphs successfully compiled = 100.0%\n",
                        "INFO:Neuron:Compiled these operators (and operator counts) to Neuron:\n",
                        "INFO:Neuron: => aten::Int: 7\n",
                        "INFO:Neuron: => aten::_convolution: 64\n",
                        "INFO:Neuron: => aten::add: 8\n",
                        "INFO:Neuron: => aten::cat: 19\n",
                        "INFO:Neuron: => aten::chunk: 9\n",
                        "INFO:Neuron: => aten::div: 1\n",
                        "INFO:Neuron: => aten::max_pool2d: 3\n",
                        "INFO:Neuron: => aten::mul: 1\n",
                        "INFO:Neuron: => aten::sigmoid: 1\n",
                        "INFO:Neuron: => aten::silu_: 57\n",
                        "INFO:Neuron: => aten::size: 3\n",
                        "INFO:Neuron: => aten::softmax: 1\n",
                        "INFO:Neuron: => aten::split_with_sizes: 1\n",
                        "INFO:Neuron: => aten::sub: 2\n",
                        "INFO:Neuron: => aten::transpose: 1\n",
                        "INFO:Neuron: => aten::unsqueeze: 1\n",
                        "INFO:Neuron: => aten::upsample_nearest2d: 2\n",
                        "INFO:Neuron: => aten::view: 5\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import torch_neuron\n",
                "\n",
                "# generate dummy input example\n",
                "example = torch.rand([1, 3, 640, 640])\n",
                "print(\"input example shape: \", example.shape)\n",
                "# trace the model forward\n",
                "trace = torch_neuron.trace(model.model, example)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f793e067",
            "metadata": {},
            "source": [
                "### Inference on neuron model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "8f814ff9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "result_neuron:  2 , shape:  torch.Size([1, 84, 8400])\n"
                    ]
                }
            ],
            "source": [
                "result_neuron = trace(example)\n",
                "print(\"result_neuron: \", len(result_neuron), \", shape: \", result_neuron[0].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c0082e3a",
            "metadata": {},
            "source": [
                "## 2. Compile and inference using ultralytics lib"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "060f5dc9",
            "metadata": {},
            "source": [
                "### Load pytorch model, yolo8, and compile it to neuron model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "793ab87d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded existing model from model/yolov8n.neuron\n"
                    ]
                }
            ],
            "source": [
                "from ultralytics import YOLO\n",
                "\n",
                "import os\n",
                "\n",
                "pt_model_path = 'model/yolov8n.pt'\n",
                "neuron_model_path = 'model/yolov8n.neuron'\n",
                "\n",
                "if os.path.exists(neuron_model_path):\n",
                "    # Load the existing model\n",
                "    m_inf= YOLO(\"model/yolov8n.neuron\", task=\"detect\")\n",
                "    print(f\"Loaded existing model from {neuron_model_path}\")\n",
                "else:\n",
                "    mx=YOLO(pt_model_path)\n",
                "    mx.export(format=\"neuron\")\n",
                "    m_inf= YOLO(\"model/yolov8n.neuron\", task=\"detect\")\n",
                "    print(f\"Compile and Load model from pytorch model, {pt_model_path}, and neuron model, {neuron_model_path}\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7b1ca898",
            "metadata": {},
            "source": [
                "### inference on neuron model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "74a76353",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model/yolov8n.neuron for Neuron (NeuronCore-v1) inference...\n",
                        "\n",
                        "image 1/1 /home/ubuntu/lab/03-yolo8-inf1/test_image/bus.jpg: 640x640 4 persons, 1 bus, 28.3ms\n",
                        "Speed: 2.2ms preprocess, 28.3ms inference, 73.9ms postprocess per image at shape (1, 3, 640, 640)\n",
                        "Results saved to \u001b[1mresult_image/predict2\u001b[0m\n",
                        "1 label saved to result_image/predict2/labels\n"
                    ]
                }
            ],
            "source": [
                "result = m_inf.predict(\"test_image/bus.jpg\", \n",
                "                            # show=True,\n",
                "                            save=True, \n",
                "                            save_txt=True, \n",
                "                            save_crop=True, \n",
                "                            save_conf=True,\n",
                "                            project='result_image')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "00fbbc97",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "result_inf2): \n",
                        " [ultralytics.engine.results.Results object with attributes:\n",
                        "\n",
                        "boxes: ultralytics.engine.results.Boxes object\n",
                        "keypoints: None\n",
                        "masks: None\n",
                        "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
                        "obb: None\n",
                        "orig_img: array([[[119, 146, 172],\n",
                        "        [121, 148, 174],\n",
                        "        [122, 152, 177],\n",
                        "        ...,\n",
                        "        [161, 171, 188],\n",
                        "        [160, 170, 187],\n",
                        "        [160, 170, 187]],\n",
                        "\n",
                        "       [[120, 147, 173],\n",
                        "        [122, 149, 175],\n",
                        "        [123, 153, 178],\n",
                        "        ...,\n",
                        "        [161, 171, 188],\n",
                        "        [160, 170, 187],\n",
                        "        [160, 170, 187]],\n",
                        "\n",
                        "       [[123, 150, 176],\n",
                        "        [124, 151, 177],\n",
                        "        [125, 155, 180],\n",
                        "        ...,\n",
                        "        [161, 171, 188],\n",
                        "        [160, 170, 187],\n",
                        "        [160, 170, 187]],\n",
                        "\n",
                        "       ...,\n",
                        "\n",
                        "       [[183, 182, 186],\n",
                        "        [179, 178, 182],\n",
                        "        [180, 179, 183],\n",
                        "        ...,\n",
                        "        [121, 111, 117],\n",
                        "        [113, 103, 109],\n",
                        "        [115, 105, 111]],\n",
                        "\n",
                        "       [[165, 164, 168],\n",
                        "        [173, 172, 176],\n",
                        "        [187, 186, 190],\n",
                        "        ...,\n",
                        "        [102,  92,  98],\n",
                        "        [101,  91,  97],\n",
                        "        [103,  93,  99]],\n",
                        "\n",
                        "       [[123, 122, 126],\n",
                        "        [145, 144, 148],\n",
                        "        [176, 175, 179],\n",
                        "        ...,\n",
                        "        [ 95,  85,  91],\n",
                        "        [ 96,  86,  92],\n",
                        "        [ 98,  88,  94]]], dtype=uint8)\n",
                        "orig_shape: (1080, 810)\n",
                        "path: '/home/ubuntu/lab/03-yolo8-inf1/test_image/bus.jpg'\n",
                        "probs: None\n",
                        "save_dir: 'result_image/predict2'\n",
                        "speed: {'preprocess': 2.172231674194336, 'inference': 28.27143669128418, 'postprocess': 73.93240928649902}]\n"
                    ]
                }
            ],
            "source": [
                "print(\"result_inf2): \\n\", result)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "yolo8-conda-py310",
            "language": "python",
            "name": "yolo8-conda-py310"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.15"
        },
        "vscode": {
            "interpreter": {
                "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
