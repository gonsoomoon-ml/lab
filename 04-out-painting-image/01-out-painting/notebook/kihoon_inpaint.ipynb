{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6466712-714f-44e9-bcf6-17d9a0ed9262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install ipywidgets --quiet\n",
    "# !pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f751026-8970-47d6-8307-6507d0730857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab5eff8-958f-44b9-952c-fd6c08597387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829b431d-d9d6-413f-845a-9613d61065d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def query(model_predictor, payload, content_type, accept):\n",
    "    \"\"\"Query the model predictor.\"\"\"\n",
    "\n",
    "    query_response = model_predictor.predict(\n",
    "        payload,\n",
    "        {\n",
    "            \"ContentType\": content_type,\n",
    "            \"Accept\": accept,\n",
    "        },\n",
    "    )\n",
    "    return query_response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    \"\"\"Parse response and return the generated images.\"\"\"\n",
    "\n",
    "    response_dict = json.loads(query_response)\n",
    "    return response_dict[\"generated_images\"]\n",
    "\n",
    "\n",
    "def display_img_and_prompt(img, prmpt):\n",
    "    \"\"\"Display the generated image.\"\"\"\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(np.array(img))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(prmpt)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d61df0d-7ac0-4005-a03f-cccf68b2e8bf",
   "metadata": {},
   "source": [
    "# Deploy stable diffusion inpainting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed85aac-4344-482d-8fe0-d67514442ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autogluon-classification-ensemble',\n",
       " 'autogluon-forecasting-chronos-t5-base',\n",
       " 'autogluon-forecasting-chronos-t5-large',\n",
       " 'autogluon-forecasting-chronos-t5-small',\n",
       " 'autogluon-regression-ensemble',\n",
       " 'catboost-classification-model',\n",
       " 'catboost-regression-model',\n",
       " 'huggingface-asr-whisper-base',\n",
       " 'huggingface-asr-whisper-large',\n",
       " 'huggingface-asr-whisper-large-v2',\n",
       " 'huggingface-asr-whisper-large-v3',\n",
       " 'huggingface-asr-whisper-large-v3-turbo',\n",
       " 'huggingface-asr-whisper-medium',\n",
       " 'huggingface-asr-whisper-small',\n",
       " 'huggingface-asr-whisper-tiny',\n",
       " 'huggingface-eqa-bert-base-cased',\n",
       " 'huggingface-eqa-bert-base-multilingual-cased',\n",
       " 'huggingface-eqa-bert-base-multilingual-uncased',\n",
       " 'huggingface-eqa-bert-base-uncased',\n",
       " 'huggingface-eqa-bert-large-cased',\n",
       " 'huggingface-eqa-bert-large-cased-whole-word-masking',\n",
       " 'huggingface-eqa-bert-large-uncased',\n",
       " 'huggingface-eqa-bert-large-uncased-whole-word-masking',\n",
       " 'huggingface-eqa-distilbert-base-cased',\n",
       " 'huggingface-eqa-distilbert-base-multilingual-cased',\n",
       " 'huggingface-eqa-distilbert-base-uncased',\n",
       " 'huggingface-eqa-distilroberta-base',\n",
       " 'huggingface-eqa-roberta-base',\n",
       " 'huggingface-eqa-roberta-base-openai-detector',\n",
       " 'huggingface-eqa-roberta-large',\n",
       " 'huggingface-fillmask-bert-base-uncased',\n",
       " 'huggingface-llm-ahxt-litellama-460m-1t',\n",
       " 'huggingface-llm-ai-forever-mgpt',\n",
       " 'huggingface-llm-alpindale-wizard-lm-2-8-22B',\n",
       " 'huggingface-llm-amazon-falconlite',\n",
       " 'huggingface-llm-amazon-falconlite2',\n",
       " 'huggingface-llm-amazon-mistrallite',\n",
       " 'huggingface-llm-aya-101',\n",
       " 'huggingface-llm-berkeley-nest-starling-lm-7b-alpha',\n",
       " 'huggingface-llm-bilingual-rinna-4b-instruction-ppo-bf16',\n",
       " 'huggingface-llm-calm2-7b-chat-bf16',\n",
       " 'huggingface-llm-cognitive-dolphin-29-llama3-8b',\n",
       " 'huggingface-llm-cohereforai-c4ai-command-r-plus',\n",
       " 'huggingface-llm-cultrix-mistraltrix-v1',\n",
       " 'huggingface-llm-dbrx-base',\n",
       " 'huggingface-llm-dbrx-instruct',\n",
       " 'huggingface-llm-dolphin-2-2-1-mistral-7b',\n",
       " 'huggingface-llm-dolphin-2-5-mixtral-8x7b',\n",
       " 'huggingface-llm-dolphin-2-7-mixtral-8x7b',\n",
       " 'huggingface-llm-eleutherai-gpt-neo-1-3b',\n",
       " 'huggingface-llm-eleutherai-gpt-neo-2-7b',\n",
       " 'huggingface-llm-eleutherai-pythia-160m-deduped',\n",
       " 'huggingface-llm-eleutherai-pythia-70m-deduped',\n",
       " 'huggingface-llm-elyza-japanese-llama-2-13b-chat',\n",
       " 'huggingface-llm-elyza-japanese-llama-2-13b-fast-chat',\n",
       " 'huggingface-llm-elyza-japanese-llama-2-7b-chat-bf16',\n",
       " 'huggingface-llm-elyza-japanese-llama-2-7b-fast-chat-bf16',\n",
       " 'huggingface-llm-falcon-180b-bf16',\n",
       " 'huggingface-llm-falcon-180b-chat-bf16',\n",
       " 'huggingface-llm-falcon-40b-bf16',\n",
       " 'huggingface-llm-falcon-40b-instruct-bf16',\n",
       " 'huggingface-llm-falcon-7b-bf16',\n",
       " 'huggingface-llm-falcon-7b-instruct-bf16',\n",
       " 'huggingface-llm-falcon2-11b',\n",
       " 'huggingface-llm-garage-baind-platypus2-7b',\n",
       " 'huggingface-llm-gemma-2b',\n",
       " 'huggingface-llm-gemma-2b-instruct',\n",
       " 'huggingface-llm-gemma-7b',\n",
       " 'huggingface-llm-gemma-7b-instruct',\n",
       " 'huggingface-llm-gradientai-llama-3-8B-instruct-262k',\n",
       " 'huggingface-llm-huggingfaceh4-mistral-7b-sft-alpha',\n",
       " 'huggingface-llm-huggingfaceh4-mistral-7b-sft-beta',\n",
       " 'huggingface-llm-huggingfaceh4-starchat-alpha',\n",
       " 'huggingface-llm-huggingfaceh4-starchat-beta',\n",
       " 'huggingface-llm-huggingfaceh4-zephyr-7b-alpha',\n",
       " 'huggingface-llm-huggingfaceh4-zephyr-7b-beta',\n",
       " 'huggingface-llm-huggingfaceh4-zephyr-orpo-141b-a35b-v01',\n",
       " 'huggingface-llm-llama-3-8b-instruct-gradient',\n",
       " 'huggingface-llm-mistral-7b',\n",
       " 'huggingface-llm-mistral-7b-instruct',\n",
       " 'huggingface-llm-mistral-7b-instruct-v3',\n",
       " 'huggingface-llm-mistral-7b-openorca-gptq',\n",
       " 'huggingface-llm-mistral-7b-v3',\n",
       " 'huggingface-llm-mistralai-mixtral-8x22B-instruct-v0-1',\n",
       " 'huggingface-llm-mixtral-8x22B',\n",
       " 'huggingface-llm-mixtral-8x7b',\n",
       " 'huggingface-llm-mixtral-8x7b-instruct',\n",
       " 'huggingface-llm-mixtral-8x7b-instruct-gptq',\n",
       " 'huggingface-llm-nexaaidev-octopus-v2',\n",
       " 'huggingface-llm-nexusflow-starling-lm-7b-beta',\n",
       " 'huggingface-llm-nousresearch-hermes-2-pro-llama-3-8B',\n",
       " 'huggingface-llm-nousresearch-nous-hermes-2-solar-10-7b',\n",
       " 'huggingface-llm-nousresearch-nous-hermes-llama-2-7b',\n",
       " 'huggingface-llm-nousresearch-nous-hermes-llama2-13b',\n",
       " 'huggingface-llm-nousresearch-yarn-mistral-7b-128k',\n",
       " 'huggingface-llm-nvidia-llama3-chatqa-1-5-70B',\n",
       " 'huggingface-llm-nvidia-llama3-chatqa-1-5-8B',\n",
       " 'huggingface-llm-openlm-research-open-llama-7b-v2',\n",
       " 'huggingface-llm-phi-2',\n",
       " 'huggingface-llm-phi-3-mini-128k-instruct',\n",
       " 'huggingface-llm-phi-3-mini-4k-instruct',\n",
       " 'huggingface-llm-qwen2-0-5b',\n",
       " 'huggingface-llm-qwen2-0-5b-instruct',\n",
       " 'huggingface-llm-qwen2-1-5b',\n",
       " 'huggingface-llm-qwen2-1-5b-instruct',\n",
       " 'huggingface-llm-qwen2-7b',\n",
       " 'huggingface-llm-qwen2-7b-instruct',\n",
       " 'huggingface-llm-rinna-3-6b-instruction-ppo-bf16',\n",
       " 'huggingface-llm-sealion-3b',\n",
       " 'huggingface-llm-sealion-7b',\n",
       " 'huggingface-llm-sealion-7b-instruct',\n",
       " 'huggingface-llm-shenzhi-wang-llama3-8B-chinese-chat',\n",
       " 'huggingface-llm-snowflake-arctic-instruct-vllm',\n",
       " 'huggingface-llm-starcoder',\n",
       " 'huggingface-llm-starcoderbase',\n",
       " 'huggingface-llm-teknium-openhermes-2-mistral-7b',\n",
       " 'huggingface-llm-thebloke-mistral-7b-openorca-awq',\n",
       " 'huggingface-llm-tiiuae-falcon-rw-1b',\n",
       " 'huggingface-llm-tinyllama-1-1b-intermediate-step-1431k-3',\n",
       " 'huggingface-llm-tinyllama-tinyllama-1-1b-chat-v0-6',\n",
       " 'huggingface-llm-tinyllama-tinyllama-1-1b-chat-v1-0',\n",
       " 'huggingface-llm-writer-palmyra-small',\n",
       " 'huggingface-llm-yi-1-5-34b',\n",
       " 'huggingface-llm-yi-1-5-34b-chat',\n",
       " 'huggingface-llm-yi-1-5-6b',\n",
       " 'huggingface-llm-yi-1-5-6b-chat',\n",
       " 'huggingface-llm-yi-1-5-9b',\n",
       " 'huggingface-llm-yi-1-5-9b-chat',\n",
       " 'huggingface-llm-zephyr-7b-gemma',\n",
       " 'huggingface-llmneuron-mistral-7b',\n",
       " 'huggingface-llmneuron-mistral-7b-instruct',\n",
       " 'huggingface-ner-distilbert-base-cased-finetuned-conll03-eng',\n",
       " 'huggingface-ner-distilbert-base-cased-finetuned-conll03-english',\n",
       " 'huggingface-ner-distilbert-base-uncased-finetuned-conll03-eng',\n",
       " 'huggingface-ner-distilbert-base-uncased-finetuned-conll03-english',\n",
       " 'huggingface-sentencesimilarity-all-MiniLM-L6-v2',\n",
       " 'huggingface-sentencesimilarity-bge-base-en',\n",
       " 'huggingface-sentencesimilarity-bge-base-en-v1-5',\n",
       " 'huggingface-sentencesimilarity-bge-large-en',\n",
       " 'huggingface-sentencesimilarity-bge-large-en-v1-5',\n",
       " 'huggingface-sentencesimilarity-bge-large-zh-v1-5',\n",
       " 'huggingface-sentencesimilarity-bge-m3',\n",
       " 'huggingface-sentencesimilarity-bge-small-en',\n",
       " 'huggingface-sentencesimilarity-bge-small-en-v1-5',\n",
       " 'huggingface-sentencesimilarity-e5-base',\n",
       " 'huggingface-sentencesimilarity-e5-base-v2',\n",
       " 'huggingface-sentencesimilarity-e5-large',\n",
       " 'huggingface-sentencesimilarity-e5-large-v2',\n",
       " 'huggingface-sentencesimilarity-e5-small-v2',\n",
       " 'huggingface-sentencesimilarity-gte-base',\n",
       " 'huggingface-sentencesimilarity-gte-large',\n",
       " 'huggingface-sentencesimilarity-gte-small',\n",
       " 'huggingface-sentencesimilarity-multilingual-e5-base',\n",
       " 'huggingface-sentencesimilarity-multilingual-e5-large',\n",
       " 'huggingface-spc-bert-base-cased',\n",
       " 'huggingface-spc-bert-base-multilingual-cased',\n",
       " 'huggingface-spc-bert-base-multilingual-uncased',\n",
       " 'huggingface-spc-bert-base-uncased',\n",
       " 'huggingface-spc-bert-large-cased',\n",
       " 'huggingface-spc-bert-large-cased-whole-word-masking',\n",
       " 'huggingface-spc-bert-large-uncased',\n",
       " 'huggingface-spc-bert-large-uncased-whole-word-masking',\n",
       " 'huggingface-spc-distilbert-base-cased',\n",
       " 'huggingface-spc-distilbert-base-multilingual-cased',\n",
       " 'huggingface-spc-distilbert-base-uncased',\n",
       " 'huggingface-spc-distilroberta-base',\n",
       " 'huggingface-spc-roberta-base',\n",
       " 'huggingface-spc-roberta-base-openai-detector',\n",
       " 'huggingface-spc-roberta-large',\n",
       " 'huggingface-spc-roberta-large-openai-detector',\n",
       " 'huggingface-spc-xlm-clm-ende-1024',\n",
       " 'huggingface-spc-xlm-mlm-ende-1024',\n",
       " 'huggingface-spc-xlm-mlm-enro-1024',\n",
       " 'huggingface-spc-xlm-mlm-tlm-xnli15-1024',\n",
       " 'huggingface-spc-xlm-mlm-xnli15-1024',\n",
       " 'huggingface-summarization-bart-large-cnn-samsum',\n",
       " 'huggingface-summarization-bert-small2bert-cnn-dailymail-summ',\n",
       " 'huggingface-summarization-bert-small2bert-small-finetuned-cnn-daily-mail-summarization',\n",
       " 'huggingface-summarization-bigbird-pegasus-large-arxiv',\n",
       " 'huggingface-summarization-bigbird-pegasus-large-pubmed',\n",
       " 'huggingface-summarization-distilbart-cnn-12-6',\n",
       " 'huggingface-summarization-distilbart-cnn-6-6',\n",
       " 'huggingface-summarization-distilbart-xsum-1-1',\n",
       " 'huggingface-summarization-distilbart-xsum-12-3',\n",
       " 'huggingface-tc-bert-base-cased',\n",
       " 'huggingface-tc-bert-base-multilingual-cased',\n",
       " 'huggingface-tc-bert-base-multilingual-uncased',\n",
       " 'huggingface-tc-bert-base-uncased',\n",
       " 'huggingface-tc-bert-large-cased',\n",
       " 'huggingface-tc-bert-large-cased-whole-word-masking',\n",
       " 'huggingface-tc-bert-large-uncased',\n",
       " 'huggingface-tc-bert-large-uncased-whole-word-masking',\n",
       " 'huggingface-tc-distilbert-base-cased',\n",
       " 'huggingface-tc-distilbert-base-multilingual-cased',\n",
       " 'huggingface-tc-distilbert-base-uncased',\n",
       " 'huggingface-tc-distilroberta-base',\n",
       " 'huggingface-tc-models',\n",
       " 'huggingface-tc-roberta-base',\n",
       " 'huggingface-tc-roberta-base-openai-detector',\n",
       " 'huggingface-tc-roberta-large',\n",
       " 'huggingface-tc-roberta-large-openai-detector',\n",
       " 'huggingface-tc-xlm-clm-ende-1024',\n",
       " 'huggingface-tc-xlm-mlm-ende-1024',\n",
       " 'huggingface-tc-xlm-mlm-enro-1024',\n",
       " 'huggingface-tc-xlm-mlm-tlm-xnli15-1024',\n",
       " 'huggingface-text2text-bart4csc-base-chinese',\n",
       " 'huggingface-text2text-bigscience-t0pp',\n",
       " 'huggingface-text2text-bigscience-t0pp-bnb-int8',\n",
       " 'huggingface-text2text-bigscience-t0pp-fp16',\n",
       " 'huggingface-text2text-flan-t5-base',\n",
       " 'huggingface-text2text-flan-t5-base-samsum',\n",
       " 'huggingface-text2text-flan-t5-large',\n",
       " 'huggingface-text2text-flan-t5-small',\n",
       " 'huggingface-text2text-flan-t5-xl',\n",
       " 'huggingface-text2text-flan-t5-xxl',\n",
       " 'huggingface-text2text-flan-t5-xxl-bnb-int8',\n",
       " 'huggingface-text2text-flan-t5-xxl-fp16',\n",
       " 'huggingface-text2text-flan-ul2-bf16',\n",
       " 'huggingface-text2text-pegasus-paraphrase',\n",
       " 'huggingface-text2text-qcpg-sentences',\n",
       " 'huggingface-text2text-t5-one-line-summary',\n",
       " 'huggingface-textembedding-all-MiniLM-L6-v2',\n",
       " 'huggingface-textembedding-bge-base-en-v1-5',\n",
       " 'huggingface-textembedding-bloom-7b1',\n",
       " 'huggingface-textembedding-bloom-7b1-fp16',\n",
       " 'huggingface-textembedding-gpt-j-6b',\n",
       " 'huggingface-textembedding-gpt-j-6b-fp16',\n",
       " 'huggingface-textembedding-gte-qwen2-7b-instruct',\n",
       " 'huggingface-textembedding-sfr-embedding-2-r',\n",
       " 'huggingface-textembedding-sfr-embedding-mistral',\n",
       " 'huggingface-textgeneration-bloom-1b1',\n",
       " 'huggingface-textgeneration-bloom-1b7',\n",
       " 'huggingface-textgeneration-bloom-560m',\n",
       " 'huggingface-textgeneration-bloomz-1b1',\n",
       " 'huggingface-textgeneration-bloomz-1b7',\n",
       " 'huggingface-textgeneration-bloomz-560m',\n",
       " 'huggingface-textgeneration-distilgpt2',\n",
       " 'huggingface-textgeneration-dolly-v2-12b-bf16',\n",
       " 'huggingface-textgeneration-dolly-v2-3b-bf16',\n",
       " 'huggingface-textgeneration-dolly-v2-7b-bf16',\n",
       " 'huggingface-textgeneration-falcon-40b-bf16',\n",
       " 'huggingface-textgeneration-falcon-40b-instruct-bf16',\n",
       " 'huggingface-textgeneration-falcon-7b-bf16',\n",
       " 'huggingface-textgeneration-falcon-7b-instruct-bf16',\n",
       " 'huggingface-textgeneration-gpt2',\n",
       " 'huggingface-textgeneration-models',\n",
       " 'huggingface-textgeneration-open-llama',\n",
       " 'huggingface-textgeneration1-bloom-176b-int8',\n",
       " 'huggingface-textgeneration1-bloom-3b',\n",
       " 'huggingface-textgeneration1-bloom-3b-fp16',\n",
       " 'huggingface-textgeneration1-bloom-7b1',\n",
       " 'huggingface-textgeneration1-bloom-7b1-fp16',\n",
       " 'huggingface-textgeneration1-bloomz-176b-fp16',\n",
       " 'huggingface-textgeneration1-bloomz-3b-fp16',\n",
       " 'huggingface-textgeneration1-bloomz-7b1-fp16',\n",
       " 'huggingface-textgeneration1-gpt-2-xl',\n",
       " 'huggingface-textgeneration1-gpt-2-xl-fp16',\n",
       " 'huggingface-textgeneration1-gpt-j-6b',\n",
       " 'huggingface-textgeneration1-gpt-j-6b-fp16',\n",
       " 'huggingface-textgeneration1-gpt-neo-1-3b',\n",
       " 'huggingface-textgeneration1-gpt-neo-1-3b-fp16',\n",
       " 'huggingface-textgeneration1-gpt-neo-125m',\n",
       " 'huggingface-textgeneration1-gpt-neo-125m-fp16',\n",
       " 'huggingface-textgeneration1-gpt-neo-2-7b',\n",
       " 'huggingface-textgeneration1-gpt-neo-2-7b-fp16',\n",
       " 'huggingface-textgeneration1-lightgpt',\n",
       " 'huggingface-textgeneration1-mpt-7b-bf16',\n",
       " 'huggingface-textgeneration1-mpt-7b-instruct-bf16',\n",
       " 'huggingface-textgeneration1-mpt-7b-storywriter-bf16',\n",
       " 'huggingface-textgeneration1-redpajama-incite-base-3B-v1-fp16',\n",
       " 'huggingface-textgeneration1-redpajama-incite-base-7B-v1-fp16',\n",
       " 'huggingface-textgeneration1-redpajama-incite-chat-3B-v1-fp16',\n",
       " 'huggingface-textgeneration1-redpajama-incite-chat-7B-v1-fp16',\n",
       " 'huggingface-textgeneration1-redpajama-incite-instruct-3B-v1-fp16',\n",
       " 'huggingface-textgeneration1-redpajama-incite-instruct-3Bv1fp16',\n",
       " 'huggingface-textgeneration1-redpajama-incite-instruct-7B-v1-fp16',\n",
       " 'huggingface-textgeneration1-redpajama-incite-instruct-7B1fp16',\n",
       " 'huggingface-textgeneration2-gpt-neox-20b-fp16',\n",
       " 'huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16',\n",
       " 'huggingface-translation-opus-mt-en-es',\n",
       " 'huggingface-translation-opus-mt-en-vi',\n",
       " 'huggingface-translation-opus-mt-mul-en',\n",
       " 'huggingface-translation-t5-base',\n",
       " 'huggingface-translation-t5-large',\n",
       " 'huggingface-translation-t5-small',\n",
       " 'huggingface-txt2img-22h-vintedois-diffusion-v0-1',\n",
       " 'huggingface-txt2img-akikagura-mkgen-diffusion',\n",
       " 'huggingface-txt2img-alxdfy-noggles-fastdb-4800',\n",
       " 'huggingface-txt2img-alxdfy-noggles9000',\n",
       " 'huggingface-txt2img-andite-anything-v4-0',\n",
       " 'huggingface-txt2img-astraliteheart-pony-diffusion-v2',\n",
       " 'huggingface-txt2img-avrik-abstract-anim-spritesheets',\n",
       " 'huggingface-txt2img-aybeeceedee-knollingcase',\n",
       " 'huggingface-txt2img-bingsu-my-k-anything-v3-0',\n",
       " 'huggingface-txt2img-bingsu-my-korean-stable-diffusion-v1-5',\n",
       " 'huggingface-txt2img-buntopsih-novgoranstefanovski',\n",
       " 'huggingface-txt2img-claudfuen-photorealistic-fuen-v1',\n",
       " 'huggingface-txt2img-coder119-vectorartz-diffusion',\n",
       " 'huggingface-txt2img-conflictx-complex-lineart',\n",
       " 'huggingface-txt2img-dallinmackay-cats-musical-diffusion',\n",
       " 'huggingface-txt2img-dallinmackay-jwst-deep-space-diffusion',\n",
       " 'huggingface-txt2img-dallinmackay-tron-legacy-diffusion',\n",
       " 'huggingface-txt2img-dallinmackay-van-gogh-diffusion',\n",
       " 'huggingface-txt2img-dgspitzer-cyberpunk-anime-diffusion',\n",
       " 'huggingface-txt2img-dreamlike-art-dreamlike-diffusion-1-0',\n",
       " 'huggingface-txt2img-eimiss-eimisanimediffusion-1-0v',\n",
       " 'huggingface-txt2img-envvi-inkpunk-diffusion',\n",
       " 'huggingface-txt2img-evel-yoshin',\n",
       " 'huggingface-txt2img-extraphy-mustafa-kemal-ataturk',\n",
       " 'huggingface-txt2img-fffiloni-mr-men-and-little-misses',\n",
       " 'huggingface-txt2img-fictiverse-elrisitas',\n",
       " 'huggingface-txt2img-fictiverse-stable-diffusion-balloonart',\n",
       " 'huggingface-txt2img-fictiverse-stable-diffusion-balloonart-model',\n",
       " 'huggingface-txt2img-fictiverse-stable-diffusion-micro-model',\n",
       " 'huggingface-txt2img-fictiverse-stable-diffusion-microscopic-model',\n",
       " 'huggingface-txt2img-fictiverse-stable-diffusion-papercut-model',\n",
       " 'huggingface-txt2img-fictiverse-stable-diffusion-voxelart-model',\n",
       " 'huggingface-txt2img-haor-evt-v3',\n",
       " 'huggingface-txt2img-hassanblend-hassanblend1-4',\n",
       " 'huggingface-txt2img-idea-ccnl-taiyi-1b-chinese-en-v01',\n",
       " 'huggingface-txt2img-idea-ccnl-taiyi-1b-chinese-v0-1',\n",
       " 'huggingface-txt2img-idea-ccnl-taiyi-stable-diffusion-1b-chinese-en-v0-1',\n",
       " 'huggingface-txt2img-idea-ccnl-taiyi-stable-diffusion-1b-chinese-v0-1',\n",
       " 'huggingface-txt2img-ifansnek-johndiffusion',\n",
       " 'huggingface-txt2img-jersonm89-avatar',\n",
       " 'huggingface-txt2img-jvkape-iconsmi-appiconsmodelforsd',\n",
       " 'huggingface-txt2img-katakana-2d-mix',\n",
       " 'huggingface-txt2img-lacambre-vulvine-look-v02',\n",
       " 'huggingface-txt2img-langboat-guohua-diffusion',\n",
       " 'huggingface-txt2img-linaqruf-anything-v3-0',\n",
       " 'huggingface-txt2img-mikesmodels-waltz-with-bashir-diffusion',\n",
       " 'huggingface-txt2img-mitchtech-klingon-diffusion',\n",
       " 'huggingface-txt2img-mitchtech-vulcan-diffusion',\n",
       " 'huggingface-txt2img-mitsua-mitsua-diffusion-cc0',\n",
       " 'huggingface-txt2img-naclbit-trinart-stable-diffusion-v2',\n",
       " 'huggingface-txt2img-nitrosocke-arcane-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-archer-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-classic-anim-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-elden-ring-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-future-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-ghibli-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-mo-di-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-nitro-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-redshift-diffusion',\n",
       " 'huggingface-txt2img-nitrosocke-spider-verse-diffusion',\n",
       " 'huggingface-txt2img-nousr-robo-diffusion',\n",
       " 'huggingface-txt2img-ogkalu-comic-diffusion',\n",
       " 'huggingface-txt2img-openjourney-openjourney',\n",
       " 'huggingface-txt2img-piesposito-openpotionbottle-v2',\n",
       " 'huggingface-txt2img-plasmo-voxel-ish',\n",
       " 'huggingface-txt2img-plasmo-woolitize',\n",
       " 'huggingface-txt2img-progamergov-min-illust-background-diffusion',\n",
       " 'huggingface-txt2img-progamergov-min-illust-backgrounddiffusion',\n",
       " 'huggingface-txt2img-prompthero-linkedin-diffusion',\n",
       " 'huggingface-txt2img-prompthero-openjourney',\n",
       " 'huggingface-txt2img-qilex-magic-diffusion',\n",
       " 'huggingface-txt2img-rabidgremlin-sd-db-epic-space-machine',\n",
       " 'huggingface-txt2img-rayhell-popupbook-diffusion',\n",
       " 'huggingface-txt2img-runwayml-stable-diffusion-v1-5',\n",
       " 'huggingface-txt2img-s3nh-beksinski-style-stable-diffusion',\n",
       " 'huggingface-txt2img-sd-dreambooth-library-original-char-cyclps',\n",
       " 'huggingface-txt2img-sd-dreambooth-library-original-character-cyclps',\n",
       " 'huggingface-txt2img-sd-dreambooth-library-persona-5-shigenori',\n",
       " 'huggingface-txt2img-sd-dreambooth-library-persona-5-shigenori-style',\n",
       " 'huggingface-txt2img-sd-dreambooth-library-seraphm',\n",
       " 'huggingface-txt2img-shirayu-sd-tohoku-v1',\n",
       " 'huggingface-txt2img-thelastben-hrrzg-style-768px',\n",
       " 'huggingface-txt2img-timothepearce-gina-the-cat',\n",
       " 'huggingface-txt2img-trystar-clonediffusion',\n",
       " 'huggingface-txt2img-tuwonga-dbluth',\n",
       " 'huggingface-txt2img-tuwonga-rotoscopee',\n",
       " 'huggingface-txt2img-volrath50-fantasy-card-diffusion',\n",
       " 'huggingface-txt2img-yayab-sd-onepiece-diffusers4',\n",
       " 'huggingface-txt2imgneuron-stabilityai-stable-diffusion-v2-1',\n",
       " 'huggingface-txt2imgneuron-stabilityai-stable-diffusion-xl-base-1-0',\n",
       " 'huggingface-txt2imgneuron-stabilityai-stable-diffusion-xlbase1',\n",
       " 'huggingface-zstc-cross-encoder-nli-deberta-base',\n",
       " 'huggingface-zstc-cross-encoder-nli-distilroberta-base',\n",
       " 'huggingface-zstc-cross-encoder-nli-minilm2-l6-h768',\n",
       " 'huggingface-zstc-cross-encoder-nli-roberta-base',\n",
       " 'huggingface-zstc-digitalepidemiologylab-covid-twit-bert2-mnli',\n",
       " 'huggingface-zstc-digitalepidemiologylab-covid-twitter-bert-v2-mnli',\n",
       " 'huggingface-zstc-eleldar-theme-classification',\n",
       " 'huggingface-zstc-emrecan-bert-base-multilingual-cased-allnli-tr',\n",
       " 'huggingface-zstc-emrecan-bert-base-multilingual-cased-multinli-tr',\n",
       " 'huggingface-zstc-emrecan-bert-base-multilingual-cased-snli-tr',\n",
       " 'huggingface-zstc-emrecan-bert-base-turkish-cased-allnli-tr',\n",
       " 'huggingface-zstc-emrecan-bert-base-turkish-cased-multinli-tr',\n",
       " 'huggingface-zstc-emrecan-bert-base-turkish-cased-snli-tr',\n",
       " 'huggingface-zstc-emrecan-bertbase-mling-cased-allnli-tr',\n",
       " 'huggingface-zstc-emrecan-bertbase-mling-cased-multinli-tr',\n",
       " 'huggingface-zstc-emrecan-cbertbase-turkish-mc4cased-multinlitr',\n",
       " 'huggingface-zstc-emrecan-cbertbase-turkish-mc4cased-snlitr',\n",
       " 'huggingface-zstc-emrecan-cbertbase-turkishmc4-cased-allnlitr',\n",
       " 'huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-allnli-tr',\n",
       " 'huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-multinli-tr',\n",
       " 'huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-snli-tr',\n",
       " 'huggingface-zstc-emrecan-dbase-turkish-cased-allnlitr',\n",
       " 'huggingface-zstc-emrecan-dbertbase-turkish-cased-multinli-tr',\n",
       " 'huggingface-zstc-emrecan-distilbert-base-turkish-cased-allnli-tr',\n",
       " 'huggingface-zstc-emrecan-distilbert-base-turkish-cased-multinli-tr',\n",
       " 'huggingface-zstc-emrecan-distilbert-base-turkish-cased-snli-tr',\n",
       " 'huggingface-zstc-facebook-bart-large-mnli',\n",
       " 'huggingface-zstc-jiva-xlm-roberta-large-it-mnli',\n",
       " 'huggingface-zstc-lighteternal-nli-xlm-r-greek',\n",
       " 'huggingface-zstc-moritzlaurer-deberta-v3-large-mnli-fever-anli-ling-wanli',\n",
       " 'huggingface-zstc-moritzlaurer-deberta3large-mnli-fever',\n",
       " 'huggingface-zstc-moritzlaurer-mdeberta-v3-base-xnli-multilingual-nli-2mil7',\n",
       " 'huggingface-zstc-moritzlaurer-mdeberta3base-xnli-mling-nli-2m7',\n",
       " 'huggingface-zstc-narsil-bart-large-mnli-opti',\n",
       " 'huggingface-zstc-narsil-deberta-large-mnli-zero-cls',\n",
       " 'huggingface-zstc-navteca-bart-large-mnli',\n",
       " 'huggingface-zstc-recognai-bert-base-spanish-wwm-cased-xnli',\n",
       " 'huggingface-zstc-recognai-zeroshot-selectra-medium',\n",
       " 'huggingface-zstc-recognai-zeroshot-selectra-small',\n",
       " 'lightgbm-classification-model',\n",
       " 'lightgbm-regression-model',\n",
       " 'meta-tc-llama-prompt-guard-86m',\n",
       " 'meta-textgeneration-llama-2-13b',\n",
       " 'meta-textgeneration-llama-2-13b-f',\n",
       " 'meta-textgeneration-llama-2-70b',\n",
       " 'meta-textgeneration-llama-2-70b-f',\n",
       " 'meta-textgeneration-llama-2-7b',\n",
       " 'meta-textgeneration-llama-2-7b-f',\n",
       " 'meta-textgeneration-llama-3-1-405b-fp8',\n",
       " 'meta-textgeneration-llama-3-1-405b-instruct-fp8',\n",
       " 'meta-textgeneration-llama-3-1-70b',\n",
       " 'meta-textgeneration-llama-3-1-70b-instruct',\n",
       " 'meta-textgeneration-llama-3-1-8b',\n",
       " 'meta-textgeneration-llama-3-1-8b-instruct',\n",
       " 'meta-textgeneration-llama-3-2-1b',\n",
       " 'meta-textgeneration-llama-3-2-1b-instruct',\n",
       " 'meta-textgeneration-llama-3-2-3b',\n",
       " 'meta-textgeneration-llama-3-2-3b-instruct',\n",
       " 'meta-textgeneration-llama-3-70b',\n",
       " 'meta-textgeneration-llama-3-70b-instruct',\n",
       " 'meta-textgeneration-llama-3-8b',\n",
       " 'meta-textgeneration-llama-3-8b-instruct',\n",
       " 'meta-textgeneration-llama-codellama-13b',\n",
       " 'meta-textgeneration-llama-codellama-13b-instruct',\n",
       " 'meta-textgeneration-llama-codellama-13b-python',\n",
       " 'meta-textgeneration-llama-codellama-34b',\n",
       " 'meta-textgeneration-llama-codellama-34b-instruct',\n",
       " 'meta-textgeneration-llama-codellama-34b-python',\n",
       " 'meta-textgeneration-llama-codellama-70b',\n",
       " 'meta-textgeneration-llama-codellama-70b-instruct',\n",
       " 'meta-textgeneration-llama-codellama-70b-python',\n",
       " 'meta-textgeneration-llama-codellama-7b',\n",
       " 'meta-textgeneration-llama-codellama-7b-instruct',\n",
       " 'meta-textgeneration-llama-codellama-7b-python',\n",
       " 'meta-textgeneration-llama-guard-3-1b',\n",
       " 'meta-textgeneration-llama-guard-3-8b',\n",
       " 'meta-textgeneration-llama-guard-7b',\n",
       " 'meta-textgenerationneuron-llama-2-13b',\n",
       " 'meta-textgenerationneuron-llama-2-13b-f',\n",
       " 'meta-textgenerationneuron-llama-2-70b',\n",
       " 'meta-textgenerationneuron-llama-2-70b-f',\n",
       " 'meta-textgenerationneuron-llama-2-7b',\n",
       " 'meta-textgenerationneuron-llama-2-7b-f',\n",
       " 'meta-textgenerationneuron-llama-3-1-70b',\n",
       " 'meta-textgenerationneuron-llama-3-1-70b-instruct',\n",
       " 'meta-textgenerationneuron-llama-3-1-8b',\n",
       " 'meta-textgenerationneuron-llama-3-1-8b-instruct',\n",
       " 'meta-textgenerationneuron-llama-3-2-1b',\n",
       " 'meta-textgenerationneuron-llama-3-2-1b-instruct',\n",
       " 'meta-textgenerationneuron-llama-3-2-3b',\n",
       " 'meta-textgenerationneuron-llama-3-2-3b-instruct',\n",
       " 'meta-textgenerationneuron-llama-3-70b',\n",
       " 'meta-textgenerationneuron-llama-3-70b-instruct',\n",
       " 'meta-textgenerationneuron-llama-3-8b',\n",
       " 'meta-textgenerationneuron-llama-3-8b-instruct',\n",
       " 'meta-textgenerationneuron-llama-codellama-70b',\n",
       " 'meta-textgenerationneuron-llama-codellama-7b',\n",
       " 'meta-textgenerationneuron-llama-codellama-7b-python',\n",
       " 'meta-textgenerationneuron-llama-guard-3-1b',\n",
       " 'meta-textgenerationneuron-llama-guard-3-8b',\n",
       " 'meta-vlm-llama-3-2-11b-vision',\n",
       " 'meta-vlm-llama-3-2-11b-vision-instruct',\n",
       " 'meta-vlm-llama-3-2-90b-vision',\n",
       " 'meta-vlm-llama-3-2-90b-vision-instruct',\n",
       " 'meta-vlm-llama-guard-3-11b-vision',\n",
       " 'model-depth2img-stable-diffusion-2-depth-fp16',\n",
       " 'model-depth2img-stable-diffusion-v1-5-controlnet',\n",
       " 'model-depth2img-stable-diffusion-v1-5-controlnet-fp16',\n",
       " 'model-depth2img-stable-diffusion-v1-5-controlnet-v1-1',\n",
       " 'model-depth2img-stable-diffusion-v1-5-controlnet-v1-1-fp16',\n",
       " 'model-depth2img-stable-diffusion-v2-1-controlnet',\n",
       " 'model-depth2img-stable-diffusion-v2-1-controlnet-fp16',\n",
       " 'model-imagegeneration-stabilityai-stable-diffusion-v2-1',\n",
       " 'model-imagegeneration-stabilityai-stable-diffusion-xl-base-1-0',\n",
       " 'model-inpainting-runwayml-stable-diffusion-inpainting',\n",
       " 'model-inpainting-runwayml-stable-diffusion-inpainting-fp16',\n",
       " 'model-inpainting-stabilityai-stable-diffusion-2-inpainting',\n",
       " 'model-inpainting-stabilityai-stable-diffusion-2-inpainting-fp16',\n",
       " 'model-inpainting-stabilityai-stable-diffusion2-inpainting-fp16',\n",
       " 'model-textgenerationjp-japanese-stablelm-instruct-alpha-7b-v2',\n",
       " 'model-txt2img-stabilityai-stable-diffusion-v1-4',\n",
       " 'model-txt2img-stabilityai-stable-diffusion-v1-4-fp16',\n",
       " 'model-txt2img-stabilityai-stable-diffusion-v2',\n",
       " 'model-txt2img-stabilityai-stable-diffusion-v2-1-base',\n",
       " 'model-txt2img-stabilityai-stable-diffusion-v2-fp16',\n",
       " 'model-upscaling-stabilityai-stable-diffusion-x4-upscaler-fp16',\n",
       " 'mxnet-is-mask-rcnn-fpn-resnet101-v1d-coco',\n",
       " 'mxnet-is-mask-rcnn-fpn-resnet18-v1b-coco',\n",
       " 'mxnet-is-mask-rcnn-fpn-resnet50-v1b-coco',\n",
       " 'mxnet-is-mask-rcnn-resnet18-v1b-coco',\n",
       " 'mxnet-od-faster-rcnn-fpn-resnet101-v1d-coco',\n",
       " 'mxnet-od-faster-rcnn-fpn-resnet50-v1b-coco',\n",
       " 'mxnet-od-faster-rcnn-resnet101-v1d-coco',\n",
       " 'mxnet-od-faster-rcnn-resnet50-v1b-coco',\n",
       " 'mxnet-od-faster-rcnn-resnet50-v1b-voc',\n",
       " 'mxnet-od-ssd-300-vgg16-atrous-coco',\n",
       " 'mxnet-od-ssd-300-vgg16-atrous-voc',\n",
       " 'mxnet-od-ssd-512-mobilenet1-0-coco',\n",
       " 'mxnet-od-ssd-512-mobilenet1-0-voc',\n",
       " 'mxnet-od-ssd-512-resnet50-v1-coco',\n",
       " 'mxnet-od-ssd-512-resnet50-v1-voc',\n",
       " 'mxnet-od-ssd-512-vgg16-atrous-coco',\n",
       " 'mxnet-od-ssd-512-vgg16-atrous-voc',\n",
       " 'mxnet-od-yolo3-darknet53-coco',\n",
       " 'mxnet-od-yolo3-darknet53-voc',\n",
       " 'mxnet-od-yolo3-mobilenet1-0-coco',\n",
       " 'mxnet-od-yolo3-mobilenet1-0-voc',\n",
       " 'mxnet-semseg-fcn-resnet101-ade',\n",
       " 'mxnet-semseg-fcn-resnet101-coco',\n",
       " 'mxnet-semseg-fcn-resnet101-voc',\n",
       " 'mxnet-semseg-fcn-resnet50-ade',\n",
       " 'mxnet-tcembedding-robertafin-base-uncased',\n",
       " 'mxnet-tcembedding-robertafin-base-wiki-uncased',\n",
       " 'mxnet-tcembedding-robertafin-large-uncased',\n",
       " 'mxnet-tcembedding-robertafin-large-wiki-uncased',\n",
       " 'pytorch-eqa-bert-base-cased',\n",
       " 'pytorch-eqa-bert-base-multilingual-cased',\n",
       " 'pytorch-eqa-bert-base-multilingual-uncased',\n",
       " 'pytorch-eqa-bert-base-uncased',\n",
       " 'pytorch-eqa-bert-large-cased',\n",
       " 'pytorch-eqa-bert-large-cased-whole-word-masking',\n",
       " 'pytorch-eqa-bert-large-cased-whole-word-masking-finetuned-squad',\n",
       " 'pytorch-eqa-bert-large-uncased',\n",
       " 'pytorch-eqa-bert-large-uncased-whole-word-masking',\n",
       " 'pytorch-eqa-bert-large-uncased-whole-word-masking-finetuned-squad',\n",
       " 'pytorch-eqa-distilbert-base-cased',\n",
       " 'pytorch-eqa-distilbert-base-multilingual-cased',\n",
       " 'pytorch-eqa-distilbert-base-uncased',\n",
       " 'pytorch-eqa-distilroberta-base',\n",
       " 'pytorch-eqa-roberta-base',\n",
       " 'pytorch-eqa-roberta-base-openai-detector',\n",
       " 'pytorch-eqa-roberta-large',\n",
       " 'pytorch-eqa-roberta-large-openai-detector',\n",
       " 'pytorch-ic-alexnet',\n",
       " 'pytorch-ic-densenet121',\n",
       " 'pytorch-ic-densenet161',\n",
       " 'pytorch-ic-densenet169',\n",
       " 'pytorch-ic-densenet201',\n",
       " 'pytorch-ic-googlenet',\n",
       " 'pytorch-ic-mobilenet-v2',\n",
       " 'pytorch-ic-resnet101',\n",
       " 'pytorch-ic-resnet152',\n",
       " 'pytorch-ic-resnet18',\n",
       " 'pytorch-ic-resnet34',\n",
       " 'pytorch-ic-resnet50',\n",
       " 'pytorch-ic-resnext101-32x8d',\n",
       " 'pytorch-ic-resnext50-32x4d',\n",
       " 'pytorch-ic-shufflenet-v2-x1-0',\n",
       " 'pytorch-ic-squeezenet1-0',\n",
       " 'pytorch-ic-squeezenet1-1',\n",
       " 'pytorch-ic-vgg11',\n",
       " 'pytorch-ic-vgg11-bn',\n",
       " 'pytorch-ic-vgg13',\n",
       " 'pytorch-ic-vgg13-bn',\n",
       " 'pytorch-ic-vgg16',\n",
       " 'pytorch-ic-vgg16-bn',\n",
       " 'pytorch-ic-vgg19',\n",
       " 'pytorch-ic-vgg19-bn',\n",
       " 'pytorch-ic-wide-resnet101-2',\n",
       " 'pytorch-ic-wide-resnet50-2',\n",
       " 'pytorch-od-nvidia-ssd',\n",
       " 'pytorch-od1-fasterrcnn-mobilenet-v3-large-320-fpn',\n",
       " 'pytorch-od1-fasterrcnn-mobilenet-v3-large-fpn',\n",
       " 'pytorch-od1-fasterrcnn-resnet50-fpn',\n",
       " 'pytorch-tabtransformerclassification-model',\n",
       " 'pytorch-tabtransformerregression-model',\n",
       " 'pytorch-textgeneration1-alexa20b',\n",
       " 'sklearn-classification-linear',\n",
       " 'sklearn-classification-snowflake',\n",
       " 'sklearn-regression-linear',\n",
       " 'sklearn-regression-snowflake',\n",
       " 'tensorflow-audioembedding-frill-1',\n",
       " 'tensorflow-audioembedding-trill-3',\n",
       " 'tensorflow-audioembedding-trill-distilled-3',\n",
       " 'tensorflow-audioembedding-trillsson1-1',\n",
       " 'tensorflow-audioembedding-trillsson2-1',\n",
       " 'tensorflow-audioembedding-trillsson3-1',\n",
       " 'tensorflow-ic-bit-m-r101x1-ilsvrc2012-classification-1',\n",
       " 'tensorflow-ic-bit-m-r101x1-imagenet21k-classification-1',\n",
       " 'tensorflow-ic-bit-m-r101x3-ilsvrc2012-classification-1',\n",
       " 'tensorflow-ic-bit-m-r101x3-imagenet21k-classification-1',\n",
       " 'tensorflow-ic-bit-m-r152x4-ilsvrc2012',\n",
       " 'tensorflow-ic-bit-m-r152x4-imagenet21k',\n",
       " 'tensorflow-ic-bit-m-r50x1-ilsvrc2012-classification-1',\n",
       " 'tensorflow-ic-bit-m-r50x1-imagenet21k-classification-1',\n",
       " 'tensorflow-ic-bit-m-r50x3-ilsvrc2012-classification-1',\n",
       " 'tensorflow-ic-bit-m-r50x3-imagenet21k-classification-1',\n",
       " 'tensorflow-ic-bit-s-r101x1-ilsvrc2012-classification-1',\n",
       " 'tensorflow-ic-bit-s-r101x3-ilsvrc2012-classification-1',\n",
       " 'tensorflow-ic-bit-s-r152x4-ilsvrc2012',\n",
       " 'tensorflow-ic-bit-s-r50x1-ilsvrc2012-classification-1',\n",
       " 'tensorflow-ic-bit-s-r50x3-ilsvrc2012-classification-1',\n",
       " 'tensorflow-ic-cait-m36-384',\n",
       " 'tensorflow-ic-cait-m48-448',\n",
       " 'tensorflow-ic-cait-s24-224',\n",
       " 'tensorflow-ic-cait-s24-384',\n",
       " 'tensorflow-ic-cait-s36-384',\n",
       " 'tensorflow-ic-cait-xs24-384',\n",
       " 'tensorflow-ic-cait-xxs24-224',\n",
       " 'tensorflow-ic-cait-xxs24-384',\n",
       " 'tensorflow-ic-cait-xxs36-224',\n",
       " 'tensorflow-ic-cait-xxs36-384',\n",
       " 'tensorflow-ic-deit-base-distilled-patch16-224',\n",
       " 'tensorflow-ic-deit-base-distilled-patch16-384',\n",
       " 'tensorflow-ic-deit-base-patch16-224',\n",
       " 'tensorflow-ic-deit-base-patch16-384',\n",
       " 'tensorflow-ic-deit-small-distilled-patch16-224',\n",
       " 'tensorflow-ic-deit-small-patch16-224',\n",
       " 'tensorflow-ic-deit-tiny-distilled-patch16-224',\n",
       " 'tensorflow-ic-deit-tiny-patch16-224',\n",
       " 'tensorflow-ic-efficientnet-b0-classification-1',\n",
       " 'tensorflow-ic-efficientnet-b1-classification-1',\n",
       " 'tensorflow-ic-efficientnet-b2-classification-1',\n",
       " 'tensorflow-ic-efficientnet-b3-classification-1',\n",
       " 'tensorflow-ic-efficientnet-b4-classification-1',\n",
       " 'tensorflow-ic-efficientnet-b5-classification-1',\n",
       " 'tensorflow-ic-efficientnet-b6-classification-1',\n",
       " 'tensorflow-ic-efficientnet-b7-classification-1',\n",
       " 'tensorflow-ic-efficientnet-lite0-classification-2',\n",
       " 'tensorflow-ic-efficientnet-lite1-classification-2',\n",
       " 'tensorflow-ic-efficientnet-lite2-classification-2',\n",
       " 'tensorflow-ic-efficientnet-lite3-classification-2',\n",
       " 'tensorflow-ic-efficientnet-lite4-classification-2',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet1k-b0',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet1k-b1',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet1k-b2',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet1k-b3',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet1k-l',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet1k-m',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet1k-s',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-b0',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-b1',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-b2',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-b3',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-b0',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-b1',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-b2',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-b3',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-l',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-m',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-s',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-xl',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-l',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-m',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-s',\n",
       " 'tensorflow-ic-efficientnet-v2-imagenet21k-xl',\n",
       " 'tensorflow-ic-imagenet-inception-resnet-v2-classification-4',\n",
       " 'tensorflow-ic-imagenet-inception-v1-classification-4',\n",
       " 'tensorflow-ic-imagenet-inception-v2-classification-4',\n",
       " 'tensorflow-ic-imagenet-inception-v3-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-025-128-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-025-160-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-025-192-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-025-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-050-128-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-050-160-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-050-192-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-050-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-075-128-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-075-160-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-075-192-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-075-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-100-128-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-100-160-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-100-192-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v1-100-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-035-128',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-035-160',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-035-192',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-035-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-035-96',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-050-128',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-050-160',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-050-192',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-050-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-050-96',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-075-128',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-075-160',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-075-192',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-075-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-075-96',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-100-160',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-100-192',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-100-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-100-96',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-130-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v2-140-224-classification-4',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v3-large-075-224',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v3-large-100-224',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v3-small-075-224',\n",
       " 'tensorflow-ic-imagenet-mobilenet-v3-small-100-224',\n",
       " 'tensorflow-ic-imagenet-nasnet-large',\n",
       " 'tensorflow-ic-imagenet-nasnet-mobile',\n",
       " 'tensorflow-ic-imagenet-pnasnet-large',\n",
       " 'tensorflow-ic-imagenet-resnet-v1-101-classification-4',\n",
       " 'tensorflow-ic-imagenet-resnet-v1-152-classification-4',\n",
       " 'tensorflow-ic-imagenet-resnet-v1-50-classification-4',\n",
       " 'tensorflow-ic-imagenet-resnet-v2-101-classification-4',\n",
       " 'tensorflow-ic-imagenet-resnet-v2-152-classification-4',\n",
       " 'tensorflow-ic-imagenet-resnet-v2-50-classification-4',\n",
       " 'tensorflow-ic-resnet-50-classification-1',\n",
       " 'tensorflow-ic-swin-base-patch4-window12-384',\n",
       " 'tensorflow-ic-swin-base-patch4-window7-224',\n",
       " 'tensorflow-ic-swin-large-patch4-window12-384',\n",
       " 'tensorflow-ic-swin-large-patch4-window7-224',\n",
       " 'tensorflow-ic-swin-s3-base-224',\n",
       " 'tensorflow-ic-swin-s3-small-224',\n",
       " 'tensorflow-ic-swin-s3-tiny-224',\n",
       " 'tensorflow-ic-swin-small-patch4-window7-224',\n",
       " 'tensorflow-ic-swin-tiny-patch4-window7-224',\n",
       " 'tensorflow-ic-tf2-preview-inception-v3-classification-4',\n",
       " 'tensorflow-ic-tf2-preview-mobilenet-v2-classification-4',\n",
       " 'tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1',\n",
       " 'tensorflow-icembedding-bit-m-r101x3-imagenet21k-featurevector-1',\n",
       " 'tensorflow-icembedding-bit-m-r101x3-imagenet21k-fv-1',\n",
       " 'tensorflow-icembedding-bit-m-r50x1-ilsvrc2012-featurevector-1',\n",
       " 'tensorflow-icembedding-bit-m-r50x3-imagenet21k-featurevector-1',\n",
       " 'tensorflow-icembedding-bit-s-r101x1-ilsvrc2012-featurevector-1',\n",
       " 'tensorflow-icembedding-bit-s-r101x3-ilsvrc2012-featurevector-1',\n",
       " 'tensorflow-icembedding-bit-s-r50x1-ilsvrc2012-featurevector-1',\n",
       " 'tensorflow-icembedding-bit-s-r50x3-ilsvrc2012-featurevector-1',\n",
       " 'tensorflow-icembedding-efficientnet-b0-featurevector-1',\n",
       " 'tensorflow-icembedding-efficientnet-b1-featurevector-1',\n",
       " 'tensorflow-icembedding-efficientnet-b2-featurevector-1',\n",
       " 'tensorflow-icembedding-efficientnet-b3-featurevector-1',\n",
       " 'tensorflow-icembedding-efficientnet-b6-featurevector-1',\n",
       " 'tensorflow-icembedding-efficientnet-lite0-featurevector-2',\n",
       " 'tensorflow-icembedding-efficientnet-lite1-featurevector-2',\n",
       " 'tensorflow-icembedding-efficientnet-lite2-featurevector-2',\n",
       " 'tensorflow-icembedding-efficientnet-lite3-featurevector-2',\n",
       " 'tensorflow-icembedding-efficientnet-lite4-featurevector-2',\n",
       " 'tensorflow-icembedding-imagenet-inception-v1-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-inception-v2-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-inception-v3-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-025-128-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-025-128-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-025-160-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-025-160-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-025-192-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-025-192-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-025-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-025-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-050-128-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-050-128-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-050-160-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-050-160-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-050-192-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-050-192-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-050-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-050-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-075-128-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-075-128-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-075-160-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-075-160-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-075-192-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-075-192-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-075-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-075-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-100-128-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-100-128-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-100-160-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-100-160-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-100-192-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-100-192-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-100-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v1-100-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-035-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-035-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-050-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-050-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-075-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-075-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-100-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-100-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-130-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-130-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-140-224-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-mobilenet-v2-140-224-fv-4',\n",
       " 'tensorflow-icembedding-imagenet-resnet-v1-101-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-resnet-v1-152-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-resnet-v1-50-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-resnet-v2-101-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-resnet-v2-152-featurevector-4',\n",
       " 'tensorflow-icembedding-imagenet-resnet-v2-50-featurevector-4',\n",
       " 'tensorflow-icembedding-resnet-50-featurevector-1',\n",
       " 'tensorflow-icembedding-tf2-preview-inception-v3-featurevector-4',\n",
       " 'tensorflow-icembedding-tf2-preview-inception-v3-fv-4',\n",
       " 'tensorflow-icembedding-tf2-preview-mobilenet-v2-featurevector-4',\n",
       " 'tensorflow-icembedding-tf2-preview-mobilenet-v2-fv-4',\n",
       " 'tensorflow-od-centernet-hourglass-1024x1024-1',\n",
       " 'tensorflow-od-centernet-hourglass-1024x1024-kpts-1',\n",
       " 'tensorflow-od-centernet-hourglass-512x512-1',\n",
       " 'tensorflow-od-centernet-hourglass-512x512-kpts-1',\n",
       " 'tensorflow-od-centernet-resnet101v1-fpn-512x512-1',\n",
       " 'tensorflow-od-centernet-resnet50v1-fpn-512x512-1',\n",
       " 'tensorflow-od-centernet-resnet50v1-fpn-512x512-kpts-1',\n",
       " 'tensorflow-od-centernet-resnet50v2-512x512-1',\n",
       " 'tensorflow-od-centernet-resnet50v2-512x512-kpts-1',\n",
       " 'tensorflow-od-efficientdet-d0-1',\n",
       " 'tensorflow-od-efficientdet-d1-1',\n",
       " 'tensorflow-od-efficientdet-d2-1',\n",
       " 'tensorflow-od-efficientdet-d3-1',\n",
       " 'tensorflow-od-efficientdet-d4-1',\n",
       " 'tensorflow-od-efficientdet-d5-1',\n",
       " 'tensorflow-od-faster-rcnn-inception-resnet-v2-1024x1024-1',\n",
       " 'tensorflow-od-faster-rcnn-inception-resnet-v2-640x640-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet101-v1-1024x1024-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet101-v1-640x640-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet101-v1-800x1333-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet152-v1-1024x1024-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet152-v1-640x640-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet152-v1-800x1333-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet50-v1-1024x1024-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet50-v1-640x640-1',\n",
       " 'tensorflow-od-faster-rcnn-resnet50-v1-800x1333-1',\n",
       " 'tensorflow-od-retinanet-resnet101-v1-fpn-1024x1024-1',\n",
       " 'tensorflow-od-retinanet-resnet101-v1-fpn-640x640-1',\n",
       " 'tensorflow-od-retinanet-resnet152-v1-fpn-1024x1024-1',\n",
       " 'tensorflow-od-retinanet-resnet152-v1-fpn-640x640-1',\n",
       " 'tensorflow-od-retinanet-resnet50-v1-fpn-1024x1024-1',\n",
       " 'tensorflow-od-retinanet-resnet50-v1-fpn-640x640-1',\n",
       " 'tensorflow-od-ssd-mobilenet-v1-fpn-640x640-1',\n",
       " 'tensorflow-od-ssd-mobilenet-v2-2',\n",
       " 'tensorflow-od-ssd-mobilenet-v2-fpnlite-320x320-1',\n",
       " 'tensorflow-od-ssd-mobilenet-v2-fpnlite-640x640-1',\n",
       " 'tensorflow-od1-ssd-efficientdet-d0-512x512-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-efficientdet-d1-640x640-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-efficientdet-d2-768x768-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-efficientdet-d3-896x896-coco17-tpu-32',\n",
       " 'tensorflow-od1-ssd-mobilenet-v1-fpn-640x640-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-mobilenet-v2-fpnlite-320x320-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-mobilenet-v2-fpnlite-640x640-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-resnet101-v1-fpn-1024x1024-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-resnet101-v1-fpn-640x640-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-resnet152-v1-fpn-1024x1024-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-resnet152-v1-fpn-640x640-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-resnet50-v1-fpn-1024x1024-coco17-tpu-8',\n",
       " 'tensorflow-od1-ssd-resnet50-v1-fpn-640x640-coco17-tpu-8',\n",
       " 'tensorflow-spc-bert-en-cased-L-12-H-768-A-12-2',\n",
       " 'tensorflow-spc-bert-en-uncased-L-12-H-768-A-12-2',\n",
       " 'tensorflow-spc-bert-en-uncased-L-24-H-1024-A-16-2',\n",
       " 'tensorflow-spc-bert-en-wwm-cased-L-24-H-1024-A-16-2',\n",
       " 'tensorflow-spc-bert-en-wwm-uncased-L-24-H-1024-A-16-2',\n",
       " 'tensorflow-spc-bert-multi-cased-L-12-H-768-A-12-2',\n",
       " 'tensorflow-spc-electra-base-1',\n",
       " 'tensorflow-spc-electra-small-1',\n",
       " 'tensorflow-spc-experts-bert-pubmed-1',\n",
       " 'tensorflow-spc-experts-bert-wiki-books-1',\n",
       " 'tensorflow-tc-albert-en-base',\n",
       " 'tensorflow-tc-bert-en-cased-L-12-H-768-A-12-2',\n",
       " 'tensorflow-tc-bert-en-cased-L-24-H-1024-A-16-2',\n",
       " 'tensorflow-tc-bert-en-uncased-L-12-H-768-A-12-2',\n",
       " 'tensorflow-tc-bert-en-uncased-L-24-H-1024-A-16-2',\n",
       " 'tensorflow-tc-bert-en-wwm-cased-L-24-H-1024-A-16-2',\n",
       " 'tensorflow-tc-bert-en-wwm-uncased-L-24-H-1024-A-16-2',\n",
       " 'tensorflow-tc-bert-multi-cased-L-12-H-768-A-12-2',\n",
       " 'tensorflow-tc-electra-base-1',\n",
       " 'tensorflow-tc-electra-small-1',\n",
       " 'tensorflow-tc-experts-bert-pubmed-1',\n",
       " 'tensorflow-tc-experts-bert-wiki-books-1',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-10-H-128-A-2',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-10-H-256-A-4',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-10-H-512-A-8',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-10-H-768-A-12',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-12-H-128-A-2',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-12-H-256-A-4',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-12-H-512-A-8',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-12-H-768-A-12',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-2-H-128-A-2',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-2-H-256-A-4',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-2-H-512-A-8',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-2-H-768-A-12',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-4-H-128-A-2',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-4-H-256-A-4',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-4-H-512-A-8',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-4-H-768-A-12',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-6-H-128-A-2',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-6-H-256-A-4',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-6-H-512-A-8',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-6-H-768-A-12',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-8-H-128-A-2',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-8-H-256-A-4',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-8-H-512-A-8',\n",
       " 'tensorflow-tc-small-bert-bert-en-uncased-L-8-H-768-A-12',\n",
       " 'tensorflow-tc-talking-heads-base',\n",
       " 'tensorflow-tc-talking-heads-large',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-10-H-128-A-2-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-10-H-256-A-4-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-10-H-512-A-8-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-10-H-768-A-12-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-12-H-128-A-2-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-12-H-256-A-4',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-12-H-512-A-8-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-4',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-2-H-128-A-2-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-2-H-256-A-4',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-2-H-512-A-8-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-2-H-768-A-12-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-4-H-128-A-2-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-4-H-256-A-4-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-4-H-512-A-8-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-4-H-768-A-12-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-6-H-128-A-2-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-6-H-256-A-4',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-6-H-512-A-8-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-6-H-768-A-12-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-8-H-256-A-4-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-8-H-512-A-8-2',\n",
       " 'tensorflow-tcembedding-bert-en-uncased-L-8-H-768-A-12-2',\n",
       " 'tensorflow-tcembedding-bert-wiki-books-mnli-2',\n",
       " 'tensorflow-tcembedding-bert-wiki-books-sst2',\n",
       " 'tensorflow-tcembedding-talkheads-ggelu-bert-en-base-2',\n",
       " 'tensorflow-tcembedding-talkheads-ggelu-bert-en-large-2',\n",
       " 'tensorflow-tcembedding-universal-sentc-encoder-cmlm-en-base-1',\n",
       " 'tensorflow-tcembedding-universal-sentc-encoder-cmlm-en-large-1',\n",
       " 'tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-base-1',\n",
       " 'tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-large-1',\n",
       " 'xgboost-classification-model',\n",
       " 'xgboost-classification-snowflake',\n",
       " 'xgboost-regression-model',\n",
       " 'xgboost-regression-snowflake']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ipywidgets import Dropdown\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "# Retrieves all Text-to-Image generation models.\n",
    "filter_value = \"task == inpainting\"\n",
    "# filter_value = \"task == outpainting\"\n",
    "inpainting_models = list_jumpstart_models(filter=filter_value)\n",
    "inpainting_models = list_jumpstart_models()\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "inpainting_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f32614b-e992-44b6-851b-024952f37889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_id, model_version = \"model-inpainting-stabilityai-stable-diffusion-2-inpainting\", \"*\"\n",
    "model_id, model_version = \"model-inpainting-runwayml-stable-diffusion-inpainting-fp16\", \"1.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193133bc-4d2b-4f07-97f2-d5c74a266e24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'model-inpainting-runwayml-stable-diffusion-inpainting-fp16' with wildcard version identifier '1.*'. You can pin to version '1.1.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-{model_id}\")\n",
    "\n",
    "# Instances with more GPU memory supports generation of larger images.\n",
    "# So, please select instance types such as ml.g5.2xlarge if you want to generate a very large image.\n",
    "inference_instance_type = \"ml.g5.2xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri. This is the base HuggingFace container image for the default model above.\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the model uri. This includes the pre-trained model and parameters as well as the inference scripts.\n",
    "# This includes all dependencies and scripts for model loading, inference handling etc..\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "# Create the SageMaker model instance\n",
    "model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    model_data=model_uri,\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b402a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy_image_uri: \n",
      " 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04\n",
      "model_uri: \n",
      " s3://jumpstart-cache-prod-us-east-1/stabilityai-infer/prepack/v1.0.0/infer-prepack-model-inpainting-runwayml-stable-diffusion-inpainting-fp16.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"deploy_image_uri: \\n\", deploy_image_uri)\n",
    "print(\"model_uri: \\n\", model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648a4772-9b57-4e8b-9ba1-3b30c7a61722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "# deploy the Model. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2dc0ff0-29f2-4fa4-961e-fcfe347acc34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "\n",
    "rekognition = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9044a2f-18b4-4c53-9e9c-2385e8404f4b",
   "metadata": {},
   "source": [
    "# masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daecb7c-f0fc-4317-a72c-a47e21404b19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'portrait_iamge/version1-result.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting (1).ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m portrait_image \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mportrait_iamge/version1-result.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(portrait_image, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m image_file:\n\u001b[1;32m      <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     image_bytes \u001b[39m=\u001b[39m image_file\u001b[39m.\u001b[39mread()\n\u001b[1;32m      <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# 원본 이미지 열기\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'portrait_iamge/version1-result.png'"
     ]
    }
   ],
   "source": [
    "portrait_image = \"portrait_iamge/version1-result.png\"\n",
    "with open(portrait_image, 'rb') as image_file:\n",
    "    image_bytes = image_file.read()\n",
    "    \n",
    "# 원본 이미지 열기\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "width, height = image.size\n",
    "\n",
    "# 마스크 생성 (초기값: 약간의 블러)\n",
    "mask = Image.new(mode=\"RGB\", size=(width, height), color=(255,255,255))  # 배경을 약간 흐리게 하기 위해 220으로 설정\n",
    "draw = ImageDraw.Draw(mask)\n",
    "\n",
    "# Rekognition으로 얼굴 감지\n",
    "response = rekognition.detect_faces(\n",
    "    Image={'Bytes': image_bytes},\n",
    "    Attributes=['DEFAULT']\n",
    ")\n",
    "\n",
    "# 각 얼굴에 대해 처리\n",
    "for face_detail in response['FaceDetails']:\n",
    "    bbox = face_detail['BoundingBox']\n",
    "\n",
    "    # 바운딩 박스 좌표 계산\n",
    "    left = int(bbox['Left'] * width)\n",
    "    top = int(bbox['Top'] * height)\n",
    "    right = int((bbox['Left'] + bbox['Width']) * width)\n",
    "    bottom = int((bbox['Top'] + bbox['Height']) * height)\n",
    "\n",
    "    # 얼굴 영역을 검은색으로 채우기\n",
    "    # 패딩을 추가하여 얼굴 주변을 더 자연스럽게 처리\n",
    "    padding = int(min(bbox['Width'], bbox['Height']) * width * 0.1)\n",
    "    draw.rectangle([\n",
    "        left - padding,\n",
    "        top - padding,\n",
    "        right + padding,\n",
    "        bottom + padding\n",
    "    ], fill=(0, 0, 0))\n",
    "\n",
    "# 전체 마스크에 블러 효과 적용\n",
    "mask = mask.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "    \n",
    "mask.save(\"mask.png\", format=\"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e2bc0-9f9e-412d-8aaf-562b5a868935",
   "metadata": {},
   "source": [
    "# inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bf710b-4a41-4d70-a731-56248b5ba620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting (1).ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m accept \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json;jpeg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Note that sending or receiving payload with raw/rgb values may hit default limits for the input payload and the response size.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m query_response \u001b[39m=\u001b[39m query(model_predictor, json\u001b[39m.\u001b[39mdumps(payload)\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m), content_type, accept)\n\u001b[1;32m     <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m generated_images \u001b[39m=\u001b[39m parse_response(query_response)\n\u001b[1;32m     <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# For accept = 'application/json;jpeg' mentioned above, returned image is a jpeg as bytes encoded with base64.b64 encoding.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://msjmjqbruw7hgpw.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/inpainting%20%281%29.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Here, we decode the image and display the image.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query' is not defined"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import random\n",
    "\n",
    "\n",
    "# content_type = 'application/json;jpeg', endpoint expects payload to be a json with the original image and the mask image as bytes encoded with base64.b64 encoding.\n",
    "# To send raw image to the endpoint, you can set content_type = 'application/json' and encoded_image as np.array(PIL.Image.open(input_img_file_name.jpg)).tolist()\n",
    "content_type = \"application/json;jpeg\"\n",
    "\n",
    "portrait_image = \"/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/input_image/01-gonsoo-fall/image.jpg\"\n",
    "mask_iamge = \"/home/sagemaker-user/Self-Study-Generative-AI/05-In-Painting/input_image/01-gonsoo-fall/mask.jpg\"\n",
    "\n",
    "with open(portrait_image, \"rb\") as f:\n",
    "    input_img_image_bytes = f.read()\n",
    "# with open(\"./mask.png\", \"rb\") as f:\n",
    "#     input_img_mask_image_bytes = f.read()\n",
    "with open(mask_iamge, \"rb\") as f:\n",
    "    input_img_mask_image_bytes = f.read()\n",
    "\n",
    "\n",
    "encoded_input_image = base64.b64encode(bytearray(input_img_image_bytes)).decode()\n",
    "encoded_mask = base64.b64encode(bytearray(input_img_mask_image_bytes)).decode()\n",
    "\n",
    "prompt = \"Leonardo da Vinci painting style, In a Renaissance-era studio with an easel and oil painting tools, a man in his thirties gazes straight ahead. The painting style is that of Renaissance oil painting\"\n",
    "\n",
    "payload = {\n",
    "    \"prompt\": prompt,\n",
    "    \"image\": encoded_input_image,\n",
    "    \"mask_image\": encoded_mask,\n",
    "    \"num_inference_steps\": 50,\n",
    "    \"guidance_scale\": 12,\n",
    "    \"seed\": random.randint(0, 10000),\n",
    "    \"negative_prompt\": \"(deformed, distorted, disfigured), bad anatomy, bad proportions, extra limbs, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, mutated, blurry, ugly, oversaturated, grain, low-res, Deformed, bad anatomy, disfigured, poorly drawn face, mutated, extra limb, ugly, poorly drawn hands, missing limb, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, plastic, 3d render, (((duplicate))), ((morbid)), ((mutilated)), extra fingers, mutated hands, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), (((deformed))), ((ugly)), blurry, ((bad anatomy)), (((bad proportions))), ((extra limbs)), cloned face, glitchy, out of frame, gross proportions, (malformed limbs), ((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), mutated hands, (fused fingers), (too many fingers), (((long neck))), low quality, low resolution, artifacts, watermark\",\n",
    "}\n",
    "\n",
    "\n",
    "# For accept = 'application/json;jpeg', endpoint returns the jpeg image as bytes encoded with base64.b64 encoding.\n",
    "# To receive raw image with rgb value set Accept = 'application/json'\n",
    "accept = \"application/json;jpeg\"\n",
    "\n",
    "# Note that sending or receiving payload with raw/rgb values may hit default limits for the input payload and the response size.\n",
    "\n",
    "query_response = query(model_predictor, json.dumps(payload).encode(\"utf-8\"), content_type, accept)\n",
    "generated_images = parse_response(query_response)\n",
    "\n",
    "\n",
    "# For accept = 'application/json;jpeg' mentioned above, returned image is a jpeg as bytes encoded with base64.b64 encoding.\n",
    "# Here, we decode the image and display the image.\n",
    "for generated_image in generated_images:\n",
    "    generated_image_decoded = BytesIO(base64.b64decode(generated_image.encode()))\n",
    "    generated_image_rgb = Image.open(generated_image_decoded).convert(\"RGB\")\n",
    "    # You can save the generated image by calling generated_image_rgb.save('inpainted_image.jpg')\n",
    "    display_img_and_prompt(generated_image_rgb, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf6cc8-1071-4466-9671-f03177a4217d",
   "metadata": {},
   "source": [
    "# (test) bedrock - titan inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd09c0b-c3ed-4a25-b988-3e34f98fe3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "class ImageError(Exception):\n",
    "    \"Custom exception for errors returned by Amazon Titan Image Generator G1\"\n",
    "\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def generate_image(model_id, body):\n",
    "    \"\"\"\n",
    "    Generate an image using Amazon Titan Image Generator G1 model on demand.\n",
    "    Args:\n",
    "        model_id (str): The model ID to use.\n",
    "        body (str) : The request body to use.\n",
    "    Returns:\n",
    "        image_bytes (bytes): The image generated by the model.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\n",
    "        \"Generating image with Amazon Titan Image Generator G1 model %s\", model_id)\n",
    "\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=model_id, accept=accept, contentType=content_type\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    base64_image = response_body.get(\"images\")[0]\n",
    "    base64_bytes = base64_image.encode('ascii')\n",
    "    image_bytes = base64.b64decode(base64_bytes)\n",
    "\n",
    "    finish_reason = response_body.get(\"error\")\n",
    "\n",
    "    if finish_reason is not None:\n",
    "        raise ImageError(f\"Image generation error. Error is {finish_reason}\")\n",
    "\n",
    "    logger.info(\n",
    "        \"Successfully generated image with Amazon Titan Image Generator G1 model %s\", model_id)\n",
    "\n",
    "    return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e4838-5402-4519-9dc7-a865b97f8c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./source.png\", 'rb') as image_file:\n",
    "    image_bytes = image_file.read()\n",
    "    \n",
    "# 원본 이미지 열기\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "width, height = image.size\n",
    "\n",
    "mask = Image.new('L', (width, height), 255)\n",
    "draw = ImageDraw.Draw(mask)\n",
    "\n",
    "# Rekognition으로 얼굴 감지\n",
    "response = rekognition.detect_faces(\n",
    "    Image={'Bytes': image_bytes},\n",
    "    Attributes=['DEFAULT']\n",
    ")\n",
    "\n",
    "# 감지된 각 얼굴에 대해 마스크 생성\n",
    "for face_detail in response['FaceDetails']:\n",
    "    bbox = face_detail['BoundingBox']\n",
    "\n",
    "    # 바운딩 박스 좌표 계산\n",
    "    left = int(bbox['Left'] * width)\n",
    "    top = int(bbox['Top'] * height)\n",
    "    right = int((bbox['Left'] + bbox['Width']) * width)\n",
    "    bottom = int((bbox['Top'] + bbox['Height']) * height)\n",
    "\n",
    "    # 얼굴 영역을 검은색으로 채우기\n",
    "    draw.rectangle([left, top, right, bottom], fill=0)\n",
    "    \n",
    "mask.save(\"mask.png\", format=\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c870ed7-a071-4e02-8624-5b6fef85195d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "    model_id = 'amazon.titan-image-generator-v2:0'\n",
    "\n",
    "    # Read image and mask image from file and encode as base64 strings.\n",
    "    with open(\"./source.png\", \"rb\") as image_file:\n",
    "        input_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "    with open(\"./mask.png\", \"rb\") as mask_image_file:\n",
    "        input_mask_image = base64.b64encode(\n",
    "            mask_image_file.read()).decode('utf8')\n",
    "\n",
    "    body = json.dumps({\n",
    "        \"taskType\": \"OUTPAINTING\",\n",
    "        \"outPaintingParams\": {\n",
    "            \"text\": \"In front of the Eiffel Tower in Paris, wearing a beret and holding a baguette, warm sunset, romantic atmosphere, 8k quality\",\n",
    "            \"negativeText\": \"bad quality, low res\",\n",
    "            \"image\": input_image,\n",
    "            \"maskImage\": input_mask_image,\n",
    "            \"outPaintingMode\": \"DEFAULT\"\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"height\": 1408,\n",
    "            \"width\": 640,\n",
    "            \"cfgScale\": 7.5\n",
    "        }\n",
    "    }\n",
    "    )\n",
    "\n",
    "    image_bytes = generate_image(model_id=model_id,\n",
    "                                 body=body)\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image.show()\n",
    "\n",
    "except ClientError as err:\n",
    "    message = err.response[\"Error\"][\"Message\"]\n",
    "    logger.error(\"A client error occurred: %s\", message)\n",
    "    print(\"A client error occured: \" +\n",
    "          format(message))\n",
    "except ImageError as err:\n",
    "    logger.error(err.message)\n",
    "    print(err.message)\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        f\"Finished generating image with Amazon Titan Image Generator G1 model {model_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695504ac-5107-437d-af3a-53493ed562ba",
   "metadata": {},
   "source": [
    "# (Test2) rekognition -> semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac643e89-3c79-4e3d-a693-384926ef8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "s3_bucket = f\"jumpstart-cache-prod-{region}\"\n",
    "key_prefix = \"inference-notebook-assets\"\n",
    "s3 = boto3.client(\"s3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0347e-7a5e-451d-8ccd-5abdf2620168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def query_endpoint(input_img):\n",
    "    endpoint_name = 'jumpstart-dft-mx-semseg-fcn-resnet1-20241025-011704'\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/x-image', Body=input_img, Accept='application/json;verbose')\n",
    "    return response\n",
    "\n",
    "def parse_seg_response(query_response):\n",
    "    response_dict = json.loads(query_response['Body'].read())\n",
    "    return response_dict['predictions'],response_dict['labels'], response_dict['image_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325bc4b-9fb4-4250-9292-be0eb1f58a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_jpg = \"source5.png\"\n",
    "\n",
    "with open(img_jpg, 'rb') as file: input_img = file.read()\n",
    "\n",
    "try:\n",
    "    query_response = query_endpoint(input_img)\n",
    "except Exception as e:\n",
    "    if e.response['Error']['Code'] == 'ModelError':\n",
    "        raise Exception(\n",
    "             \"Backend scripts have been updated in Feb '22 to standardize response \"\n",
    "             \"format of endpoint response.\"\n",
    "             \"Previous endpoints may not support verbose response type used in this notebook.\"\n",
    "             f\"To use this notebook, please launch the endpoint again. Error: {e}.\"\n",
    "        )\n",
    "    else:\n",
    "        raise\n",
    "try:\n",
    "    predictions, labels, image_labels =  parse_seg_response(query_response)\n",
    "except (TypeError, KeyError) as e:\n",
    "    raise Exception(\n",
    "          \"Backend scripts have been updated in Feb '22 to standardize response \"\n",
    "          \"format of endpoint response.\"\n",
    "           \"Response from previous endpoints not consistent with this notebook.\"\n",
    "           f\"To use this notebook, please launch the endpoint again. Error: {e}.\"\n",
    "   )\n",
    "print('Objects present in the picture:',image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fd0d8-b719-42d8-af3c-d2bb850681c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getvocpallete(num_cls):\n",
    "    # 이진 팔레트 생성 (검은색과 흰색만 사용)\n",
    "    pallete = [0] * (num_cls * 3)\n",
    "    \n",
    "    # 배경(255)은 흰색으로 설정\n",
    "    pallete[255*3:255*3+3] = [255, 255, 255]\n",
    "    \n",
    "    # person 클래스(15)는 검은색으로 설정 - 이미 0으로 초기화되어 있음\n",
    "    # pallete[15*3:15*3+3] = [0, 0, 0]\n",
    "    \n",
    "    return pallete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1a248-d70e-4838-bddf-4f320f95adcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pallete = getvocpallete(256)\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "npimg = np.array(predictions)\n",
    "npimg[npimg != 15] = 255\n",
    "npimg[npimg == -1] = 255\n",
    "mask = Image.fromarray(npimg.astype('uint8'))\n",
    "mask.putpalette(pallete)\n",
    "print(mask.size)\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039e4ab-df27-4bf2-ba47-1893eb305bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cropped = mask.crop((0, 0, 512, 512))\n",
    "cropped.save(\"mask.png\")\n",
    "cropped.show()\n",
    "\n",
    "# cropped + mask된 이미지를 다시 stable diffusion 또는 bedrock 으로.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
