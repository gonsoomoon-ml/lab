+ export NCCL_DEBUG=WARN
+ NCCL_DEBUG=WARN
+ export FI_PROVIDER=efa
+ FI_PROVIDER=efa
+ export 'NCCL_SOCKET_IFNAME=^lo,docker0,veth_def_agent'
+ NCCL_SOCKET_IFNAME='^lo,docker0,veth_def_agent'
+ export NCCL_IGNORE_DISABLED_P2P=1
+ NCCL_IGNORE_DISABLED_P2P=1
+ export TORCH_NCCL_ASYNC_ERROR_HANDLING=1
+ TORCH_NCCL_ASYNC_ERROR_HANDLING=1
+ export TORCH_DIST_INIT_BARRIER=1
+ TORCH_DIST_INIT_BARRIER=1
+ export CUDA_DEVICE_MAX_CONNECTIONS=1
+ CUDA_DEVICE_MAX_CONNECTIONS=1
++ head -n 1 /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b/hostname
+ MASTER_ADDR=ip-10-1-107-242
++ cut -d : -f 1
+++ hostname
++ grep -nx -o '\bip-10-1-97-113\b' /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b/hostname
+ NODEID=3
+ NNODES=4
+ PROCESSES_PER_NODE=8
+ MASTER_PORT=41000
+ DISTRIBUTED_ARGS='--nproc_per_node 8 --nnodes 4 --rdzv_endpoint=ip-10-1-107-242 --rdzv_id=100 --rdzv_backend=c10d'
++ hostname
+ LAUNCHER_HOSTNAME=ip-10-1-97-113
+ mkdir -p /fsx/ubuntu/tmp
+ GIT_CLONE_DIR=/fsx/ubuntu/tmp/ip-10-1-97-113
+ [[ -d /fsx/ubuntu/tmp/ip-10-1-97-113 ]]
+ git clone https://github.com/aws/sagemaker-hyperpod-training-adapter-for-nemo.git /fsx/ubuntu/tmp/ip-10-1-97-113
Cloning into '/fsx/ubuntu/tmp/ip-10-1-97-113'...
+ GIT_CLONE_DIR=/fsx/ubuntu/tmp/ip-10-1-97-113/
+ cd /fsx/ubuntu/tmp/ip-10-1-97-113/
+ rm -rf __pycache__
+ unset SLURM_NTASKS
+ torchrun --nproc_per_node 8 --nnodes 4 --rdzv_endpoint=ip-10-1-107-242 --rdzv_id=100 --rdzv_backend=c10d examples/llama/llama_pretrain.py --config-path=/fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b --config-name=hf-llama3-2-1b_hydra.yaml
+ export NCCL_DEBUG=WARN
+ NCCL_DEBUG=WARN
+ export FI_PROVIDER=efa
+ FI_PROVIDER=efa
+ export 'NCCL_SOCKET_IFNAME=^lo,docker0,veth_def_agent'
+ NCCL_SOCKET_IFNAME='^lo,docker0,veth_def_agent'
+ export NCCL_IGNORE_DISABLED_P2P=1
+ NCCL_IGNORE_DISABLED_P2P=1
+ export TORCH_NCCL_ASYNC_ERROR_HANDLING=1
+ TORCH_NCCL_ASYNC_ERROR_HANDLING=1
+ export TORCH_DIST_INIT_BARRIER=1
+ TORCH_DIST_INIT_BARRIER=1
+ export CUDA_DEVICE_MAX_CONNECTIONS=1
+ CUDA_DEVICE_MAX_CONNECTIONS=1
++ head -n 1 /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b/hostname
+ MASTER_ADDR=ip-10-1-107-242
++ cut -d : -f 1
+++ hostname
++ grep -nx -o '\bip-10-1-67-233\b' /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b/hostname
+ NODEID=2
+ NNODES=4
+ PROCESSES_PER_NODE=8
+ MASTER_PORT=41000
+ DISTRIBUTED_ARGS='--nproc_per_node 8 --nnodes 4 --rdzv_endpoint=ip-10-1-107-242 --rdzv_id=100 --rdzv_backend=c10d'
++ hostname
+ LAUNCHER_HOSTNAME=ip-10-1-67-233
+ mkdir -p /fsx/ubuntu/tmp
+ GIT_CLONE_DIR=/fsx/ubuntu/tmp/ip-10-1-67-233
+ [[ -d /fsx/ubuntu/tmp/ip-10-1-67-233 ]]
+ git clone https://github.com/aws/sagemaker-hyperpod-training-adapter-for-nemo.git /fsx/ubuntu/tmp/ip-10-1-67-233
Cloning into '/fsx/ubuntu/tmp/ip-10-1-67-233'...
+ export NCCL_DEBUG=WARN
+ NCCL_DEBUG=WARN
+ export FI_PROVIDER=efa
+ FI_PROVIDER=efa
+ export 'NCCL_SOCKET_IFNAME=^lo,docker0,veth_def_agent'
+ NCCL_SOCKET_IFNAME='^lo,docker0,veth_def_agent'
+ export NCCL_IGNORE_DISABLED_P2P=1
+ NCCL_IGNORE_DISABLED_P2P=1
+ export TORCH_NCCL_ASYNC_ERROR_HANDLING=1
+ TORCH_NCCL_ASYNC_ERROR_HANDLING=1
+ export TORCH_DIST_INIT_BARRIER=1
+ TORCH_DIST_INIT_BARRIER=1
+ export CUDA_DEVICE_MAX_CONNECTIONS=1
+ CUDA_DEVICE_MAX_CONNECTIONS=1
++ head -n 1 /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b/hostname
+ MASTER_ADDR=ip-10-1-107-242
++ cut -d : -f 1
+++ hostname
++ grep -nx -o '\bip-10-1-24-129\b' /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b/hostname
+ NODEID=1
+ NNODES=4
+ PROCESSES_PER_NODE=8
+ MASTER_PORT=41000
+ DISTRIBUTED_ARGS='--nproc_per_node 8 --nnodes 4 --rdzv_endpoint=ip-10-1-107-242 --rdzv_id=100 --rdzv_backend=c10d'
++ hostname
+ LAUNCHER_HOSTNAME=ip-10-1-24-129
+ mkdir -p /fsx/ubuntu/tmp
+ GIT_CLONE_DIR=/fsx/ubuntu/tmp/ip-10-1-24-129
+ [[ -d /fsx/ubuntu/tmp/ip-10-1-24-129 ]]
+ git clone https://github.com/aws/sagemaker-hyperpod-training-adapter-for-nemo.git /fsx/ubuntu/tmp/ip-10-1-24-129
Cloning into '/fsx/ubuntu/tmp/ip-10-1-24-129'...
+ GIT_CLONE_DIR=/fsx/ubuntu/tmp/ip-10-1-67-233/
+ cd /fsx/ubuntu/tmp/ip-10-1-67-233/
+ rm -rf __pycache__
+ unset SLURM_NTASKS
+ torchrun --nproc_per_node 8 --nnodes 4 --rdzv_endpoint=ip-10-1-107-242 --rdzv_id=100 --rdzv_backend=c10d examples/llama/llama_pretrain.py --config-path=/fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b --config-name=hf-llama3-2-1b_hydra.yaml
+ GIT_CLONE_DIR=/fsx/ubuntu/tmp/ip-10-1-24-129/
+ cd /fsx/ubuntu/tmp/ip-10-1-24-129/
+ rm -rf __pycache__
+ unset SLURM_NTASKS
+ torchrun --nproc_per_node 8 --nnodes 4 --rdzv_endpoint=ip-10-1-107-242 --rdzv_id=100 --rdzv_backend=c10d examples/llama/llama_pretrain.py --config-path=/fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b --config-name=hf-llama3-2-1b_hydra.yaml
W0222 13:48:31.778000 140686344320256 torch/distributed/run.py:779] 
W0222 13:48:31.778000 140686344320256 torch/distributed/run.py:779] *****************************************
W0222 13:48:31.778000 140686344320256 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0222 13:48:31.778000 140686344320256 torch/distributed/run.py:779] *****************************************
W0222 13:48:32.380000 140164295124224 torch/distributed/run.py:779] 
W0222 13:48:32.380000 140164295124224 torch/distributed/run.py:779] *****************************************
W0222 13:48:32.380000 140164295124224 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0222 13:48:32.380000 140164295124224 torch/distributed/run.py:779] *****************************************
W0222 13:48:32.601000 139851237541120 torch/distributed/run.py:779] 
W0222 13:48:32.601000 139851237541120 torch/distributed/run.py:779] *****************************************
W0222 13:48:32.601000 139851237541120 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0222 13:48:32.601000 139851237541120 torch/distributed/run.py:779] *****************************************
+ export NCCL_DEBUG=WARN
+ NCCL_DEBUG=WARN
+ export FI_PROVIDER=efa
+ FI_PROVIDER=efa
+ export 'NCCL_SOCKET_IFNAME=^lo,docker0,veth_def_agent'
+ NCCL_SOCKET_IFNAME='^lo,docker0,veth_def_agent'
+ export NCCL_IGNORE_DISABLED_P2P=1
+ NCCL_IGNORE_DISABLED_P2P=1
+ export TORCH_NCCL_ASYNC_ERROR_HANDLING=1
+ TORCH_NCCL_ASYNC_ERROR_HANDLING=1
+ export TORCH_DIST_INIT_BARRIER=1
+ TORCH_DIST_INIT_BARRIER=1
+ export CUDA_DEVICE_MAX_CONNECTIONS=1
+ CUDA_DEVICE_MAX_CONNECTIONS=1
++ head -n 1 /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b/hostname
+ MASTER_ADDR=ip-10-1-107-242
++ cut -d : -f 1
+++ hostname
++ grep -nx -o '\bip-10-1-107-242\b' /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b/hostname
+ NODEID=0
+ NNODES=4
+ PROCESSES_PER_NODE=8
+ MASTER_PORT=41000
+ DISTRIBUTED_ARGS='--nproc_per_node 8 --nnodes 4 --rdzv_endpoint=ip-10-1-107-242 --rdzv_id=100 --rdzv_backend=c10d'
++ hostname
+ LAUNCHER_HOSTNAME=ip-10-1-107-242
+ mkdir -p /fsx/ubuntu/tmp
+ GIT_CLONE_DIR=/fsx/ubuntu/tmp/ip-10-1-107-242
+ [[ -d /fsx/ubuntu/tmp/ip-10-1-107-242 ]]
+ git clone https://github.com/aws/sagemaker-hyperpod-training-adapter-for-nemo.git /fsx/ubuntu/tmp/ip-10-1-107-242
Cloning into '/fsx/ubuntu/tmp/ip-10-1-107-242'...
+ GIT_CLONE_DIR=/fsx/ubuntu/tmp/ip-10-1-107-242/
+ cd /fsx/ubuntu/tmp/ip-10-1-107-242/
+ rm -rf __pycache__
+ unset SLURM_NTASKS
+ torchrun --nproc_per_node 8 --nnodes 4 --rdzv_endpoint=ip-10-1-107-242 --rdzv_id=100 --rdzv_backend=c10d examples/llama/llama_pretrain.py --config-path=/fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b --config-name=hf-llama3-2-1b_hydra.yaml
W0222 13:48:51.655000 139693095666944 torch/distributed/run.py:779] 
W0222 13:48:51.655000 139693095666944 torch/distributed/run.py:779] *****************************************
W0222 13:48:51.655000 139693095666944 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0222 13:48:51.655000 139693095666944 torch/distributed/run.py:779] *****************************************
[2025-02-22 13:48:57.301: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:473: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:497: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
      @custom_bwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:521: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:527: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
      @custom_bwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:536: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:542: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
      @custom_bwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:549: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:558: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
      @custom_bwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:565: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:570: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
      @custom_bwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:581: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:48:57 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/utils.py:600: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
      @custom_bwd
    
[2025-02-22 13:48:57.311: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.316: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.353: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.384: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.399: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.405: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.437: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.459: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.477: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.484: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.487: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.493: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.494: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.497: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.512: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.514: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.515: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.526: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.532: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.533: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.540: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.551: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.555: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.560: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.562: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.566: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.577: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.585: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.595: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.605: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[2025-02-22 13:48:57.618: W torch/sagemaker/state_handler.py:46] Disabling Torch compile for using torch.sagemaker
[NeMo W 2025-02-22 13:49:08 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/tensor_parallel/layers.py:278: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:49:08 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/tensor_parallel/layers.py:294: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
      @custom_bwd
    
[NeMo W 2025-02-22 13:49:08 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/tensor_parallel/layers.py:389: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:49:08 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/tensor_parallel/layers.py:428: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
      @custom_bwd
    
[NeMo W 2025-02-22 13:49:08 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/embedding.py:193: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
[NeMo W 2025-02-22 13:49:08 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/embedding.py:258: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
      @custom_fwd
    
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
[NeMo W 2025-02-22 13:49:09 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/dist_checkpointing/strategies/torch.py:22: DeprecationWarning: `torch.distributed._sharded_tensor` will be deprecated, use `torch.distributed._shard.sharded_tensor` instead
      from torch.distributed._sharded_tensor import ShardedTensor as TorchShardedTensor
    
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
[NeMo W 2025-02-22 13:49:10 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/models/gpt/gpt_layer_specs.py:41: UserWarning: Apex is not installed. Falling back to Torch LayerNorm
      warnings.warn(f'Apex is not installed. Falling back to Torch LayerNorm')
    
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
[NeMo W 2025-02-22 13:49:10 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/models/retro/encoder_spec.py:47: UserWarning: Apex is not installed. Falling back to Torch LayerNorm
      warnings.warn(f'Apex is not installed. Falling back to Torch LayerNorm')
    
[NeMo W 2025-02-22 13:49:10 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/models/retro/decoder_spec.py:39: UserWarning: Apex is not installed. Falling back to Torch LayerNorm
      warnings.warn(f'Apex is not installed. Falling back to Torch LayerNorm')
    
[NeMo W 2025-02-22 13:49:10 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/megatron/core/models/T5/t5_spec.py:46: UserWarning: Apex is not installed. Falling back to Torch LayerNorm
      warnings.warn(f'Apex is not installed. Falling back to Torch LayerNorm')
    
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
`zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
[NeMo I 2025-02-22 13:49:14 nemo_logging:381] 
    
    ************** Experiment configuration ***********
[NeMo I 2025-02-22 13:49:14 nemo_logging:381] 
    name:
    - hf_llama_8b
    use_smp_model: true
    distributed_backend: nccl
    log_perf_metrics: false
    model:
      model_type: llama_v3
      train_batch_size: 2
      val_batch_size: 1
      fsdp: true
      moe: false
      activation_checkpointing: false
      activation_loading_horizon: 1
      delayed_param: true
      offload_activations: false
      seed: 12345
      grad_clip: 1.0
      sharding_strategy: hybrid_shard
      forward_prefetch: true
      shard_degree: 8
      backward_fetch_policy: backward_pre
      auto_wrap_policy: transformer_auto_wrap_policy
      limit_all_gathers: false
      use_orig_param: true
      context_parallel_degree: 1
      tensor_model_parallel_degree: 1
      expert_model_parallel_degree: 1
      max_context_width: 8192
      max_position_embeddings: 8192
      num_hidden_layers: 16
      hidden_size: 2048
      num_attention_heads: 32
      intermediate_size: 8192
      initializer_range: 0.02
      layernorm_epsilon: 1.0e-05
      vocab_size: 128256
      num_key_value_heads: 8
      use_flash_attention: true
      sliding_window: null
      use_sliding_window: null
      max_window_layers: null
      rms_norm_eps: null
      rope_theta: 500000.0
      multi_modal: false
      tie_word_embeddings: true
      num_experts_per_tok: null
      num_local_experts: null
      moe_load_balancing: sinkhorn
      global_token_shuffle: null
      moe_all_to_all_dispatcher: null
      fp8: false
      fp8_amax_history_len: 1024
      fp8_amax_compute_algo: max
      do_finetune: false
      hf_model_name_or_path: null
      hf_access_token: null
      precision: bf16
      lr_decay_iters: 50
      log_reduced_training_loss: true
      optim:
        name: adamw
        lr: 0.0001
        weight_decay: 0.01
        betas:
        - 0.9
        - 0.95
        sched:
          name: CosineAnnealing
          warmup_steps: 0
          constant_steps: 0
          min_lr: 1.0e-06
      data:
        train_dir: ''
        val_dir: ''
        dataset_type: hf
        use_synthetic_data: true
      gpu_affinity:
        enabled: true
      nsys_profile:
        enabled: false
        start_step: 10
        end_step: 10
        ranks:
        - 0
        gen_shape: false
      viztracer:
        enabled: false
        ranks:
        - 0
        tracer_entries: 1000000
        verbose: 1
        max_stack_depth: -1
        ignore_c_function: true
        ignore_frozen: true
        log_func_retval: false
        log_func_args: false
        log_print: false
        log_gc: false
        log_sparse: false
        log_async: false
        log_audit: null
        pid_suffix: false
        file_info: true
        register_global: true
        trace_self: false
        min_duration: 200
        minimize_memory: false
        dump_raw: false
        sanitize_function_name: false
        output_file: null
      peft:
        peft_type: null
        rank: 32
        alpha: 16.0
        dropout: 0.1
        target_modules: null
      rope_scaling:
        rope_type: llama3
        factor: 32.0
        high_freq_factor: 4.0
        low_freq_factor: 1.0
        original_max_position_embeddings: 8192
      nvte_attn_backend: null
    trainer:
      devices: 8
      num_nodes: 4
      accelerator: gpu
      precision: bf16
      max_steps: 50
      log_every_n_steps: 1
      val_check_interval: 1
      limit_val_batches: 0
    exp_manager:
      exp_dir: ''
      name: experiment
      explicit_log_dir: null
      create_tensorboard_logger: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        save_top_k: 0
        every_n_train_steps: 10
        monitor: step
        mode: max
        save_last: false
      export_full_model:
        every_n_train_steps: 0
        save_last: true
        final_export_dir: null
      checkpoint_dir: /checkpoints/
      resume_from_checkpoint: null
      auto_checkpoint:
        enabled: false
        warmup_steps: 12
        drop_n_warmup_steps: 3
    run:
      name: hf-llama3-2-1b
      results_dir: /fsx/ubuntu/sagemaker-hyperpod-recipes/results/hf-llama3-2-1b
      time_limit: 6-00:00:00
    
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[NeMo I 2025-02-22 13:49:14 nemo_logging:381] Experiments will be logged at experiment/2025-02-22_13-49-14
[NeMo I 2025-02-22 13:49:14 nemo_logging:381] TensorboardLogger has been set up
You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/32
Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/32
[W222 13:49:20.560613353 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/32
[W222 13:49:20.344235141 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/32
[W222 13:49:20.305451640 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/32
[W222 13:49:20.363724752 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/32
[W222 13:49:20.949101807 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/32
[W222 13:49:20.597252096 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/32
[W222 13:49:21.063109062 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/32
[W222 13:49:21.175352365 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/32
[W222 13:49:21.216989479 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/32
[W222 13:49:21.821067954 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/32
[W222 13:49:21.669802447 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/32
[W222 13:49:21.494603642 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/32
[W222 13:49:21.858910391 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/32
[W222 13:49:22.302262473 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/32
[W222 13:49:22.263905947 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/32
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/32
[W222 13:49:22.130315183 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/32
[W222 13:49:22.186970185 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W222 13:49:22.154454869 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/32
[W222 13:49:22.240995558 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/32
[W222 13:49:22.505414018 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/32
Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/32
[W222 13:49:22.393889318 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W222 13:49:22.460149750 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/32
[W222 13:49:22.758112439 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/32
[W222 13:49:23.900350215 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/32
[W222 13:49:23.167114037 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/32
[W222 13:49:23.037586185 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/32
[W222 13:49:23.592248188 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/32
[W222 13:49:23.140899528 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/32
[W222 13:49:23.692460532 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/32
Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/32
[W222 13:49:23.734210015 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W222 13:49:23.737343419 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W222 13:49:23.208834212 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 32 processes
----------------------------------------------------------------------------------------------------

[2025-02-22 13:49:23.853: I torch/sagemaker/state_handler.py:223] Sizes (pp, rep, sdp, tp, ep, cp, world) = (1, None, 8, 1, 1, 1, 32).
NCCL version 2.21.5+cuda12.1
[2025-02-22 13:49:26.428: I hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py:132] Overriding model config with {'vocab_size': 128256, 'hidden_size': 2048, 'intermediate_size': 8192, 'num_hidden_layers': 16, 'num_attention_heads': 32, 'max_position_embeddings': 8192, 'initializer_range': 0.02, 'num_key_value_heads': 8, 'rms_norm_eps': 1e-05, 'rope_theta': 500000.0, 'delayed_param': True, 'rope_scaling': {'rope_type': 'llama3', 'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192}}
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[2025-02-22 13:49:26.697: I torch/sagemaker/tensor_parallel/parallelize.py:82] Created transformed model
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in LlamaModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
[2025-02-22 13:49:27.186: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.186: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.186: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.187: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[NeMo I 2025-02-22 13:49:27 nemo_logging:381] Using FSDP plugin with auto_wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7f2873f8b560>, transformer_layer_cls=(<class 'torch.sagemaker.tensor_parallel.transformer.TransformerLayer'>,))
[2025-02-22 13:49:27.189: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.188: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.189: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.189: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.190: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.192: I torch/sagemaker/utils/process_group_utils.py:107] Shard groups: `[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]`.
[2025-02-22 13:49:27.197: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.197: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.197: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.197: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.197: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.197: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.197: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.198: I torch/sagemaker/utils/process_group_utils.py:100] Repli groups: `[[0, 8, 16, 24], [1, 9, 17, 25], [2, 10, 18, 26], [3, 11, 19, 27], [4, 12, 20, 28], [5, 13, 21, 29], [6, 14, 22, 30], [7, 15, 23, 31]]`.
[2025-02-22 13:49:27.301: I torch/sagemaker/utils/utils.py:52] [ 0] Runtime is     0.1129 seconds: FSDP constructor.
[NeMo I 2025-02-22 13:49:27 nemo_logging:381] Optimizer config = AdamW (
    Parameter Group 0
        amsgrad: False
        betas: [0.9, 0.95]
        capturable: False
        differentiable: False
        eps: 1e-08
        foreach: None
        fused: None
        lr: 0.0001
        maximize: False
        weight_decay: 0.01
    )
[NeMo I 2025-02-22 13:49:27 nemo_logging:381] Scheduler "<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f27d41025d0>" 
    will be used during training (effective maximum steps = 50) - 
    Parameters : 
    (warmup_steps: 0
    constant_steps: 0
    min_lr: 1.0e-06
    max_steps: 50
    )
[NeMo I 2025-02-22 13:49:27 nemo_logging:381] Training Model:
    FullyShardedDataParallel(
      (_fsdp_wrapped_module): TransformerLMHead(
        (word_embedding): DistributedEmbedding(128256, 2048)
        (dropout): Dropout(p=0.0, inplace=False)
        (transformer): Transformer(
          (seq_layers): ModuleList(
            (0-15): 16 x FullyShardedDataParallel(
              (_fsdp_wrapped_module): TransformerLayer(
                (layer): TransformerLayer(
                  (self_attention): MultiheadAttention(
                    (layernorm_qkv): LayerNormLinear()
                    (core_attention): DotProductAttention(
                      (flash_attention): FlashAttention()
                      (fused_attention): FusedAttention()
                      (unfused_attention): UnfusedDotProductAttention(
                        (scale_mask_softmax): FusedScaleMaskSoftmax()
                        (attention_dropout): Dropout(p=0.0, inplace=False)
                      )
                    )
                    (proj): Linear()
                  )
                  (layernorm_mlp): LayerNormMLP()
                )
                (rotary): PatchedRotaryPositionEmbedding()
              )
            )
          )
        )
        (layernorm): RMSNorm()
        (ce_loss): DistributedCrossEntropy()
        (lm_head): Linear(in_features=2048, out_features=128256, bias=False)
      )
    )

  | Name  | Type                     | Params | Mode 
-----------------------------------------------------------
0 | model | FullyShardedDataParallel | 187 M  | train
-----------------------------------------------------------
187 M     Trainable params
0         Non-trainable params
187 M     Total params
749.241   Total estimated model params size (MB)
[NeMo W 2025-02-22 13:49:28 nemo_logging:393] /opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=2` in the `DataLoader` to improve performance.
    
NCCL version 2.21.5+cuda12.1
NCCL version 2.21.5+cuda12.1
NCCL version 2.21.5+cuda12.1
Error executing job with overrides: []
[rank18]: Traceback (most recent call last):
[rank18]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 43, in <module>
[rank18]:     main()
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank18]:     _run_hydra(
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank18]:     _run_app(
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank18]:     run_and_report(
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank18]:     raise ex
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank18]:     return func()
[rank18]:            ^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank18]:     lambda: hydra.run(
[rank18]:             ^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank18]:     _ = ret.return_value
[rank18]:         ^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank18]:     raise self._return_value
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank18]:     ret.return_value = task_function(task_cfg)
[rank18]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank18]:     return fn(merged_config, *args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 38, in main
[rank18]:     train(cfg)
[rank18]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 32, in train
[rank18]:     trainer.fit(model_module, datamodule=data_module)
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank18]:     call._call_and_handle_interrupt(
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank18]:     return trainer_fn(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank18]:     self._run(model, ckpt_path=ckpt_path)
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank18]:     results = self._run_stage()
[rank18]:               ^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank18]:     self.fit_loop.run()
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank18]:     self.advance()
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank18]:     self.epoch_loop.run(self._data_fetcher)
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank18]:     self.advance(data_fetcher)
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank18]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank18]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank18]:     self._optimizer_step(batch_idx, closure)
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank18]:     call._call_lightning_module_hook(
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank18]:     output = fn(*args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank18]:     optimizer.step(closure=optimizer_closure)
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank18]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank18]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank18]:     super().optimizer_step(*a, **kw)
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank18]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank18]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank18]:     return optimizer.step(closure=closure, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank18]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank18]:     out = func(*args, **kwargs)
[rank18]:           ^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank18]:     ret = func(self, *args, **kwargs)
[rank18]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank18]:     loss = closure()
[rank18]:            ^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank18]:     closure_result = closure()
[rank18]:                      ^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank18]:     self._result = self.closure(*args, **kwargs)
[rank18]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank18]:     return func(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank18]:     step_output = self._step_fn()
[rank18]:                   ^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank18]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank18]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank18]:     output = fn(*args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank18]:     return self.lightning_module.training_step(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank18]:     output_dict = wrapped(*args, **kwargs)
[rank18]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank18]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank18]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank18]:     return self(
[rank18]:            ^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank18]:     return forward_call(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank18]:     return self.model(*a, **kw)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank18]:     return forward_call(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank18]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank18]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank18]:     module_outputs = super().__call__(
[rank18]:                      ^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank18]:     return forward_call(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank18]:     lm_logits = self.lm_head(hidden_states)
[rank18]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank18]:     return self._call_impl(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank18]:     return forward_call(*args, **kwargs)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank18]:     return F.linear(input, self.weight, self.bias)
[rank18]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank18]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 2 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank2]: Traceback (most recent call last):
[rank2]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 43, in <module>
[rank2]:     main()
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank2]:     _run_hydra(
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank2]:     _run_app(
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank2]:     run_and_report(
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank2]:     raise ex
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank2]:     return func()
[rank2]:            ^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank2]:     lambda: hydra.run(
[rank2]:             ^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank2]:     _ = ret.return_value
[rank2]:         ^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank2]:     raise self._return_value
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank2]:     ret.return_value = task_function(task_cfg)
[rank2]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank2]:     return fn(merged_config, *args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 38, in main
[rank2]:     train(cfg)
[rank2]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 32, in train
[rank2]:     trainer.fit(model_module, datamodule=data_module)
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank2]:     return trainer_fn(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank2]:     results = self._run_stage()
[rank2]:               ^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank2]:     self.advance()
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank2]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank2]:     self._optimizer_step(batch_idx, closure)
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank2]:     call._call_lightning_module_hook(
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank2]:     optimizer.step(closure=optimizer_closure)
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank2]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank2]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank2]:     super().optimizer_step(*a, **kw)
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank2]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank2]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank2]:     return optimizer.step(closure=closure, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank2]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank2]:     out = func(*args, **kwargs)
[rank2]:           ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank2]:     ret = func(self, *args, **kwargs)
[rank2]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank2]:     loss = closure()
[rank2]:            ^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank2]:     closure_result = closure()
[rank2]:                      ^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:                   ^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank2]:     return self.lightning_module.training_step(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank2]:     output_dict = wrapped(*args, **kwargs)
[rank2]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank2]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank2]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank2]:     return self(
[rank2]:            ^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank2]:     return self.model(*a, **kw)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank2]:     module_outputs = super().__call__(
[rank2]:                      ^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank2]:     lm_logits = self.lm_head(hidden_states)
[rank2]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank2]:     return F.linear(input, self.weight, self.bias)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 2 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
[rank3]: Traceback (most recent call last):
[rank3]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 43, in <module>
[rank3]:     main()
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank3]:     _run_hydra(
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank3]:     _run_app(
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank3]:     run_and_report(
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank3]:     raise ex
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank3]:     return func()
[rank3]:            ^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank3]:     lambda: hydra.run(
[rank3]:             ^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank3]:     _ = ret.return_value
[rank3]:         ^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank3]:     raise self._return_value
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank3]:     ret.return_value = task_function(task_cfg)
[rank3]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank3]:     return fn(merged_config, *args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 38, in main
[rank3]:     train(cfg)
[rank3]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 32, in train
[rank3]:     trainer.fit(model_module, datamodule=data_module)
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank3]:     return trainer_fn(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank3]:     results = self._run_stage()
[rank3]:               ^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank3]:     self.advance()
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]: Traceback (most recent call last):
[rank21]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 43, in <module>
[rank21]:     main()
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank21]:     _run_hydra(
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank21]:     _run_app(
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank21]:     run_and_report(
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank21]:     raise ex
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank21]:     return func()
[rank21]:            ^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank21]:     lambda: hydra.run(
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank3]:     self._optimizer_step(batch_idx, closure)
[rank21]:             ^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank21]:     _ = ret.return_value
[rank21]:         ^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank21]:     raise self._return_value
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank21]:     ret.return_value = task_function(task_cfg)
[rank21]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank21]:     return fn(merged_config, *args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 38, in main
[rank21]:     train(cfg)
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank3]:     call._call_lightning_module_hook(
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank3]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank21]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 32, in train
[rank21]:     trainer.fit(model_module, datamodule=data_module)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank21]:     call._call_and_handle_interrupt(
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank21]:     return trainer_fn(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank21]:     self._run(model, ckpt_path=ckpt_path)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank21]:     results = self._run_stage()
[rank21]:               ^^^^^^^^^^^^^^^^^
[rank3]:     super().optimizer_step(*a, **kw)
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank3]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank3]:     return optimizer.step(closure=closure, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank21]:     self.fit_loop.run()
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank21]:     self.advance()
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank21]:     self.epoch_loop.run(self._data_fetcher)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank21]:     self.advance(data_fetcher)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank21]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank21]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank3]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank3]:     out = func(*args, **kwargs)
[rank3]:           ^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank3]:     ret = func(self, *args, **kwargs)
[rank3]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank3]:     loss = closure()
[rank3]:            ^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank3]:     closure_result = closure()
[rank3]:                      ^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank21]:     self._optimizer_step(batch_idx, closure)
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:                   ^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank21]:     call._call_lightning_module_hook(
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank21]:     output = fn(*args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank21]:     optimizer.step(closure=optimizer_closure)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank21]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank21]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank3]:     return self.lightning_module.training_step(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank3]:     output_dict = wrapped(*args, **kwargs)
[rank3]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank3]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank3]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank21]:     super().optimizer_step(*a, **kw)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank21]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank21]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank3]:     return self(
[rank3]:            ^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank3]:     return self.model(*a, **kw)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank21]:     return optimizer.step(closure=closure, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank21]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank21]:     out = func(*args, **kwargs)
[rank21]:           ^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank21]:     ret = func(self, *args, **kwargs)
[rank21]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank21]:     loss = closure()
[rank21]:            ^^^^^^^^^
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank3]:     module_outputs = super().__call__(
[rank3]:                      ^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank21]:     closure_result = closure()
[rank21]:                      ^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank21]:     self._result = self.closure(*args, **kwargs)
[rank21]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank21]:     return func(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank21]:     step_output = self._step_fn()
[rank21]:                   ^^^^^^^^^^^^^^^
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank3]:     lm_logits = self.lm_head(hidden_states)
[rank3]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank21]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank21]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank3]:     return F.linear(input, self.weight, self.bias)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank21]:     output = fn(*args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank21]:     return self.lightning_module.training_step(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank21]:     output_dict = wrapped(*args, **kwargs)
[rank21]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank21]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank21]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 3 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank21]:     return self(
[rank21]:            ^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank21]:     return forward_call(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank21]:     return self.model(*a, **kw)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank5]: Traceback (most recent call last):
[rank5]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 43, in <module>
[rank5]:     main()
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank5]:     _run_hydra(
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank5]:     _run_app(
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank5]:     run_and_report(
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank5]:     raise ex
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank5]:     return func()
[rank5]:            ^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank5]:     lambda: hydra.run(
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank21]:     return forward_call(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank21]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank21]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank21]:     module_outputs = super().__call__(
[rank21]:                      ^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank21]:     return self._call_impl(*args, **kwargs)
[rank5]:             ^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank5]:     _ = ret.return_value
[rank5]:         ^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank5]:     raise self._return_value
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank5]:     ret.return_value = task_function(task_cfg)
[rank5]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank5]:     return fn(merged_config, *args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 38, in main
[rank5]:     train(cfg)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank21]:     return forward_call(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank21]:     lm_logits = self.lm_head(hidden_states)
[rank21]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank21]:     return self._call_impl(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank21]:     return forward_call(*args, **kwargs)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 32, in train
[rank5]:     trainer.fit(model_module, datamodule=data_module)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank5]:     call._call_and_handle_interrupt(
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank5]:     return trainer_fn(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank5]:     self._run(model, ckpt_path=ckpt_path)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank5]:     results = self._run_stage()
[rank5]:               ^^^^^^^^^^^^^^^^^
[rank21]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank5]:     self.fit_loop.run()
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank5]:     self.advance()
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank5]:     self.epoch_loop.run(self._data_fetcher)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank5]:     self.advance(data_fetcher)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank5]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank5]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]:     return F.linear(input, self.weight, self.bias)
[rank21]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank21]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 5 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank5]:     self._optimizer_step(batch_idx, closure)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank5]:     call._call_lightning_module_hook(
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank5]:     output = fn(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank5]:     optimizer.step(closure=optimizer_closure)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank5]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank5]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank5]:     super().optimizer_step(*a, **kw)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank5]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank5]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank5]:     return optimizer.step(closure=closure, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank5]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank5]:     out = func(*args, **kwargs)
[rank5]:           ^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank5]:     ret = func(self, *args, **kwargs)
[rank5]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank5]:     loss = closure()
[rank5]:            ^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank5]:     closure_result = closure()
[rank5]:                      ^^^^^^^^^
[rank17]: Traceback (most recent call last):
[rank17]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 43, in <module>
[rank17]:     main()
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank17]:     _run_hydra(
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank17]:     _run_app(
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank17]:     run_and_report(
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank17]:     raise ex
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank17]:     return func()
[rank17]:            ^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank17]:     lambda: hydra.run(
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank5]:     self._result = self.closure(*args, **kwargs)
[rank5]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank5]:     return func(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank5]:     step_output = self._step_fn()
[rank5]:                   ^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank5]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank5]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:             ^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank17]:     _ = ret.return_value
[rank17]:         ^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank17]:     raise self._return_value
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank17]:     ret.return_value = task_function(task_cfg)
[rank17]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank17]:     return fn(merged_config, *args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 38, in main
[rank17]:     train(cfg)
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank5]:     output = fn(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank5]:     return self.lightning_module.training_step(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank5]:     output_dict = wrapped(*args, **kwargs)
[rank5]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank5]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank5]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 32, in train
[rank17]:     trainer.fit(model_module, datamodule=data_module)
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank17]:     call._call_and_handle_interrupt(
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank17]:     return trainer_fn(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank17]:     self._run(model, ckpt_path=ckpt_path)
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank17]:     results = self._run_stage()
[rank17]:               ^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank5]:     return self(
[rank5]:            ^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank5]:     return self.model(*a, **kw)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank17]:     self.fit_loop.run()
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank17]:     self.advance()
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank17]:     self.epoch_loop.run(self._data_fetcher)
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank17]:     self.advance(data_fetcher)
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank17]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank17]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank5]:     module_outputs = super().__call__(
[rank5]:                      ^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank17]:     self._optimizer_step(batch_idx, closure)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank5]:     lm_logits = self.lm_head(hidden_states)
[rank5]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank17]:     call._call_lightning_module_hook(
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank17]:     output = fn(*args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank17]:     optimizer.step(closure=optimizer_closure)
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank17]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank17]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank5]:     return F.linear(input, self.weight, self.bias)
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank17]:     super().optimizer_step(*a, **kw)
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank17]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank17]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank5]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 5 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank17]:     return optimizer.step(closure=closure, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank17]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank17]:     out = func(*args, **kwargs)
[rank17]:           ^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank17]:     ret = func(self, *args, **kwargs)
[rank17]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank17]:     loss = closure()
[rank17]:            ^^^^^^^^^
Error executing job with overrides: []
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank17]:     closure_result = closure()
[rank17]:                      ^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank17]:     self._result = self.closure(*args, **kwargs)
[rank17]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank17]:     return func(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank17]:     step_output = self._step_fn()
[rank17]:                   ^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank17]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank17]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank17]:     output = fn(*args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank17]:     return self.lightning_module.training_step(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank17]:     output_dict = wrapped(*args, **kwargs)
[rank17]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank17]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank17]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank17]:     return self(
[rank17]:            ^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank17]:     return forward_call(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank17]:     return self.model(*a, **kw)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank17]:     return forward_call(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank17]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank17]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank17]:     module_outputs = super().__call__(
[rank17]:                      ^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank17]:     return forward_call(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank17]:     lm_logits = self.lm_head(hidden_states)
[rank17]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank17]:     return self._call_impl(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank17]:     return forward_call(*args, **kwargs)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank17]:     return F.linear(input, self.weight, self.bias)
[rank17]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank17]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 1 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank4]: Traceback (most recent call last):
[rank4]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 43, in <module>
[rank4]:     main()
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank4]:     _run_hydra(
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank4]:     _run_app(
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank4]:     run_and_report(
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank4]:     raise ex
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank4]:     return func()
[rank4]:            ^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank4]:     lambda: hydra.run(
[rank4]:             ^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank4]:     _ = ret.return_value
[rank4]:         ^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank4]:     raise self._return_value
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank4]:     ret.return_value = task_function(task_cfg)
[rank4]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank4]:     return fn(merged_config, *args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 38, in main
[rank4]:     train(cfg)
[rank4]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 32, in train
[rank4]:     trainer.fit(model_module, datamodule=data_module)
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank4]:     call._call_and_handle_interrupt(
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank4]:     return trainer_fn(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank4]:     self._run(model, ckpt_path=ckpt_path)
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank4]:     results = self._run_stage()
[rank4]:               ^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank4]:     self.fit_loop.run()
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank4]:     self.advance()
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank4]:     self.epoch_loop.run(self._data_fetcher)
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank4]:     self.advance(data_fetcher)
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank4]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank4]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank4]:     self._optimizer_step(batch_idx, closure)
Error executing job with overrides: []
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank4]:     call._call_lightning_module_hook(
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank4]:     output = fn(*args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank4]:     optimizer.step(closure=optimizer_closure)
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank4]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank4]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank4]:     super().optimizer_step(*a, **kw)
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank4]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank4]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank4]:     return optimizer.step(closure=closure, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank4]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank4]:     out = func(*args, **kwargs)
[rank4]:           ^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank4]:     ret = func(self, *args, **kwargs)
[rank4]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank4]:     loss = closure()
[rank4]:            ^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank4]:     closure_result = closure()
[rank4]:                      ^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank4]:     self._result = self.closure(*args, **kwargs)
[rank4]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank4]:     return func(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank4]:     step_output = self._step_fn()
[rank4]:                   ^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank4]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank4]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank4]:     output = fn(*args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank4]:     return self.lightning_module.training_step(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank4]:     output_dict = wrapped(*args, **kwargs)
[rank4]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank4]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank4]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank4]:     return self(
[rank4]:            ^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank4]:     return self.model(*a, **kw)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank4]:     module_outputs = super().__call__(
[rank4]:                      ^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank4]:     lm_logits = self.lm_head(hidden_states)
[rank4]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank4]:     return F.linear(input, self.weight, self.bias)
[rank4]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 4 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
[rank23]: Traceback (most recent call last):
[rank23]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 43, in <module>
[rank23]:     main()
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank23]:     _run_hydra(
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank23]:     _run_app(
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank23]:     run_and_report(
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank23]:     raise ex
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank23]:     return func()
[rank23]:            ^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank23]:     lambda: hydra.run(
[rank23]:             ^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank23]:     _ = ret.return_value
[rank23]:         ^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank23]:     raise self._return_value
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank23]:     ret.return_value = task_function(task_cfg)
[rank23]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank23]:     return fn(merged_config, *args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 38, in main
[rank23]:     train(cfg)
[rank23]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 32, in train
[rank23]:     trainer.fit(model_module, datamodule=data_module)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank23]:     call._call_and_handle_interrupt(
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank23]:     return trainer_fn(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank23]:     self._run(model, ckpt_path=ckpt_path)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank23]:     results = self._run_stage()
[rank23]:               ^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank23]:     self.fit_loop.run()
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank23]:     self.advance()
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank23]:     self.epoch_loop.run(self._data_fetcher)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank23]:     self.advance(data_fetcher)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank23]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank23]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank23]:     self._optimizer_step(batch_idx, closure)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank23]:     call._call_lightning_module_hook(
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank23]:     output = fn(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank23]:     optimizer.step(closure=optimizer_closure)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank23]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank23]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]: Traceback (most recent call last):
[rank7]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 43, in <module>
[rank7]:     main()
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank7]:     _run_hydra(
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank7]:     _run_app(
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank7]:     run_and_report(
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank7]:     raise ex
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank7]:     return func()
[rank7]:            ^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank7]:     lambda: hydra.run(
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank23]:     super().optimizer_step(*a, **kw)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank23]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank23]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank23]:     return optimizer.step(closure=closure, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank23]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank23]:     out = func(*args, **kwargs)
[rank23]:           ^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank23]:     ret = func(self, *args, **kwargs)
[rank23]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank23]:     loss = closure()
[rank23]:            ^^^^^^^^^
[rank7]:             ^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank7]:     _ = ret.return_value
[rank7]:         ^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank7]:     raise self._return_value
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank7]:     ret.return_value = task_function(task_cfg)
[rank7]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank7]:     return fn(merged_config, *args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 38, in main
[rank7]:     train(cfg)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank23]:     closure_result = closure()
[rank23]:                      ^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank23]:     self._result = self.closure(*args, **kwargs)
[rank23]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank23]:     return func(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank23]:     step_output = self._step_fn()
[rank23]:                   ^^^^^^^^^^^^^^^
[rank7]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 32, in train
[rank7]:     trainer.fit(model_module, datamodule=data_module)
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank7]:     call._call_and_handle_interrupt(
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank7]:     return trainer_fn(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank7]:     self._run(model, ckpt_path=ckpt_path)
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank7]:     results = self._run_stage()
[rank7]:               ^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank23]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank23]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank7]:     self.fit_loop.run()
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank7]:     self.advance()
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank7]:     self.epoch_loop.run(self._data_fetcher)
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank7]:     self.advance(data_fetcher)
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank7]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank7]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank23]:     output = fn(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank23]:     return self.lightning_module.training_step(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank23]:     output_dict = wrapped(*args, **kwargs)
[rank23]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank23]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank23]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank7]:     self._optimizer_step(batch_idx, closure)
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank23]:     return self(
[rank23]:            ^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank23]:     return forward_call(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank23]:     return self.model(*a, **kw)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank7]:     call._call_lightning_module_hook(
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank7]:     output = fn(*args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank7]:     optimizer.step(closure=optimizer_closure)
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank7]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank7]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank23]:     return forward_call(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank23]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank23]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank23]:     module_outputs = super().__call__(
[rank23]:                      ^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank7]:     super().optimizer_step(*a, **kw)
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank7]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank7]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank7]:     return optimizer.step(closure=closure, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank23]:     return forward_call(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank23]:     lm_logits = self.lm_head(hidden_states)
[rank23]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank23]:     return self._call_impl(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank23]:     return forward_call(*args, **kwargs)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank7]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank7]:     out = func(*args, **kwargs)
[rank7]:           ^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank7]:     ret = func(self, *args, **kwargs)
[rank7]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank7]:     loss = closure()
[rank7]:            ^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank7]:     closure_result = closure()
[rank7]:                      ^^^^^^^^^
[rank23]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank7]:     self._result = self.closure(*args, **kwargs)
[rank7]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank7]:     return func(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank7]:     step_output = self._step_fn()
[rank7]:                   ^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank7]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank7]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]:     return F.linear(input, self.weight, self.bias)
[rank23]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank23]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 7 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank7]:     output = fn(*args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank7]:     return self.lightning_module.training_step(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank7]:     output_dict = wrapped(*args, **kwargs)
[rank7]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank7]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank7]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error executing job with overrides: []
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank7]:     return self(
[rank7]:            ^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank7]:     return self.model(*a, **kw)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank7]:     module_outputs = super().__call__(
[rank7]:                      ^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank7]:     lm_logits = self.lm_head(hidden_states)
[rank7]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank7]:     return F.linear(input, self.weight, self.bias)
[rank7]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 7 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank20]: Traceback (most recent call last):
[rank20]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 43, in <module>
[rank20]:     main()
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank20]:     _run_hydra(
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank20]:     _run_app(
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank20]:     run_and_report(
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank20]:     raise ex
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank20]:     return func()
[rank20]:            ^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank20]:     lambda: hydra.run(
[rank20]:             ^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank20]:     _ = ret.return_value
[rank20]:         ^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank20]:     raise self._return_value
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank20]:     ret.return_value = task_function(task_cfg)
[rank20]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank20]:     return fn(merged_config, *args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 38, in main
[rank20]:     train(cfg)
[rank20]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 32, in train
[rank20]:     trainer.fit(model_module, datamodule=data_module)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank20]:     call._call_and_handle_interrupt(
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank20]:     return trainer_fn(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank20]:     self._run(model, ckpt_path=ckpt_path)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank20]:     results = self._run_stage()
[rank20]:               ^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank20]:     self.fit_loop.run()
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank20]:     self.advance()
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank20]:     self.epoch_loop.run(self._data_fetcher)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank20]:     self.advance(data_fetcher)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank20]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank20]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank20]:     self._optimizer_step(batch_idx, closure)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank20]:     call._call_lightning_module_hook(
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank20]:     output = fn(*args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank20]:     optimizer.step(closure=optimizer_closure)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank20]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank20]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank20]:     super().optimizer_step(*a, **kw)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank20]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank20]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank20]:     return optimizer.step(closure=closure, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank20]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank20]:     out = func(*args, **kwargs)
[rank20]:           ^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank20]:     ret = func(self, *args, **kwargs)
[rank20]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank20]:     loss = closure()
[rank20]:            ^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank20]:     closure_result = closure()
[rank20]:                      ^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank20]:     self._result = self.closure(*args, **kwargs)
[rank20]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank20]:     return func(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank20]:     step_output = self._step_fn()
[rank20]:                   ^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank20]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank20]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]: Traceback (most recent call last):
[rank6]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 43, in <module>
[rank6]:     main()
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank6]:     _run_hydra(
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank6]:     _run_app(
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank6]:     run_and_report(
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank6]:     raise ex
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank6]:     return func()
[rank6]:            ^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank6]:     lambda: hydra.run(
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank20]:     output = fn(*args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank20]:     return self.lightning_module.training_step(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank20]:     output_dict = wrapped(*args, **kwargs)
[rank20]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank20]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank20]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:             ^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank6]:     _ = ret.return_value
[rank6]:         ^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank6]:     raise self._return_value
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank6]:     ret.return_value = task_function(task_cfg)
[rank6]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank6]:     return fn(merged_config, *args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 38, in main
[rank6]:     train(cfg)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank20]:     return self(
[rank20]:            ^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank20]:     return forward_call(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank20]:     return self.model(*a, **kw)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank6]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 32, in train
[rank6]:     trainer.fit(model_module, datamodule=data_module)
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank6]:     call._call_and_handle_interrupt(
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank6]:     return trainer_fn(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank6]:     self._run(model, ckpt_path=ckpt_path)
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank6]:     results = self._run_stage()
[rank6]:               ^^^^^^^^^^^^^^^^^
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank20]:     return forward_call(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank20]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank20]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank20]:     module_outputs = super().__call__(
[rank20]:                      ^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank20]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank6]:     self.fit_loop.run()
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank6]:     self.advance()
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank6]:     self.epoch_loop.run(self._data_fetcher)
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank6]:     self.advance(data_fetcher)
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank6]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank6]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank20]:     return forward_call(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank20]:     lm_logits = self.lm_head(hidden_states)
[rank20]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank20]:     return self._call_impl(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank20]:     return forward_call(*args, **kwargs)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank6]:     self._optimizer_step(batch_idx, closure)
[rank20]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank6]:     call._call_lightning_module_hook(
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank6]:     output = fn(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank6]:     optimizer.step(closure=optimizer_closure)
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank6]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank6]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank20]:     return F.linear(input, self.weight, self.bias)
[rank20]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank20]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 4 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank6]:     super().optimizer_step(*a, **kw)
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank6]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank6]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank6]:     return optimizer.step(closure=closure, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank6]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank6]:     out = func(*args, **kwargs)
[rank6]:           ^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank6]:     ret = func(self, *args, **kwargs)
[rank6]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank6]:     loss = closure()
[rank6]:            ^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank6]:     closure_result = closure()
[rank6]:                      ^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank6]:     self._result = self.closure(*args, **kwargs)
[rank6]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank6]:     return func(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank6]:     step_output = self._step_fn()
[rank6]:                   ^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank6]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank6]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error executing job with overrides: []
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank6]:     output = fn(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank6]:     return self.lightning_module.training_step(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank6]:     output_dict = wrapped(*args, **kwargs)
[rank6]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank6]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank6]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank6]:     return self(
[rank6]:            ^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank6]:     return self.model(*a, **kw)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank6]:     module_outputs = super().__call__(
[rank6]:                      ^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank19]: Traceback (most recent call last):
[rank19]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 43, in <module>
[rank19]:     main()
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank19]:     _run_hydra(
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank19]:     _run_app(
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank19]:     run_and_report(
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank19]:     raise ex
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank19]:     return func()
[rank19]:            ^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank19]:     lambda: hydra.run(
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank6]:     lm_logits = self.lm_head(hidden_states)
[rank6]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:             ^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank19]:     _ = ret.return_value
[rank19]:         ^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank19]:     raise self._return_value
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank19]:     ret.return_value = task_function(task_cfg)
[rank19]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank19]:     return fn(merged_config, *args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 38, in main
[rank19]:     train(cfg)
[rank6]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank6]:     return F.linear(input, self.weight, self.bias)
[rank19]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 32, in train
[rank19]:     trainer.fit(model_module, datamodule=data_module)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank19]:     call._call_and_handle_interrupt(
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank19]:     return trainer_fn(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank19]:     self._run(model, ckpt_path=ckpt_path)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank19]:     results = self._run_stage()
[rank19]:               ^^^^^^^^^^^^^^^^^
[rank6]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 6 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank19]:     self.fit_loop.run()
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank19]:     self.advance()
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank19]:     self.epoch_loop.run(self._data_fetcher)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank19]:     self.advance(data_fetcher)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank19]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank19]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank19]:     self._optimizer_step(batch_idx, closure)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 43, in <module>
[rank0]:     main()
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank0]:     _run_hydra(
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank0]:     _run_app(
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank0]:     run_and_report(
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank0]:     raise ex
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank0]:     return func()
[rank0]:            ^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank0]:     lambda: hydra.run(
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank19]:     call._call_lightning_module_hook(
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank19]:     output = fn(*args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank19]:     optimizer.step(closure=optimizer_closure)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank19]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank19]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:             ^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank0]:     _ = ret.return_value
[rank0]:         ^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank0]:     raise self._return_value
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank0]:     ret.return_value = task_function(task_cfg)
[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank0]:     return fn(merged_config, *args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 38, in main
[rank0]:     train(cfg)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank19]:     super().optimizer_step(*a, **kw)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank19]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank19]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 32, in train
[rank0]:     trainer.fit(model_module, datamodule=data_module)
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank0]:     return trainer_fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank0]:     results = self._run_stage()
[rank0]:               ^^^^^^^^^^^^^^^^^
[rank19]:     return optimizer.step(closure=closure, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank19]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank19]:     out = func(*args, **kwargs)
[rank19]:           ^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank19]:     ret = func(self, *args, **kwargs)
[rank19]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank19]:     loss = closure()
[rank19]:            ^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank19]:     closure_result = closure()
[rank19]:                      ^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank19]:     self._result = self.closure(*args, **kwargs)
[rank19]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank19]:     return func(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank19]:     step_output = self._step_fn()
[rank19]:                   ^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank19]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank19]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank19]:     output = fn(*args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank19]:     return self.lightning_module.training_step(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank19]:     output_dict = wrapped(*args, **kwargs)
[rank19]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank19]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank19]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:     super().optimizer_step(*a, **kw)
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank0]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:     return optimizer.step(closure=closure, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank19]:     return self(
[rank19]:            ^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank19]:     return forward_call(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank19]:     return self.model(*a, **kw)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank0]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank0]:     ret = func(self, *args, **kwargs)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank0]:     loss = closure()
[rank0]:            ^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank0]:     closure_result = closure()
[rank0]:                      ^^^^^^^^^
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank19]:     return forward_call(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank19]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank19]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank19]:     module_outputs = super().__call__(
[rank19]:                      ^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank19]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:                   ^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank19]:     return forward_call(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank19]:     lm_logits = self.lm_head(hidden_states)
[rank19]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank19]:     return self._call_impl(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank19]:     return forward_call(*args, **kwargs)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank0]:     return self.lightning_module.training_step(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank0]:     output_dict = wrapped(*args, **kwargs)
[rank0]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank0]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank0]:     return self(
[rank0]:            ^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank0]:     return self.model(*a, **kw)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank19]:     return F.linear(input, self.weight, self.bias)
[rank19]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank19]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 3 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank0]:     module_outputs = super().__call__(
[rank0]:                      ^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank0]:     lm_logits = self.lm_head(hidden_states)
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank0]:     return F.linear(input, self.weight, self.bias)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 43, in <module>
[rank1]:     main()
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank1]:     _run_hydra(
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank1]:     _run_app(
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank1]:     run_and_report(
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank1]:     raise ex
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank1]:     return func()
[rank1]:            ^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank1]:     lambda: hydra.run(
[rank1]:             ^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank1]:     _ = ret.return_value
[rank1]:         ^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank1]:     raise self._return_value
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank1]:     ret.return_value = task_function(task_cfg)
[rank1]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank1]:     return fn(merged_config, *args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 38, in main
[rank1]:     train(cfg)
[rank1]:   File "/fsx/ubuntu/tmp/ip-10-1-107-242/examples/llama/llama_pretrain.py", line 32, in train
[rank1]:     trainer.fit(model_module, datamodule=data_module)
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank1]:     return trainer_fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank1]:     results = self._run_stage()
[rank1]:               ^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank1]:     self.advance()
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank16]: Traceback (most recent call last):
[rank16]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 43, in <module>
[rank16]:     main()
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank16]:     _run_hydra(
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank16]:     _run_app(
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank16]:     run_and_report(
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank16]:     raise ex
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank16]:     return func()
[rank16]:            ^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank16]:     lambda: hydra.run(
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank16]:             ^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank16]:     _ = ret.return_value
[rank16]:         ^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank16]:     raise self._return_value
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank16]:     ret.return_value = task_function(task_cfg)
[rank16]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank16]:     return fn(merged_config, *args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 38, in main
[rank16]:     train(cfg)
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank1]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank1]:     self._optimizer_step(batch_idx, closure)
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank1]:     call._call_lightning_module_hook(
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 32, in train
[rank16]:     trainer.fit(model_module, datamodule=data_module)
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank16]:     call._call_and_handle_interrupt(
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank16]:     return trainer_fn(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank16]:     self._run(model, ckpt_path=ckpt_path)
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank16]:     results = self._run_stage()
[rank16]:               ^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank1]:     optimizer.step(closure=optimizer_closure)
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank1]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank1]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank1]:     super().optimizer_step(*a, **kw)
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank1]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank16]:     self.fit_loop.run()
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank16]:     self.advance()
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank16]:     self.epoch_loop.run(self._data_fetcher)
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank16]:     self.advance(data_fetcher)
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank16]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank16]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank1]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank1]:     return optimizer.step(closure=closure, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank1]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank1]:     out = func(*args, **kwargs)
[rank1]:           ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank16]:     self._optimizer_step(batch_idx, closure)
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank1]:     ret = func(self, *args, **kwargs)
[rank1]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank1]:     loss = closure()
[rank1]:            ^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank1]:     closure_result = closure()
[rank1]:                      ^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank16]:     call._call_lightning_module_hook(
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank16]:     output = fn(*args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank16]:     optimizer.step(closure=optimizer_closure)
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank16]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank16]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank1]:     step_output = self._step_fn()
[rank1]:                   ^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank1]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank1]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank1]:     return self.lightning_module.training_step(*args, **kwargs)
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank16]:     super().optimizer_step(*a, **kw)
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank16]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank16]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank1]:     output_dict = wrapped(*args, **kwargs)
[rank1]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank1]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank1]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank1]:     return self(
[rank1]:            ^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:     return optimizer.step(closure=closure, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank16]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank16]:     out = func(*args, **kwargs)
[rank16]:           ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank16]:     ret = func(self, *args, **kwargs)
[rank16]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank16]:     loss = closure()
[rank16]:            ^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank1]:     return self.model(*a, **kw)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank16]:     closure_result = closure()
[rank16]:                      ^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank16]:     self._result = self.closure(*args, **kwargs)
[rank16]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank16]:     return func(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank16]:     step_output = self._step_fn()
[rank16]:                   ^^^^^^^^^^^^^^^
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank1]:     module_outputs = super().__call__(
[rank1]:                      ^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank1]:     lm_logits = self.lm_head(hidden_states)
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank16]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank16]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank16]:     output = fn(*args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank16]:     return self.lightning_module.training_step(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank16]:     output_dict = wrapped(*args, **kwargs)
[rank16]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank16]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank16]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank1]:     return F.linear(input, self.weight, self.bias)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank16]:     return self(
[rank16]:            ^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank16]:     return forward_call(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank16]:     return self.model(*a, **kw)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 1 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank16]:     return forward_call(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank16]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank16]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank16]:     module_outputs = super().__call__(
[rank16]:                      ^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank16]:     return forward_call(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank16]:     lm_logits = self.lm_head(hidden_states)
[rank16]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank16]:     return self._call_impl(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank16]:     return forward_call(*args, **kwargs)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank16]:     return F.linear(input, self.weight, self.bias)
[rank16]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank16]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank22]: Traceback (most recent call last):
[rank22]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 43, in <module>
[rank22]:     main()
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank22]:     _run_hydra(
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank22]:     _run_app(
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank22]:     run_and_report(
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank22]:     raise ex
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank22]:     return func()
[rank22]:            ^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank22]:     lambda: hydra.run(
[rank22]:             ^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank22]:     _ = ret.return_value
[rank22]:         ^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank22]:     raise self._return_value
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank22]:     ret.return_value = task_function(task_cfg)
[rank22]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank22]:     return fn(merged_config, *args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 38, in main
[rank22]:     train(cfg)
[rank22]:   File "/fsx/ubuntu/tmp/ip-10-1-67-233/examples/llama/llama_pretrain.py", line 32, in train
[rank22]:     trainer.fit(model_module, datamodule=data_module)
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank22]:     call._call_and_handle_interrupt(
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank22]:     return trainer_fn(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank22]:     self._run(model, ckpt_path=ckpt_path)
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank22]:     results = self._run_stage()
[rank22]:               ^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank22]:     self.fit_loop.run()
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank22]:     self.advance()
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank22]:     self.epoch_loop.run(self._data_fetcher)
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank22]:     self.advance(data_fetcher)
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank22]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank22]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank22]:     self._optimizer_step(batch_idx, closure)
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank22]:     call._call_lightning_module_hook(
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank22]:     output = fn(*args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank22]:     optimizer.step(closure=optimizer_closure)
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank22]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank22]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank22]:     super().optimizer_step(*a, **kw)
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank22]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank22]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank22]:     return optimizer.step(closure=closure, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank22]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank22]:     out = func(*args, **kwargs)
[rank22]:           ^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank22]:     ret = func(self, *args, **kwargs)
[rank22]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank22]:     loss = closure()
[rank22]:            ^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank22]:     closure_result = closure()
[rank22]:                      ^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank22]:     self._result = self.closure(*args, **kwargs)
[rank22]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank22]:     return func(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank22]:     step_output = self._step_fn()
[rank22]:                   ^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank22]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank22]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank22]:     output = fn(*args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank22]:     return self.lightning_module.training_step(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank22]:     output_dict = wrapped(*args, **kwargs)
[rank22]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank22]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank22]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank22]:     return self(
[rank22]:            ^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank22]:     return forward_call(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank22]:     return self.model(*a, **kw)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank22]:     return forward_call(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank22]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank22]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank22]:     module_outputs = super().__call__(
[rank22]:                      ^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank22]:     return forward_call(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank22]:     lm_logits = self.lm_head(hidden_states)
[rank22]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank22]:     return self._call_impl(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank22]:     return forward_call(*args, **kwargs)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank22]:     return F.linear(input, self.weight, self.bias)
[rank22]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank22]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 6 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank28]: Traceback (most recent call last):
[rank28]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 43, in <module>
[rank28]:     main()
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank28]:     _run_hydra(
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank28]:     _run_app(
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank28]:     run_and_report(
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank28]:     raise ex
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank28]:     return func()
[rank28]:            ^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank28]:     lambda: hydra.run(
[rank28]:             ^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank28]:     _ = ret.return_value
[rank28]:         ^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank28]:     raise self._return_value
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank28]:     ret.return_value = task_function(task_cfg)
[rank28]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank28]:     return fn(merged_config, *args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 38, in main
[rank28]:     train(cfg)
[rank28]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 32, in train
[rank28]:     trainer.fit(model_module, datamodule=data_module)
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank28]:     call._call_and_handle_interrupt(
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank28]:     return trainer_fn(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank28]:     self._run(model, ckpt_path=ckpt_path)
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank28]:     results = self._run_stage()
[rank28]:               ^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank28]:     self.fit_loop.run()
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank28]:     self.advance()
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank28]:     self.epoch_loop.run(self._data_fetcher)
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank28]:     self.advance(data_fetcher)
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank28]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank28]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank28]:     self._optimizer_step(batch_idx, closure)
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank28]:     call._call_lightning_module_hook(
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank28]:     output = fn(*args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank28]:     optimizer.step(closure=optimizer_closure)
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank28]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank28]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank28]:     super().optimizer_step(*a, **kw)
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank28]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank28]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank28]:     return optimizer.step(closure=closure, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank28]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank28]:     out = func(*args, **kwargs)
[rank28]:           ^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank28]:     ret = func(self, *args, **kwargs)
[rank28]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank28]:     loss = closure()
[rank28]:            ^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank28]:     closure_result = closure()
[rank28]:                      ^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank28]:     self._result = self.closure(*args, **kwargs)
[rank28]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank28]:     return func(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank28]:     step_output = self._step_fn()
[rank28]:                   ^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank28]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank28]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank28]:     output = fn(*args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank28]:     return self.lightning_module.training_step(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank28]:     output_dict = wrapped(*args, **kwargs)
[rank28]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank28]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank28]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank28]:     return self(
[rank28]:            ^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank28]:     return forward_call(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank28]:     return self.model(*a, **kw)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank28]:     return forward_call(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank28]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank28]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank28]:     module_outputs = super().__call__(
[rank28]:                      ^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank28]:     return forward_call(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank28]:     lm_logits = self.lm_head(hidden_states)
[rank28]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank28]:     return self._call_impl(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank28]:     return forward_call(*args, **kwargs)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank28]:     return F.linear(input, self.weight, self.bias)
[rank28]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank28]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 4 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank29]: Traceback (most recent call last):
[rank29]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 43, in <module>
[rank29]:     main()
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank29]:     _run_hydra(
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank29]:     _run_app(
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank29]:     run_and_report(
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank29]:     raise ex
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank29]:     return func()
[rank29]:            ^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank29]:     lambda: hydra.run(
[rank29]:             ^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank29]:     _ = ret.return_value
[rank29]:         ^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank29]:     raise self._return_value
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank29]:     ret.return_value = task_function(task_cfg)
[rank29]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank29]:     return fn(merged_config, *args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 38, in main
[rank29]:     train(cfg)
[rank29]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 32, in train
[rank29]:     trainer.fit(model_module, datamodule=data_module)
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank29]:     call._call_and_handle_interrupt(
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank29]:     return trainer_fn(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank29]:     self._run(model, ckpt_path=ckpt_path)
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank29]:     results = self._run_stage()
[rank29]:               ^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank29]:     self.fit_loop.run()
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank29]:     self.advance()
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank29]:     self.epoch_loop.run(self._data_fetcher)
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank29]:     self.advance(data_fetcher)
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank29]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank29]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank29]:     self._optimizer_step(batch_idx, closure)
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank29]:     call._call_lightning_module_hook(
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank29]:     output = fn(*args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank29]:     optimizer.step(closure=optimizer_closure)
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank29]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank29]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank29]:     super().optimizer_step(*a, **kw)
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank29]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank29]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank29]:     return optimizer.step(closure=closure, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank29]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank29]:     out = func(*args, **kwargs)
[rank29]:           ^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank29]:     ret = func(self, *args, **kwargs)
[rank29]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank29]:     loss = closure()
[rank29]:            ^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank29]:     closure_result = closure()
[rank29]:                      ^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank29]:     self._result = self.closure(*args, **kwargs)
[rank29]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank29]:     return func(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank29]:     step_output = self._step_fn()
[rank29]:                   ^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank29]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank29]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank29]:     output = fn(*args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank29]:     return self.lightning_module.training_step(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank29]:     output_dict = wrapped(*args, **kwargs)
[rank29]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank29]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank29]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank29]:     return self(
[rank29]:            ^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank29]:     return forward_call(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank29]:     return self.model(*a, **kw)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank29]:     return forward_call(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank29]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank29]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank29]:     module_outputs = super().__call__(
[rank29]:                      ^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank29]:     return forward_call(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank29]:     lm_logits = self.lm_head(hidden_states)
[rank29]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank29]:     return self._call_impl(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank29]:     return forward_call(*args, **kwargs)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank29]:     return F.linear(input, self.weight, self.bias)
[rank29]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank29]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 5 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
[rank27]: Traceback (most recent call last):
[rank27]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 43, in <module>
[rank27]:     main()
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank27]:     _run_hydra(
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank27]:     _run_app(
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank27]:     run_and_report(
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank27]:     raise ex
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank27]:     return func()
[rank27]:            ^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank27]:     lambda: hydra.run(
[rank27]:             ^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank27]:     _ = ret.return_value
[rank27]:         ^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank27]:     raise self._return_value
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank27]:     ret.return_value = task_function(task_cfg)
[rank27]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank27]:     return fn(merged_config, *args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 38, in main
[rank27]:     train(cfg)
[rank27]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 32, in train
[rank27]:     trainer.fit(model_module, datamodule=data_module)
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank27]:     call._call_and_handle_interrupt(
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank27]:     return trainer_fn(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank27]:     self._run(model, ckpt_path=ckpt_path)
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank27]:     results = self._run_stage()
[rank27]:               ^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank27]:     self.fit_loop.run()
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank27]:     self.advance()
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank27]:     self.epoch_loop.run(self._data_fetcher)
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank27]:     self.advance(data_fetcher)
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank27]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank27]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank27]:     self._optimizer_step(batch_idx, closure)
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank27]:     call._call_lightning_module_hook(
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank27]:     output = fn(*args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank27]:     optimizer.step(closure=optimizer_closure)
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank27]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank27]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank27]:     super().optimizer_step(*a, **kw)
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank27]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank27]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank27]:     return optimizer.step(closure=closure, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank27]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank27]:     out = func(*args, **kwargs)
[rank27]:           ^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank27]:     ret = func(self, *args, **kwargs)
[rank27]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank27]:     loss = closure()
[rank27]:            ^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank27]:     closure_result = closure()
[rank27]:                      ^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank27]:     self._result = self.closure(*args, **kwargs)
[rank27]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank27]:     return func(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank27]:     step_output = self._step_fn()
[rank27]:                   ^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank27]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank27]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank27]:     output = fn(*args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank27]:     return self.lightning_module.training_step(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank27]:     output_dict = wrapped(*args, **kwargs)
[rank27]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank27]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank27]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank27]:     return self(
[rank27]:            ^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank27]:     return forward_call(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank27]:     return self.model(*a, **kw)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank27]:     return forward_call(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank27]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank27]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank27]:     module_outputs = super().__call__(
[rank27]:                      ^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank27]:     return forward_call(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank27]:     lm_logits = self.lm_head(hidden_states)
[rank27]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank27]:     return self._call_impl(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank27]:     return forward_call(*args, **kwargs)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank27]:     return F.linear(input, self.weight, self.bias)
[rank27]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank27]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 3 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
Error executing job with overrides: []
[rank24]: Traceback (most recent call last):
[rank24]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 43, in <module>
[rank24]:     main()
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank24]:     _run_hydra(
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank24]:     _run_app(
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank24]:     run_and_report(
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank24]:     raise ex
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank24]:     return func()
[rank24]:            ^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank24]:     lambda: hydra.run(
[rank24]:             ^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank24]:     _ = ret.return_value
[rank24]:         ^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank24]:     raise self._return_value
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank24]:     ret.return_value = task_function(task_cfg)
[rank24]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank24]:     return fn(merged_config, *args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 38, in main
[rank24]:     train(cfg)
[rank24]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 32, in train
[rank24]:     trainer.fit(model_module, datamodule=data_module)
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank24]:     call._call_and_handle_interrupt(
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank24]:     return trainer_fn(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank24]:     self._run(model, ckpt_path=ckpt_path)
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank24]:     results = self._run_stage()
[rank24]:               ^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank24]:     self.fit_loop.run()
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank24]:     self.advance()
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank24]:     self.epoch_loop.run(self._data_fetcher)
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank24]:     self.advance(data_fetcher)
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank24]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank24]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank24]:     self._optimizer_step(batch_idx, closure)
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank24]:     call._call_lightning_module_hook(
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank24]:     output = fn(*args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank24]:     optimizer.step(closure=optimizer_closure)
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank24]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank24]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank24]:     super().optimizer_step(*a, **kw)
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank24]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank24]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank24]:     return optimizer.step(closure=closure, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank24]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank24]:     out = func(*args, **kwargs)
[rank24]:           ^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank24]:     ret = func(self, *args, **kwargs)
[rank24]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank24]:     loss = closure()
[rank24]:            ^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank24]:     closure_result = closure()
[rank24]:                      ^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank24]:     self._result = self.closure(*args, **kwargs)
[rank24]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank24]:     return func(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank24]:     step_output = self._step_fn()
[rank24]:                   ^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank24]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank24]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank24]:     output = fn(*args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank24]:     return self.lightning_module.training_step(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank24]:     output_dict = wrapped(*args, **kwargs)
[rank24]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank24]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank24]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank24]:     return self(
[rank24]:            ^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank24]:     return forward_call(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank24]:     return self.model(*a, **kw)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank24]:     return forward_call(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank24]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank24]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank24]:     module_outputs = super().__call__(
[rank24]:                      ^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank24]:     return forward_call(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank24]:     lm_logits = self.lm_head(hidden_states)
[rank24]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank24]:     return self._call_impl(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank24]:     return forward_call(*args, **kwargs)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank24]:     return F.linear(input, self.weight, self.bias)
[rank24]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank24]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 21.98 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 20.95 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 129.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank30]: Traceback (most recent call last):
[rank30]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 43, in <module>
[rank30]:     main()
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank30]:     _run_hydra(
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank30]:     _run_app(
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank30]:     run_and_report(
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank30]:     raise ex
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank30]:     return func()
[rank30]:            ^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank30]:     lambda: hydra.run(
[rank30]:             ^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank30]:     _ = ret.return_value
[rank30]:         ^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank30]:     raise self._return_value
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank30]:     ret.return_value = task_function(task_cfg)
[rank30]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank30]:     return fn(merged_config, *args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 38, in main
[rank30]:     train(cfg)
[rank30]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 32, in train
[rank30]:     trainer.fit(model_module, datamodule=data_module)
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank30]:     call._call_and_handle_interrupt(
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank30]:     return trainer_fn(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank30]:     self._run(model, ckpt_path=ckpt_path)
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank30]:     results = self._run_stage()
[rank30]:               ^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank30]:     self.fit_loop.run()
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank30]:     self.advance()
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank30]:     self.epoch_loop.run(self._data_fetcher)
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank30]:     self.advance(data_fetcher)
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank30]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank30]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank30]:     self._optimizer_step(batch_idx, closure)
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank30]:     call._call_lightning_module_hook(
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank30]:     output = fn(*args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank30]:     optimizer.step(closure=optimizer_closure)
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank30]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank30]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank30]:     super().optimizer_step(*a, **kw)
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank30]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank30]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank30]:     return optimizer.step(closure=closure, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank30]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank30]:     out = func(*args, **kwargs)
[rank30]:           ^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank30]:     ret = func(self, *args, **kwargs)
[rank30]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank30]:     loss = closure()
[rank30]:            ^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank30]:     closure_result = closure()
[rank30]:                      ^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank30]:     self._result = self.closure(*args, **kwargs)
[rank30]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank30]:     return func(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank30]:     step_output = self._step_fn()
[rank30]:                   ^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank30]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank30]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank30]:     output = fn(*args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank30]:     return self.lightning_module.training_step(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank30]:     output_dict = wrapped(*args, **kwargs)
[rank30]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank30]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank30]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank30]:     return self(
[rank30]:            ^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank30]:     return forward_call(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank30]:     return self.model(*a, **kw)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank30]:     return forward_call(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank30]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank30]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank30]:     module_outputs = super().__call__(
[rank30]:                      ^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank30]:     return forward_call(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank30]:     lm_logits = self.lm_head(hidden_states)
[rank30]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank30]:     return self._call_impl(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank30]:     return forward_call(*args, **kwargs)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank30]:     return F.linear(input, self.weight, self.bias)
[rank30]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank30]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 6 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank25]: Traceback (most recent call last):
[rank25]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 43, in <module>
[rank25]:     main()
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank25]:     _run_hydra(
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank25]:     _run_app(
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank25]:     run_and_report(
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank25]:     raise ex
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank25]:     return func()
[rank25]:            ^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank25]:     lambda: hydra.run(
[rank25]:             ^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank25]:     _ = ret.return_value
[rank25]:         ^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank25]:     raise self._return_value
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank25]:     ret.return_value = task_function(task_cfg)
[rank25]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank25]:     return fn(merged_config, *args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 38, in main
[rank25]:     train(cfg)
[rank25]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 32, in train
[rank25]:     trainer.fit(model_module, datamodule=data_module)
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank25]:     call._call_and_handle_interrupt(
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank25]:     return trainer_fn(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank25]:     self._run(model, ckpt_path=ckpt_path)
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank25]:     results = self._run_stage()
[rank25]:               ^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank25]:     self.fit_loop.run()
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank25]:     self.advance()
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank25]:     self.epoch_loop.run(self._data_fetcher)
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank25]:     self.advance(data_fetcher)
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank25]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank25]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank25]:     self._optimizer_step(batch_idx, closure)
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank25]:     call._call_lightning_module_hook(
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank25]:     output = fn(*args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank25]:     optimizer.step(closure=optimizer_closure)
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank25]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank25]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank25]:     super().optimizer_step(*a, **kw)
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank25]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank25]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank25]:     return optimizer.step(closure=closure, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank25]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank25]:     out = func(*args, **kwargs)
[rank25]:           ^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank25]:     ret = func(self, *args, **kwargs)
[rank25]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank25]:     loss = closure()
[rank25]:            ^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank25]:     closure_result = closure()
[rank25]:                      ^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank25]:     self._result = self.closure(*args, **kwargs)
[rank25]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank25]:     return func(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank25]:     step_output = self._step_fn()
[rank25]:                   ^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank25]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank25]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank25]:     output = fn(*args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank25]:     return self.lightning_module.training_step(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank25]:     output_dict = wrapped(*args, **kwargs)
[rank25]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank25]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank25]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank25]:     return self(
[rank25]:            ^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank25]:     return forward_call(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank25]:     return self.model(*a, **kw)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank25]:     return forward_call(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank25]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank25]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank25]:     module_outputs = super().__call__(
[rank25]:                      ^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank25]:     return forward_call(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank25]:     lm_logits = self.lm_head(hidden_states)
[rank25]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank25]:     return self._call_impl(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank25]:     return forward_call(*args, **kwargs)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank25]:     return F.linear(input, self.weight, self.bias)
[rank25]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank25]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 1 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank26]: Traceback (most recent call last):
[rank26]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 43, in <module>
[rank26]:     main()
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank26]:     _run_hydra(
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank26]:     _run_app(
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank26]:     run_and_report(
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank26]:     raise ex
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank26]:     return func()
[rank26]:            ^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank26]:     lambda: hydra.run(
[rank26]:             ^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank26]:     _ = ret.return_value
[rank26]:         ^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank26]:     raise self._return_value
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank26]:     ret.return_value = task_function(task_cfg)
[rank26]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank26]:     return fn(merged_config, *args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 38, in main
[rank26]:     train(cfg)
[rank26]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 32, in train
[rank26]:     trainer.fit(model_module, datamodule=data_module)
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank26]:     call._call_and_handle_interrupt(
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank26]:     return trainer_fn(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank26]:     self._run(model, ckpt_path=ckpt_path)
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank26]:     results = self._run_stage()
[rank26]:               ^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank26]:     self.fit_loop.run()
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank26]:     self.advance()
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank26]:     self.epoch_loop.run(self._data_fetcher)
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank26]:     self.advance(data_fetcher)
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank26]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank26]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank26]:     self._optimizer_step(batch_idx, closure)
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank26]:     call._call_lightning_module_hook(
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank26]:     output = fn(*args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank26]:     optimizer.step(closure=optimizer_closure)
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank26]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank26]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank26]:     super().optimizer_step(*a, **kw)
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank26]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank26]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank26]:     return optimizer.step(closure=closure, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank26]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank26]:     out = func(*args, **kwargs)
[rank26]:           ^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank26]:     ret = func(self, *args, **kwargs)
[rank26]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank26]:     loss = closure()
[rank26]:            ^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank26]:     closure_result = closure()
[rank26]:                      ^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank26]:     self._result = self.closure(*args, **kwargs)
[rank26]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank26]:     return func(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank26]:     step_output = self._step_fn()
[rank26]:                   ^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank26]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank26]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank26]:     output = fn(*args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank26]:     return self.lightning_module.training_step(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank26]:     output_dict = wrapped(*args, **kwargs)
[rank26]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank26]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank26]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank26]:     return self(
[rank26]:            ^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank26]:     return forward_call(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank26]:     return self.model(*a, **kw)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank26]:     return forward_call(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank26]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank26]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank26]:     module_outputs = super().__call__(
[rank26]:                      ^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank26]:     return forward_call(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank26]:     lm_logits = self.lm_head(hidden_states)
[rank26]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank26]:     return self._call_impl(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank26]:     return forward_call(*args, **kwargs)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank26]:     return F.linear(input, self.weight, self.bias)
[rank26]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank26]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 2 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank31]: Traceback (most recent call last):
[rank31]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 43, in <module>
[rank31]:     main()
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank31]:     _run_hydra(
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank31]:     _run_app(
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank31]:     run_and_report(
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank31]:     raise ex
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank31]:     return func()
[rank31]:            ^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank31]:     lambda: hydra.run(
[rank31]:             ^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank31]:     _ = ret.return_value
[rank31]:         ^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank31]:     raise self._return_value
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank31]:     ret.return_value = task_function(task_cfg)
[rank31]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank31]:     return fn(merged_config, *args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 38, in main
[rank31]:     train(cfg)
[rank31]:   File "/fsx/ubuntu/tmp/ip-10-1-97-113/examples/llama/llama_pretrain.py", line 32, in train
[rank31]:     trainer.fit(model_module, datamodule=data_module)
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank31]:     call._call_and_handle_interrupt(
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank31]:     return trainer_fn(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank31]:     self._run(model, ckpt_path=ckpt_path)
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank31]:     results = self._run_stage()
[rank31]:               ^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank31]:     self.fit_loop.run()
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank31]:     self.advance()
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank31]:     self.epoch_loop.run(self._data_fetcher)
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank31]:     self.advance(data_fetcher)
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank31]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank31]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank31]:     self._optimizer_step(batch_idx, closure)
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank31]:     call._call_lightning_module_hook(
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank31]:     output = fn(*args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank31]:     optimizer.step(closure=optimizer_closure)
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank31]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank31]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank31]:     super().optimizer_step(*a, **kw)
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank31]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank31]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank31]:     return optimizer.step(closure=closure, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank31]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank31]:     out = func(*args, **kwargs)
[rank31]:           ^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank31]:     ret = func(self, *args, **kwargs)
[rank31]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank31]:     loss = closure()
[rank31]:            ^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank31]:     closure_result = closure()
[rank31]:                      ^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank31]:     self._result = self.closure(*args, **kwargs)
[rank31]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank31]:     return func(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank31]:     step_output = self._step_fn()
[rank31]:                   ^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank31]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank31]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank31]:     output = fn(*args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank31]:     return self.lightning_module.training_step(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank31]:     output_dict = wrapped(*args, **kwargs)
[rank31]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank31]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank31]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank31]:     return self(
[rank31]:            ^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank31]:     return forward_call(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank31]:     return self.model(*a, **kw)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank31]:     return forward_call(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank31]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank31]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank31]:     module_outputs = super().__call__(
[rank31]:                      ^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank31]:     return forward_call(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank31]:     lm_logits = self.lm_head(hidden_states)
[rank31]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank31]:     return self._call_impl(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank31]:     return forward_call(*args, **kwargs)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank31]:     return F.linear(input, self.weight, self.bias)
[rank31]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank31]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 7 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank10]: Traceback (most recent call last):
[rank10]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 43, in <module>
[rank10]:     main()
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank10]:     _run_hydra(
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank10]:     _run_app(
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank10]:     run_and_report(
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank10]:     raise ex
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank10]:     return func()
[rank10]:            ^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank10]:     lambda: hydra.run(
[rank10]:             ^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank10]:     _ = ret.return_value
[rank10]:         ^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank10]:     raise self._return_value
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank10]:     ret.return_value = task_function(task_cfg)
[rank10]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank10]:     return fn(merged_config, *args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 38, in main
[rank10]:     train(cfg)
[rank10]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 32, in train
[rank10]:     trainer.fit(model_module, datamodule=data_module)
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank10]:     call._call_and_handle_interrupt(
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank10]:     return trainer_fn(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank10]:     self._run(model, ckpt_path=ckpt_path)
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank10]:     results = self._run_stage()
[rank10]:               ^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank10]:     self.fit_loop.run()
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank10]:     self.advance()
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank10]:     self.epoch_loop.run(self._data_fetcher)
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank10]:     self.advance(data_fetcher)
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank10]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank10]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank10]:     self._optimizer_step(batch_idx, closure)
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank10]:     call._call_lightning_module_hook(
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank10]:     output = fn(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank10]:     optimizer.step(closure=optimizer_closure)
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank10]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank10]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank10]:     super().optimizer_step(*a, **kw)
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank10]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank10]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank10]:     return optimizer.step(closure=closure, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank10]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank10]:     out = func(*args, **kwargs)
[rank10]:           ^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank10]:     ret = func(self, *args, **kwargs)
[rank10]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank10]:     loss = closure()
[rank10]:            ^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank10]:     closure_result = closure()
[rank10]:                      ^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank10]:     self._result = self.closure(*args, **kwargs)
[rank10]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank10]:     return func(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank10]:     step_output = self._step_fn()
[rank10]:                   ^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank10]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank10]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank10]:     output = fn(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank10]:     return self.lightning_module.training_step(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank10]:     output_dict = wrapped(*args, **kwargs)
[rank10]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank10]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank10]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank10]:     return self(
[rank10]:            ^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank10]:     return self.model(*a, **kw)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank10]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank10]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank10]:     module_outputs = super().__call__(
[rank10]:                      ^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank10]:     lm_logits = self.lm_head(hidden_states)
[rank10]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank10]:     return F.linear(input, self.weight, self.bias)
[rank10]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank10]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 2 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank11]: Traceback (most recent call last):
[rank11]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 43, in <module>
[rank11]:     main()
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank11]:     _run_hydra(
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank11]:     _run_app(
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank11]:     run_and_report(
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank11]:     raise ex
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank11]:     return func()
[rank11]:            ^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank11]:     lambda: hydra.run(
[rank11]:             ^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank11]:     _ = ret.return_value
[rank11]:         ^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank11]:     raise self._return_value
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank11]:     ret.return_value = task_function(task_cfg)
[rank11]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank11]:     return fn(merged_config, *args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 38, in main
[rank11]:     train(cfg)
[rank11]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 32, in train
[rank11]:     trainer.fit(model_module, datamodule=data_module)
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank11]:     call._call_and_handle_interrupt(
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank11]:     return trainer_fn(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank11]:     self._run(model, ckpt_path=ckpt_path)
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank11]:     results = self._run_stage()
[rank11]:               ^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank11]:     self.fit_loop.run()
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank11]:     self.advance()
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank11]:     self.epoch_loop.run(self._data_fetcher)
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank11]:     self.advance(data_fetcher)
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank11]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank11]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank11]:     self._optimizer_step(batch_idx, closure)
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank11]:     call._call_lightning_module_hook(
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank11]:     output = fn(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank11]:     optimizer.step(closure=optimizer_closure)
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank11]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank11]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank11]:     super().optimizer_step(*a, **kw)
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank11]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank11]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank11]:     return optimizer.step(closure=closure, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank11]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank11]:     out = func(*args, **kwargs)
[rank11]:           ^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank11]:     ret = func(self, *args, **kwargs)
[rank11]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank11]:     loss = closure()
[rank11]:            ^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank11]:     closure_result = closure()
[rank11]:                      ^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank11]:     self._result = self.closure(*args, **kwargs)
[rank11]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank11]:     return func(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank11]:     step_output = self._step_fn()
[rank11]:                   ^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank11]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank11]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank11]:     output = fn(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank11]:     return self.lightning_module.training_step(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank11]:     output_dict = wrapped(*args, **kwargs)
[rank11]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank11]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank11]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank11]:     return self(
[rank11]:            ^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank11]:     return self.model(*a, **kw)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank11]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank11]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank11]:     module_outputs = super().__call__(
[rank11]:                      ^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank11]:     lm_logits = self.lm_head(hidden_states)
[rank11]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank11]:     return F.linear(input, self.weight, self.bias)
[rank11]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank11]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 3 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
[rank13]: Traceback (most recent call last):
[rank13]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 43, in <module>
[rank13]:     main()
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank13]:     _run_hydra(
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank13]:     _run_app(
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank13]:     run_and_report(
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank13]:     raise ex
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank13]:     return func()
[rank13]:            ^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank13]:     lambda: hydra.run(
[rank13]:             ^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank13]:     _ = ret.return_value
[rank13]:         ^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank13]:     raise self._return_value
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank13]:     ret.return_value = task_function(task_cfg)
[rank13]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank13]:     return fn(merged_config, *args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 38, in main
[rank13]:     train(cfg)
[rank13]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 32, in train
[rank13]:     trainer.fit(model_module, datamodule=data_module)
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank13]:     call._call_and_handle_interrupt(
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank13]:     return trainer_fn(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank13]:     self._run(model, ckpt_path=ckpt_path)
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank13]:     results = self._run_stage()
[rank13]:               ^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank13]:     self.fit_loop.run()
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank13]:     self.advance()
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank13]:     self.epoch_loop.run(self._data_fetcher)
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank13]:     self.advance(data_fetcher)
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank13]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank13]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank13]:     self._optimizer_step(batch_idx, closure)
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank13]:     call._call_lightning_module_hook(
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank13]:     output = fn(*args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank13]:     optimizer.step(closure=optimizer_closure)
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank13]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank13]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank13]:     super().optimizer_step(*a, **kw)
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank13]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank13]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank13]:     return optimizer.step(closure=closure, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank13]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank13]:     out = func(*args, **kwargs)
[rank13]:           ^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank13]:     ret = func(self, *args, **kwargs)
[rank13]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank13]:     loss = closure()
[rank13]:            ^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank13]:     closure_result = closure()
[rank13]:                      ^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank13]:     self._result = self.closure(*args, **kwargs)
[rank13]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank13]:     return func(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank13]:     step_output = self._step_fn()
[rank13]:                   ^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank13]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank13]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank13]:     output = fn(*args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank13]:     return self.lightning_module.training_step(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank13]:     output_dict = wrapped(*args, **kwargs)
[rank13]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank13]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank13]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank13]:     return self(
[rank13]:            ^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank13]:     return self.model(*a, **kw)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank13]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank13]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank13]:     module_outputs = super().__call__(
[rank13]:                      ^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank13]:     lm_logits = self.lm_head(hidden_states)
[rank13]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank13]:     return F.linear(input, self.weight, self.bias)
[rank13]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank13]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 5 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank15]: Traceback (most recent call last):
[rank15]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 43, in <module>
[rank15]:     main()
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank15]:     _run_hydra(
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank15]:     _run_app(
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank15]:     run_and_report(
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank15]:     raise ex
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank15]:     return func()
[rank15]:            ^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank15]:     lambda: hydra.run(
[rank15]:             ^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank15]:     _ = ret.return_value
[rank15]:         ^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank15]:     raise self._return_value
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank15]:     ret.return_value = task_function(task_cfg)
[rank15]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank15]:     return fn(merged_config, *args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 38, in main
[rank15]:     train(cfg)
[rank15]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 32, in train
[rank15]:     trainer.fit(model_module, datamodule=data_module)
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank15]:     call._call_and_handle_interrupt(
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank15]:     return trainer_fn(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank15]:     self._run(model, ckpt_path=ckpt_path)
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank15]:     results = self._run_stage()
[rank15]:               ^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank15]:     self.fit_loop.run()
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank15]:     self.advance()
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank15]:     self.epoch_loop.run(self._data_fetcher)
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank15]:     self.advance(data_fetcher)
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank15]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank15]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank15]:     self._optimizer_step(batch_idx, closure)
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank15]:     call._call_lightning_module_hook(
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank15]:     output = fn(*args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank15]:     optimizer.step(closure=optimizer_closure)
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank15]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank15]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank15]:     super().optimizer_step(*a, **kw)
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank15]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank15]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank15]:     return optimizer.step(closure=closure, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank15]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank15]:     out = func(*args, **kwargs)
[rank15]:           ^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank15]:     ret = func(self, *args, **kwargs)
[rank15]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank15]:     loss = closure()
[rank15]:            ^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank15]:     closure_result = closure()
[rank15]:                      ^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank15]:     self._result = self.closure(*args, **kwargs)
[rank15]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank15]:     return func(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank15]:     step_output = self._step_fn()
[rank15]:                   ^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank15]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank15]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank15]:     output = fn(*args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank15]:     return self.lightning_module.training_step(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank15]:     output_dict = wrapped(*args, **kwargs)
[rank15]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank15]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank15]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank15]:     return self(
[rank15]:            ^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank15]:     return self.model(*a, **kw)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank15]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank15]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank15]:     module_outputs = super().__call__(
[rank15]:                      ^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank15]:     lm_logits = self.lm_head(hidden_states)
[rank15]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank15]:     return F.linear(input, self.weight, self.bias)
[rank15]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank15]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 7 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank12]: Traceback (most recent call last):
[rank12]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 43, in <module>
[rank12]:     main()
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank12]:     _run_hydra(
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank12]:     _run_app(
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank12]:     run_and_report(
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank12]:     raise ex
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank12]:     return func()
[rank12]:            ^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank12]:     lambda: hydra.run(
[rank12]:             ^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank12]:     _ = ret.return_value
[rank12]:         ^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank12]:     raise self._return_value
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank12]:     ret.return_value = task_function(task_cfg)
[rank12]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank12]:     return fn(merged_config, *args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 38, in main
[rank12]:     train(cfg)
[rank12]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 32, in train
[rank12]:     trainer.fit(model_module, datamodule=data_module)
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank12]:     call._call_and_handle_interrupt(
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank12]:     return trainer_fn(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank12]:     self._run(model, ckpt_path=ckpt_path)
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank12]:     results = self._run_stage()
[rank12]:               ^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank12]:     self.fit_loop.run()
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank12]:     self.advance()
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank12]:     self.epoch_loop.run(self._data_fetcher)
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank12]:     self.advance(data_fetcher)
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank12]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank12]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank12]:     self._optimizer_step(batch_idx, closure)
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank12]:     call._call_lightning_module_hook(
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank12]:     output = fn(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank12]:     optimizer.step(closure=optimizer_closure)
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank12]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank12]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank12]:     super().optimizer_step(*a, **kw)
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank12]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank12]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank12]:     return optimizer.step(closure=closure, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank12]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank12]:     out = func(*args, **kwargs)
[rank12]:           ^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank12]:     ret = func(self, *args, **kwargs)
[rank12]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank12]:     loss = closure()
[rank12]:            ^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank12]:     closure_result = closure()
[rank12]:                      ^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank12]:     self._result = self.closure(*args, **kwargs)
[rank12]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank12]:     return func(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank12]:     step_output = self._step_fn()
[rank12]:                   ^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank12]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank12]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank12]:     output = fn(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank12]:     return self.lightning_module.training_step(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank12]:     output_dict = wrapped(*args, **kwargs)
[rank12]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank12]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank12]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank12]:     return self(
[rank12]:            ^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank12]:     return self.model(*a, **kw)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank12]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank12]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank12]:     module_outputs = super().__call__(
[rank12]:                      ^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank12]:     lm_logits = self.lm_head(hidden_states)
[rank12]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank12]:     return F.linear(input, self.weight, self.bias)
[rank12]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank12]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 4 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank8]: Traceback (most recent call last):
[rank8]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 43, in <module>
[rank8]:     main()
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank8]:     _run_hydra(
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank8]:     _run_app(
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank8]:     run_and_report(
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank8]:     raise ex
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank8]:     return func()
[rank8]:            ^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank8]:     lambda: hydra.run(
[rank8]:             ^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank8]:     _ = ret.return_value
[rank8]:         ^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank8]:     raise self._return_value
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank8]:     ret.return_value = task_function(task_cfg)
[rank8]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank8]:     return fn(merged_config, *args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 38, in main
[rank8]:     train(cfg)
[rank8]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 32, in train
[rank8]:     trainer.fit(model_module, datamodule=data_module)
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank8]:     call._call_and_handle_interrupt(
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank8]:     return trainer_fn(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank8]:     self._run(model, ckpt_path=ckpt_path)
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank8]:     results = self._run_stage()
[rank8]:               ^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank8]:     self.fit_loop.run()
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank8]:     self.advance()
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank8]:     self.epoch_loop.run(self._data_fetcher)
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank8]:     self.advance(data_fetcher)
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank8]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank8]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank8]:     self._optimizer_step(batch_idx, closure)
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank8]:     call._call_lightning_module_hook(
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank8]:     output = fn(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank8]:     optimizer.step(closure=optimizer_closure)
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank8]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank8]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank8]:     super().optimizer_step(*a, **kw)
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank8]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank8]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank8]:     return optimizer.step(closure=closure, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank8]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank8]:     out = func(*args, **kwargs)
[rank8]:           ^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank8]:     ret = func(self, *args, **kwargs)
[rank8]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank8]:     loss = closure()
[rank8]:            ^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank8]:     closure_result = closure()
[rank8]:                      ^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank8]:     self._result = self.closure(*args, **kwargs)
[rank8]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank8]:     return func(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank8]:     step_output = self._step_fn()
[rank8]:                   ^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank8]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank8]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank8]:     output = fn(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank8]:     return self.lightning_module.training_step(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank8]:     output_dict = wrapped(*args, **kwargs)
[rank8]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank8]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank8]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank8]:     return self(
[rank8]:            ^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank8]:     return self.model(*a, **kw)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank8]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank8]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank8]:     module_outputs = super().__call__(
[rank8]:                      ^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank8]:     lm_logits = self.lm_head(hidden_states)
[rank8]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank8]:     return F.linear(input, self.weight, self.bias)
[rank8]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank8]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank14]: Traceback (most recent call last):
[rank14]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 43, in <module>
[rank14]:     main()
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank14]:     _run_hydra(
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank14]:     _run_app(
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank14]:     run_and_report(
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank14]:     raise ex
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank14]:     return func()
[rank14]:            ^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank14]:     lambda: hydra.run(
[rank14]:             ^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank14]:     _ = ret.return_value
[rank14]:         ^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank14]:     raise self._return_value
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank14]:     ret.return_value = task_function(task_cfg)
[rank14]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank14]:     return fn(merged_config, *args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 38, in main
[rank14]:     train(cfg)
[rank14]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 32, in train
[rank14]:     trainer.fit(model_module, datamodule=data_module)
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank14]:     call._call_and_handle_interrupt(
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank14]:     return trainer_fn(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank14]:     self._run(model, ckpt_path=ckpt_path)
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank14]:     results = self._run_stage()
[rank14]:               ^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank14]:     self.fit_loop.run()
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank14]:     self.advance()
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank14]:     self.epoch_loop.run(self._data_fetcher)
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank14]:     self.advance(data_fetcher)
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank14]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank14]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank14]:     self._optimizer_step(batch_idx, closure)
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank14]:     call._call_lightning_module_hook(
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank14]:     output = fn(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank14]:     optimizer.step(closure=optimizer_closure)
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank14]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank14]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank14]:     super().optimizer_step(*a, **kw)
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank14]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank14]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank14]:     return optimizer.step(closure=closure, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank14]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank14]:     out = func(*args, **kwargs)
[rank14]:           ^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank14]:     ret = func(self, *args, **kwargs)
[rank14]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank14]:     loss = closure()
[rank14]:            ^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank14]:     closure_result = closure()
[rank14]:                      ^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank14]:     self._result = self.closure(*args, **kwargs)
[rank14]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank14]:     return func(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank14]:     step_output = self._step_fn()
[rank14]:                   ^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank14]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank14]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank14]:     output = fn(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank14]:     return self.lightning_module.training_step(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank14]:     output_dict = wrapped(*args, **kwargs)
[rank14]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank14]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank14]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank14]:     return self(
[rank14]:            ^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank14]:     return self.model(*a, **kw)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank14]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank14]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank14]:     module_outputs = super().__call__(
[rank14]:                      ^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank14]:     lm_logits = self.lm_head(hidden_states)
[rank14]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank14]:     return F.linear(input, self.weight, self.bias)
[rank14]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank14]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 6 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error executing job with overrides: []
[rank9]: Traceback (most recent call last):
[rank9]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 43, in <module>
[rank9]:     main()
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/main.py", line 94, in decorated_main
[rank9]:     _run_hydra(
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
[rank9]:     _run_app(
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 457, in _run_app
[rank9]:     run_and_report(
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
[rank9]:     raise ex
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
[rank9]:     return func()
[rank9]:            ^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
[rank9]:     lambda: hydra.run(
[rank9]:             ^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/_internal/hydra.py", line 132, in run
[rank9]:     _ = ret.return_value
[rank9]:         ^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 260, in return_value
[rank9]:     raise self._return_value
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hydra/core/utils.py", line 186, in run_job
[rank9]:     ret.return_value = task_function(task_cfg)
[rank9]:                        ^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/utils/config_utils.py", line 104, in validations_wrapper
[rank9]:     return fn(merged_config, *args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 38, in main
[rank9]:     train(cfg)
[rank9]:   File "/fsx/ubuntu/tmp/ip-10-1-24-129/examples/llama/llama_pretrain.py", line 32, in train
[rank9]:     trainer.fit(model_module, datamodule=data_module)
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 543, in fit
[rank9]:     call._call_and_handle_interrupt(
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
[rank9]:     return trainer_fn(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in _fit_impl
[rank9]:     self._run(model, ckpt_path=ckpt_path)
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _run
[rank9]:     results = self._run_stage()
[rank9]:               ^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1030, in _run_stage
[rank9]:     self.fit_loop.run()
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank9]:     self.advance()
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank9]:     self.epoch_loop.run(self._data_fetcher)
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank9]:     self.advance(data_fetcher)
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank9]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank9]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank9]:     self._optimizer_step(batch_idx, closure)
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank9]:     call._call_lightning_module_hook(
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 159, in _call_lightning_module_hook
[rank9]:     output = fn(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 1308, in optimizer_step
[rank9]:     optimizer.step(closure=optimizer_closure)
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py", line 153, in step
[rank9]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank9]:                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/parts/fsdp_strategy.py", line 271, in optimizer_step
[rank9]:     super().optimizer_step(*a, **kw)
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 238, in optimizer_step
[rank9]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/fsdp.py", line 149, in optimizer_step
[rank9]:     return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank9]:     return optimizer.step(closure=closure, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 130, in wrapper
[rank9]:     return func.__get__(opt, opt.__class__)(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank9]:     out = func(*args, **kwargs)
[rank9]:           ^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank9]:     ret = func(self, *args, **kwargs)
[rank9]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/optim/adamw.py", line 204, in step
[rank9]:     loss = closure()
[rank9]:            ^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank9]:     closure_result = closure()
[rank9]:                      ^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank9]:     self._result = self.closure(*args, **kwargs)
[rank9]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank9]:     return func(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank9]:     step_output = self._step_fn()
[rank9]:                   ^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 317, in _training_step
[rank9]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank9]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 311, in _call_strategy_hook
[rank9]:     output = fn(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank9]:     return self.lightning_module.training_step(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/nemo/utils/model_utils.py", line 434, in wrap_training_step
[rank9]:     output_dict = wrapped(*args, **kwargs)
[rank9]:                   ^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 434, in training_step
[rank9]:     self.loss = self._training_step(batch, batch_idx, *a, **kw)
[rank9]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 418, in _training_step
[rank9]:     return self(
[rank9]:            ^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/hyperpod_nemo_adapter/collections/model/sagemaker_base_model.py", line 504, in forward
[rank9]:     return self.model(*a, **kw)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 874, in forward
[rank9]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank9]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformed_module.py", line 17, in __call__
[rank9]:     module_outputs = super().__call__(
[rank9]:                      ^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/sagemaker/tensor_parallel/transformer.py", line 376, in forward
[rank9]:     lm_logits = self.lm_head(hidden_states)
[rank9]:                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]:   File "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 117, in forward
[rank9]:     return F.linear(input, self.weight, self.bias)
[rank9]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank9]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 1 has a total capacity of 21.98 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 20.88 GiB memory in use. Of the allocated memory 20.39 GiB is allocated by PyTorch, and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/1562 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1562 [00:00<?, ?it/s] Epoch 0:   0%|          | 0/1562 [00:05<?, ?it/s]
W0222 13:49:35.974000 139693095666944 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 110354 closing signal SIGTERM
W0222 13:49:35.974000 139693095666944 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 110355 closing signal SIGTERM
W0222 13:49:35.975000 139693095666944 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 110356 closing signal SIGTERM
W0222 13:49:35.976000 139693095666944 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 110357 closing signal SIGTERM
W0222 13:49:35.981000 139693095666944 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 110358 closing signal SIGTERM
W0222 13:49:35.989000 139693095666944 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 110360 closing signal SIGTERM
W0222 13:49:35.989000 139693095666944 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 110361 closing signal SIGTERM
W0222 13:49:36.179000 140164295124224 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 168830 closing signal SIGTERM
W0222 13:49:36.181000 140164295124224 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 168831 closing signal SIGTERM
W0222 13:49:36.181000 140164295124224 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 168832 closing signal SIGTERM
W0222 13:49:36.185000 139851237541120 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 194936 closing signal SIGTERM
W0222 13:49:36.183000 140164295124224 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 168833 closing signal SIGTERM
W0222 13:49:36.183000 140164295124224 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 168834 closing signal SIGTERM
W0222 13:49:36.185000 139851237541120 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 194937 closing signal SIGTERM
W0222 13:49:36.186000 139851237541120 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 194938 closing signal SIGTERM
W0222 13:49:36.187000 140164295124224 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 168835 closing signal SIGTERM
W0222 13:49:36.187000 139851237541120 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 194939 closing signal SIGTERM
W0222 13:49:36.188000 139851237541120 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 194940 closing signal SIGTERM
W0222 13:49:36.189000 139851237541120 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 194941 closing signal SIGTERM
W0222 13:49:36.190000 139851237541120 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 194942 closing signal SIGTERM
W0222 13:49:36.187000 140686344320256 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 157428 closing signal SIGTERM
W0222 13:49:36.189000 140686344320256 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 157429 closing signal SIGTERM
W0222 13:49:36.191000 140686344320256 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 157430 closing signal SIGTERM
W0222 13:49:36.192000 140686344320256 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 157431 closing signal SIGTERM
W0222 13:49:36.195000 140164295124224 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 168836 closing signal SIGTERM
W0222 13:49:36.195000 140686344320256 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 157433 closing signal SIGTERM
W0222 13:49:36.196000 140686344320256 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 157434 closing signal SIGTERM
W0222 13:49:36.197000 140686344320256 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 157435 closing signal SIGTERM
E0222 13:49:37.282000 139693095666944 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 5 (pid: 110359) of binary: /opt/conda/bin/python
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.4.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
examples/llama/llama_pretrain.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-22_13:49:35
  host      : ip-10-1-107-242.ec2.internal
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 110359)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
E0222 13:49:37.593000 140164295124224 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 168829) of binary: /opt/conda/bin/python
W0222 13:49:37.596000 140164295124224 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-67-233.ec2.internal_168826_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
W0222 13:49:37.604000 140164295124224 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-67-233.ec2.internal_168826_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
W0222 13:49:37.606000 140164295124224 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-67-233.ec2.internal_168826_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.4.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
examples/llama/llama_pretrain.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-22_13:49:36
  host      : ip-10-1-67-233.ec2.internal
  rank      : 16 (local_rank: 0)
  exitcode  : 1 (pid: 168829)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
E0222 13:49:37.618000 140686344320256 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 4 (pid: 157432) of binary: /opt/conda/bin/python
E0222 13:49:37.620000 139851237541120 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 7 (pid: 194943) of binary: /opt/conda/bin/python
W0222 13:49:37.621000 140686344320256 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-97-113.ec2.internal_157425_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
W0222 13:49:37.622000 139851237541120 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-24-129.ec2.internal_194932_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
W0222 13:49:37.630000 140686344320256 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-97-113.ec2.internal_157425_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
W0222 13:49:37.632000 139851237541120 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-24-129.ec2.internal_194932_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
W0222 13:49:37.632000 140686344320256 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-97-113.ec2.internal_157425_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.4.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
examples/llama/llama_pretrain.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-22_13:49:36
  host      : ip-10-1-97-113.ec2.internal
  rank      : 28 (local_rank: 4)
  exitcode  : 1 (pid: 157432)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
W0222 13:49:37.634000 139851237541120 torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1218] The node 'ip-10-1-24-129.ec2.internal_194932_0' has failed to shutdown the rendezvous '100' due to an error of type RendezvousConnectionError.
Traceback (most recent call last):
  File "/opt/conda/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.4.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
examples/llama/llama_pretrain.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-22_13:49:36
  host      : ip-10-1-24-129.ec2.internal
  rank      : 15 (local_rank: 7)
  exitcode  : 1 (pid: 194943)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: ip-10-1-107-242: task 3: Exited with exit code 1
srun: error: ip-10-1-97-113: task 2: Exited with exit code 1
srun: error: ip-10-1-24-129: task 0: Exited with exit code 1
srun: error: ip-10-1-67-233: task 1: Exited with exit code 1
