# ê°€ì´ë“œ: How to set up EFA on AWS EC2 P4d

ì•„ë˜ì˜ ì°¸ê³  ìë£Œë¥¼ ì¼ë¶€ ë‚´ìš©ì„ ì°¸ê³  í•˜ì˜€ìŠµë‹ˆë‹¤. ì•„ë˜ ë‚´ìš© ë³´ë©´ì„œ, ë¶€ì¡±í•œ ë¶€ë¶„ì€ ì•„ë˜ ì°¸ê³  ë‚´ìš©ì„ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.
- ì°¸ê³  ìë£Œ
    - [Amazon EC2ì—ì„œ HPC ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ EFA ë° MPI ì‹œì‘í•˜ê¸°](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/efa-start.html#efa-start-tempinstance)

    

## 1. EFAë¥¼ ì‚¬ìš©í•œ ë³´ì•ˆ ê·¸ë£¹ ì¤€ë¹„
ë¨¼ì € "ë³´ì•ˆ ê·¸ë£¹" ì„ ìƒì„± í•©ë‹ˆë‹¤. ì´ëŠ” EC2 ë¥¼ ìƒì„±í• ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
ì•„ë˜ì™€ ê°™ì´ ì¸ë°”ìš´ë“œ/ì•„ì›ƒë°”ìš´ë“œ ì„¸íŒ…ì„ í•´ì£¼ì„¸ìš”.
- inbound
    - ![inbound.jpg](img/inbound.jpg)
- outbound
    - ![outbound.jpg](img/outbound.jpg)

## 2. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

* AMI Image & Instance Type
ì•„ë˜ ì£¼ì–´ì§„ AMI ë° Instancy Type ì„ ì°¸ì¡° í•˜ì„¸ìš”. ë³¸ì¸ì€ Capacity Reservation ì„ í†µí•´ì„œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì„ íƒ í•˜ì˜€ìŠµë‹ˆë‹¤.
    * ![ami_image.jpg](img/ami_image.jpg)
* VPC Subnet
    - ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì‹œ í• ë‹¹ëœ VPC ì˜ Available Zone (AZ) ì— Subnet ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: us-east-1c)
    * ![vpc_subnet.jpg](img/vpc_subnet.jpg)
* [ì¤‘ìš”] ë„¤íŠ¸ì›Œí¬ ì¹´ë“œ ì„¤ì • - ê³ ê¸‰
    * ì¹´ë“œ1: ì•„ë˜ì™€ ê°™ì´ ì„¤ì •ì„ í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. 
        * ![network_card.jpg](img/network_card.jpg)
    - ìµœëŒ€ EFA 4ê°œì˜ ì¹´ë“œë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” 1ê°œë§Œì„ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤.
        - [ì°¸ê³ ] í˜„ì¬ ì €ìëŠ” 4ê°œì˜ EFA ì¹´ë“œë¥¼ ì¶”ê°€ë¥¼ ì‹œë„ í–ˆìœ¼ë‚˜, ì •í™•í•œ ë°©ë²•ì„ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤. ì¶”í›„ ê°œì„  í•´ë³´ê² ìŠµë‹ˆë‹¤.
* ìŠ¤í† ë¦¬ì§€
    - ìŠ¤í† ë¦¬ì§€ëŠ” ì¶©ë¶„í•˜ê²Œ ìƒì„±í•´ì£¼ì„¸ìš”. 
    * 256 GB ì„¤ì •
* ë‘ ê°œ ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ
    * ![two_ec2.jpg](img/two_ec2.jpg)

## 3. EFA ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸
í˜„ì¬ì˜ ì‚¬ìš©í•œ AMI ëŠ” ê¸°ë³¸ì ì¸ Nvidia GPU ë“œë¼ì´ë²„ & CUDA & EFA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ ë¯¸ë¦¬ ì„¤ì¹˜ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
* Nvidia GPU ë“œë¼ì´ë²„ê°€ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
    ```
    nvidia-smi -q | head
    ```
    * ![nvidia-smi-driver.jpg](img/nvidia-smi-driver.jpg)
* EFA ì†Œí”„íŠ¸ì›¨ì–´ êµ¬ì„± ìš”ì†Œê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
    ```
    fi_info -p efa -t FI_EP_RDM
    ```
        * ![efa_info.jpg](img/efa_info.jpg)
    

## 4. EFA ë™ì‘ í…ŒìŠ¤íŠ¸:
EFA ë™ì‘ í…ŒìŠ¤íŠ¸ëŠ” "NCCL í…ŒìŠ¤íŠ¸" ë¥¼ ì„¤ì¹˜í•´ì„œ ì§„í–‰ í•©ë‹ˆë‹¤.

* NCCL Git Repo ë‹¤ìš´ë¡œë“œ
    ```
    git clone https://github.com/NVIDIA/nccl-tests.git && cd nccl-tests
    ```
* Libfabric ë””ë ‰í„°ë¦¬ë¥¼ LD_LIBRARY_PATH ë³€ìˆ˜ì— ì¶”ê°€
    ```
    export LD_LIBRARY_PATH=/opt/amazon/efa/lib:$LD_LIBRARY_PATH # Ubuntu
    ```
* NCCL í…ŒìŠ¤íŠ¸ ì„¤ì¹˜
ì•„ë˜ ëª…ë ¹ì´ ì—ëŸ¬ê°€ ê²½ë¡œê°€ ì˜ëª» ë˜ì–´ ìˆìœ¼ë©´, ìˆ˜ì •í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”.
    ```
    make MPI=1 MPI_HOME=/opt/amazon/openmpi \
            NCCL_HOME=/usr/local/cuda-12.6 \
            CUDA_HOME=/usr/local/cuda-12.6
    ```
    - ![install_nccl_test.jpg](img/install_nccl_test.jpg)
    
* Host íŒŒì¼ ìƒì„±
    ```
    /opt/amazon/openmpi/bin/mpirun \
            -x FI_EFA_USE_DEVICE_RDMA=1 \
            -x LD_LIBRARY_PATH=/opt/nccl/build/lib:/usr/local/cuda/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/opt/amazon/ofi-nccl/lib:$LD_LIBRARY_PATH \
            -x NCCL_DEBUG=INFO \
            --hostfile my-hosts -n 8 -N 8 \
            --mca pml ^cm --mca btl tcp,self --mca btl_tcp_if_exclude lo,docker0 --bind-to none \
            $HOME/nccl-tests/build/all_reduce_perf -b 8 -e 1G -f 2 -g 1 -c 1 -n 100
    ```
* EFA ë° NCCL êµ¬ì„± í…ŒìŠ¤íŠ¸
    * ìœ„ì˜ my-hosts íŒŒì¼ì´ ìˆëŠ” ìœ„ì¹˜ì—ì„œ ì‹¤í–‰ í•¨.
        ```
            /opt/amazon/openmpi/bin/mpirun \
            -x FI_EFA_USE_DEVICE_RDMA=1 \
            -x LD_LIBRARY_PATH=/opt/nccl/build/lib:/usr/local/cuda/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/opt/amazon/ofi-nccl/lib:$LD_LIBRARY_PATH \
            -x NCCL_DEBUG=INFO \
            --hostfile my-hosts -n 8 -N 8 \
            --mca pml ^cm --mca btl tcp,self --mca btl_tcp_if_exclude lo,docker0 --bind-to none \
            $HOME/nccl-tests/build/all_reduce_perf -b 8 -e 1G -f 2 -g 1 -c 1 -n 100
        ```

    * ê²°ê³¼
        ```
        ip-172-31-47-132:11752:11839 [6] NCCL INFO NET/OFI Running on p4d.24xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/amazon/ofi-nccl/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml
        ip-172-31-47-132:11749:11843 [3] NCCL INFO NET/OFI Selected provider is efa, fabric is efa (found 1 nics)
        ```

        - ![ncc_result.jpg](img/ncc_result.jpg)
            ```
            * ìœ„ì˜ ì‹¤í–‰ ë¡œê·¸ ìš”ì•½
                * í›Œë¥­í•œ ê²°ê³¼ì…ë‹ˆë‹¤! NCCL í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆë„¤ìš”. ì£¼ìš” ê²°ê³¼ë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤:
                * ğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ!
                * ì‹œìŠ¤í…œ êµ¬ì„±
                * ì¸ìŠ¤í„´ìŠ¤: AWS p4d.24xlarge
                * GPU: 8x NVIDIA A100-SXM4-40GB
                * NCCL: ë²„ì „ 2.24.3+cuda12.6
                * ë„¤íŠ¸ì›Œí‚¹: EFA (Elastic Fabric Adapter) with aws-ofi-nccl 1.14.1
                * ì„±ëŠ¥ ê²°ê³¼
                * í‰ê·  ë²„ìŠ¤ ëŒ€ì—­í­: 54.16 GB/s
                * 1GB ë°ì´í„° ì²˜ë¦¬:
                    * ì•Œê³ ë¦¬ì¦˜ ëŒ€ì—­í­: ~130 GB/s
                    * ë²„ìŠ¤ ëŒ€ì—­í­: ~227 GB/s
                    * ì²˜ë¦¬ ì‹œê°„: ~8.25ms
                * ì§€ì—°ì‹œê°„ (8ë°”ì´íŠ¸): ~79-82 ë§ˆì´í¬ë¡œì´ˆ
                * ì˜¤ë¥˜: 0ê°œ âœ…
                * ë„¤íŠ¸ì›Œí¬ í† í´ë¡œì§€
                * ëª¨ë“  GPU ê°„ P2P ì—°ê²° í™œì„±í™”
                * EFA ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ ê³ ì„±ëŠ¥ í†µì‹ 
                * 24ê°œ collective ì±„ë„, 32ê°œ P2P ì±„ë„
                * ì£¼ìš” íŠ¹ì§•
                * âœ… 8ê°œ GPU ëª¨ë‘ ì •ìƒ ì¸ì‹
                    âœ… P2P (Peer-to-Peer) í†µì‹  í™œì„±í™”
                    âœ… EFA ë„¤íŠ¸ì›Œí‚¹ ìµœì í™”
                    âœ… ëª¨ë“  í¬ê¸°ì˜ ë°ì´í„°ì—ì„œ ì•ˆì •ì  ì„±ëŠ¥
                    âœ… ì˜¤ë¥˜ ì—†ì´ ì™„ë£Œ
                * ì´ ê²°ê³¼ëŠ” ë¶„ì‚° í•™ìŠµì„ ìœ„í•œ ìµœì ì˜ ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ì œ PyTorchë‚˜ ë‹¤ë¥¸ ML í”„ë ˆì„ì›Œí¬ì—ì„œ ë©€í‹°-GPU í›ˆë ¨ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
            ```

## 5. Run code

* ì•„ë˜ Git Repo ë¥¼ ë‹¤ìš´ë¡œë“œ í•˜ì„¸ìš”.
    ```
    git clone https://github.com/pytorch/examples.git
    ```
- ì‚¬ìš© ì½”ë“œ
    - https://github.com/pytorch/examples/blob/main/distributed/ddp-tutorial-series/multigpu_torchrun.py
        - ![ddp_code.jpg](img/ddp_code.jpg)
* ê°€ìƒ í™˜ê²½ì¸ pytorch ë¡œ ì§„ì… í•©ë‹ˆë‹¤. 
    * ![enter_ve.jpg](img/enter_ve.jpg)
* ì²«ë²ˆì§¸ EC2 ì—ì„œ ë‹¤ìŒì˜ ë©¸ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”. 
    * rdzv_endpoint=172.31.47.132:30000  is the first ECâ€™s private ip.
    * â€”node_rank=0 is only different
        ```
                cd /home/ubuntu/examples/distributed/ddp-tutorial-series
                
                torchrun --nproc_per_node=8 \
                --nnodes=2 \
                --node_rank=0 \
                --rdzv_id=456 \
                --rdzv_backend=c10d \
                --rdzv_endpoint=172.31.47.132:30000 multigpu_torchrun.py 3000 1000
        ```

* ì²«ë²ˆì§¸ EC2 ì—ì„œ ë‹¤ìŒì˜ ë©¸ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”. : (
    * rdzv_endpoint=172.31.47.132:30000  is the first ECâ€™s private ip.
    * â€”node_rank=1 is only different
            ```
            cd /home/ubuntu/examples/distributed/ddp-tutorial-series

            torchrun --nproc_per_node=8 \
            --nnodes=2 \
            --node_rank=1 \
            --rdzv_id=456 \
            --rdzv_backend=c10d \
            --rdzv_endpoint=172.31.47.132:30000 multigpu_torchrun.py 3000 1000
            ```
            
## 6. Monitoring EFA on two EC2
* ëª¨ë‹ˆí„°ë§ shell íŒŒì¼
    ```
        * #!/bin/bash
            
            # EFA í™•ì¸
            if ! fi_info -p efa >/dev/null 2>&1; then
                echo "âŒ EFAê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
                exit 1
            fi
            
            # ì¸í„°í˜ì´ìŠ¤ ì°¾ê¸°
            EFA_IFACE=$(ls /sys/class/net/ | grep -E "(ens|eth)" | head -1)
            echo "ëª¨ë‹ˆí„°ë§ ì‹œì‘: $EFA_IFACE (Ctrl+Cë¡œ ì¢…ë£Œ)"
            
            # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
            watch -n 1 "echo 'EFA Stats ($EFA_IFACE) - \$(date +\"%H:%M:%S\")'; cat /proc/net/dev | grep $EFA_IFACE | awk '{printf \"ğŸ“¥ ìˆ˜ì‹ : %.1f MB\\nğŸ“¤ ì†¡ì‹ : %.1f MB\", \$2/1024/1024, \$10/1024/1024}'"
            
    ```
* EFA ëª¨ë‹ˆí„°ë§ ê²°ê³¼
    * ![efa_monitoring.jpg](img/efa_monitoring.jpg)
* GPU ì‚¬ìš©ìœ¨
    * all GPUs on each machine are being used.
    * The first machine:
        * watch -n 1 nvidia-smi
        * ![gpu_usage_ec-01.jpg](img/gpu_usage_ec-01.jpg)
    * The second machine
        * watch -n 1 nvidia-smi
        * ![gpu_usage_ec-02.jpg](img/gpu_usage_ec-02.jpg) 

## 7. íŠ¸ëŸ¬ë¸” ìŠˆíŒ…:

* ì—ëŸ¬: timeout
    - ![error_timeout.jpg](img/error_timeout.jpg)
    * ì›ì¸
        * ![error_block_port.jpg](img/error_block_port.jpg)
    * í¬íŠ¸ê°€ ë§‰í˜€ ìˆì–´ì„œ, ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •
        * ![error_fix_block_port.jpg](img/error_fix_block_port.jpg)
* ì—ëŸ¬ : ë¬´ì‘ë‹µ 
    * ![error_no_response.jpg](img/error_no_response.jpg)
    * ì›ì¸
        * í¬íŠ¸ ì´ìŠˆ
        * í¬íŠ¸ ì •ë¦¬ ë° ì¬ì‹¤í–‰ ( í˜¹ì€ í¬íŠ¸ ë²ˆí˜¸ ë°”ê¿ˆ)
            * 30000ë²ˆ í¬íŠ¸ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ í™•ì¸ 
                lsof -i:30000 # í¬íŠ¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ 
                sudo kill -9 $(lsof -ti:30000)
                
                

