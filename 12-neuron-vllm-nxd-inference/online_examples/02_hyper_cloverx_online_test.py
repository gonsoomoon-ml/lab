import requests
import time
import statistics
from concurrent.futures import ThreadPoolExecutor
import json

def test_single_request(prompt, model_name="/workspace/local-models/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B"):
    """ë‹¨ì¼ ìš”ì²­ í…ŒìŠ¤íŠ¸"""
    start_time = time.time()
    
    try:
        # í•œê¸€ í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•œ í—¤ë” ì„¤ì •
        headers = {
            "Content-Type": "application/json; charset=utf-8"
        }
        
        response = requests.post(
            "http://localhost:8080/v1/chat/completions",
            headers=headers,
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 500,  # 10-500 í† í° ë²”ìœ„ë¥¼ ìœ„í•´ 500ìœ¼ë¡œ ì¦ê°€
                "temperature": 0.7
            },
            timeout=30
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        if response.status_code == 200:
            result = response.json()
            tokens_used = result.get("usage", {}).get("total_tokens", 0)
            return {
                "success": True,
                "response_time": response_time,
                "tokens_used": tokens_used,
                "response": result["choices"][0]["message"]["content"]
            }
        else:
            # ì—ëŸ¬ ì‘ë‹µ ë‚´ìš©ë„ í¬í•¨
            error_detail = ""
            try:
                error_detail = response.json()
            except:
                error_detail = response.text
            
            return {
                "success": False,
                "response_time": response_time,
                "error": f"HTTP {response.status_code}",
                "error_detail": error_detail
            }
            
    except Exception as e:
        return {
            "success": False,
            "response_time": time.time() - start_time,
            "error": str(e)
        }

def check_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        response = requests.get("http://localhost:8080/v1/models")
        response.raise_for_status()
        models = response.json()
        
        # ëª¨ë¸ ëª©ë¡ ì¶œë ¥
        print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
        if "data" in models and models["data"]:
            for model in models["data"]:
                print(f"  - {model['id']}")
            return models["data"]  # data ë°°ì—´ë§Œ ë°˜í™˜
        else:
            print("  ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ ëª¨ë¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ëª©ë¡ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def run_benchmark(num_requests=20, concurrent_requests=1):
    """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print(f"ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘: {num_requests}ê°œ ìš”ì²­, {concurrent_requests}ê°œ ë™ì‹œ ì‹¤í–‰")
    print("=" * 50)
    
    # ë²¤ì¹˜ë§ˆí¬ ì „ì²´ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    benchmark_start_time = time.time()
    
    # ë¨¼ì € ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
    available_models = check_available_models()
    if not available_models:
        print("âš ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì²« ë²ˆì§¸ ëª¨ë¸ ì‚¬ìš©
    model_name = available_models[0]["id"]
    print(f"ğŸ¯ ì‚¬ìš©í•  ëª¨ë¸: {model_name}")
    
    # 20ê°œì˜ ë‹¤ì–‘í•œ í•œê¸€ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë“¤ (10-500 í† í° ë²”ìœ„ì˜ ë‹µë³€ì´ ë‚˜ì˜¤ë„ë¡ ì„¤ê³„)
    test_prompts = [
        "ë°”ì´ë¸Œ ì½”ë”©ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜",
        "ì•ˆë…•í•˜ì„¸ìš”! ê°„ë‹¨í•œ ì¸ì‚¬ë§ì„ í•´ì£¼ì„¸ìš”.",
        "íŒŒë¦¬ëŠ” ì–´ëŠ ë‚˜ë¼ì˜ ìˆ˜ë„ì¸ê°€ìš”?",
        "1+1ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì¬ë¯¸ìˆëŠ” ë†ë‹´ì„ í•˜ë‚˜ í•´ì£¼ì„¸ìš”.",
        "íŒŒì´ì¬ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "í•œêµ­ì˜ ì „í†µ ìŒì‹ ì¤‘ ê¹€ì¹˜ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ê¸°í›„ ë³€í™”ê°€ ìš°ë¦¬ ìƒí™œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ìŠ¤ë§ˆíŠ¸í°ì˜ ì¥ë‹¨ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ë…ì„œì˜ ì¤‘ìš”ì„±ì— ëŒ€í•´ ë§í•´ì£¼ì„¸ìš”.",
        "ìš´ë™ì´ ê±´ê°•ì— ë¯¸ì¹˜ëŠ” ê¸ì •ì ì¸ íš¨ê³¼ë“¤ì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”.",
        "ìš”ë¦¬ ì´ˆë³´ìë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ìš”ë¦¬ íŒì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ì—¬í–‰ì„ ê°ˆ ë•Œ ì¤€ë¹„í•´ì•¼ í•  í•„ìˆ˜í’ˆë“¤ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.",
        "ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì¡°ì–¸í•´ì£¼ì„¸ìš”.",
        "ì¹œí™˜ê²½ ìƒí™œì„ ìœ„í•œ ì‹¤ì²œ ë°©ë²•ë“¤ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.",
        "íš¨ê³¼ì ì¸ ì‹œê°„ ê´€ë¦¬ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ê±´ê°•í•œ ì‹ìŠµê´€ì„ ìœ„í•œ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.",
        "ì·¨ë¯¸ ìƒí™œì˜ ì¤‘ìš”ì„±ê³¼ ì¶”ì²œ ì·¨ë¯¸ë¥¼ ì†Œê°œí•´ì£¼ì„¸ìš”.",
        "ë””ì§€í„¸ ë””í†¡ìŠ¤ì˜ í•„ìš”ì„±ê³¼ ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    ]
    
    results = []
    
    if concurrent_requests == 1:
        # ìˆœì°¨ ì‹¤í–‰
        for i in range(num_requests):
            prompt = test_prompts[i % len(test_prompts)]
            print(f"ìš”ì²­ {i+1}/{num_requests}: {prompt[:30]}...")
            
            result = test_single_request(prompt, model_name)
            results.append(result)
            
            if result["success"]:
                print(f"  âœ… ì„±ê³µ - {result['response_time']:.2f}ì´ˆ, {result['tokens_used']} í† í°")
                print(f"     ì‘ë‹µ: {result['response'][:50]}...")
            else:
                print(f"  âŒ ì‹¤íŒ¨ - {result['error']}")
                if "error_detail" in result:
                    print(f"     ìƒì„¸: {result['error_detail']}")
    
    else:
        # ë™ì‹œ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=concurrent_requests) as executor:
            futures = []
            for i in range(num_requests):
                prompt = test_prompts[i % len(test_prompts)]
                futures.append(executor.submit(test_single_request, prompt, model_name))
            
            for i, future in enumerate(futures):
                result = future.result()
                results.append(result)
                print(f"ìš”ì²­ {i+1}/{num_requests} ì™„ë£Œ - {result['response_time']:.2f}ì´ˆ")
    
    # ë²¤ì¹˜ë§ˆí¬ ì „ì²´ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
    benchmark_end_time = time.time()
    total_benchmark_time = benchmark_end_time - benchmark_start_time
    
    # ê²°ê³¼ ë¶„ì„
    successful_results = [r for r in results if r["success"]]
    failed_results = [r for r in results if not r["success"]]
    
    print("\n" + "=" * 50)
    print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
    print("=" * 50)
    
    print(f"ì´ ìš”ì²­ ìˆ˜: {len(results)}")
    print(f"ì„±ê³µ: {len(successful_results)}")
    print(f"ì‹¤íŒ¨: {len(failed_results)}")
    print(f"ì„±ê³µë¥ : {len(successful_results)/len(results)*100:.1f}%")
    
    if successful_results:
        response_times = [r["response_time"] for r in successful_results]
        tokens_used = [r["tokens_used"] for r in successful_results]
        
        print(f"\nâ±ï¸  ì‘ë‹µ ì‹œê°„:")
        print(f"  í‰ê· : {statistics.mean(response_times):.2f}ì´ˆ")
        print(f"  ì¤‘ê°„ê°’: {statistics.median(response_times):.2f}ì´ˆ")
        print(f"  ìµœì†Œ: {min(response_times):.2f}ì´ˆ")
        print(f"  ìµœëŒ€: {max(response_times):.2f}ì´ˆ")
        
        print(f"\nğŸ“ í† í° ì‚¬ìš©ëŸ‰:")
        print(f"  í‰ê· : {statistics.mean(tokens_used):.1f} í† í°")
        print(f"  ì´í•©: {sum(tokens_used)} í† í°")
        
        # ê¸°ì¡´ ì²˜ë¦¬ëŸ‰ ê³„ì‚° (ê°œë³„ ì‘ë‹µ ì‹œê°„ ê¸°ë°˜)
        total_response_time = sum(response_times)
        if total_response_time > 0:
            requests_per_second_individual = len(successful_results) / total_response_time
            print(f"\nğŸš€ ê°œë³„ ì‘ë‹µ ì‹œê°„ ê¸°ë°˜ ì²˜ë¦¬ëŸ‰: {requests_per_second_individual:.2f} ìš”ì²­/ì´ˆ")
        
        # ìƒˆë¡œìš´ ì´ ì²˜ë¦¬ëŸ‰ ê³„ì‚° (ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹œê°„ ê¸°ë°˜)
        print(f"\nğŸš€ ì´ ì²˜ë¦¬ëŸ‰ ì§€í‘œ:")
        print(f"  ì „ì²´ ì‹¤í–‰ ì‹œê°„: {total_benchmark_time:.2f}ì´ˆ")
        print(f"  ì´ ì²˜ë¦¬ëŸ‰: {len(successful_results)/total_benchmark_time:.2f} ìš”ì²­/ì´ˆ")
        print(f"  í† í° ì²˜ë¦¬ëŸ‰: {sum(tokens_used)/total_benchmark_time:.1f} í† í°/ì´ˆ")
        
        # íš¨ìœ¨ì„± ë¹„êµ
        if total_response_time > 0:
            efficiency_ratio = total_benchmark_time / total_response_time
            print(f"  íš¨ìœ¨ì„± ë¹„ìœ¨: {efficiency_ratio:.2f} (1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ íš¨ìœ¨ì )")
    
    if failed_results:
        print(f"\nâŒ ì‹¤íŒ¨í•œ ìš”ì²­ë“¤:")
        for i, result in enumerate(failed_results):
            print(f"  {i+1}. {result['error']}")
            if "error_detail" in result:
                print(f"     ìƒì„¸: {result['error_detail']}") 

if __name__ == "__main__":
    # í•œê¸€ í”„ë¡¬í”„íŠ¸ ë²¤ì¹˜ë§ˆí¬ (20ê°œ ìš”ì²­, ìˆœì°¨ ì‹¤í–‰)
    run_benchmark(num_requests=20, concurrent_requests=1)
    
    print("\n" + "=" * 50)
    
    # ë™ì‹œ ì‹¤í–‰ ë²¤ì¹˜ë§ˆí¬ (20ê°œ ìš”ì²­, 3ê°œ ë™ì‹œ ì‹¤í–‰)
    run_benchmark(num_requests=20, concurrent_requests=4) 